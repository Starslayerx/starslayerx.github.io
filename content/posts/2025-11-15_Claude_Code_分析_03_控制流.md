+++
date = '2025-11-14T11:00:00+01:00'
draft = false
title = 'Claude Code åˆ†æ 03ï¼šæ§åˆ¶æµ'
tags = ['Agent']
+++

# ğŸ”„ æ§åˆ¶æµä¸ç¼–æ’å¼•æ“

```mermaid
sequenceDiagram
    participant User
    participant MainLoop as Main Loop (tt)
    participant LLM as LLM API
    participant ToolBatch as Tool Batcher
    participant Tool1 as ReadTool
    participant Tool2 as GrepTool
    participant Tool3 as EditTool
    participant UI as UI Renderer
    User->>MainLoop: "Search for TODO comments and update them"
    MainLoop->>LLM: Stream request with context
    LLM-->>MainLoop: text_delta: "I'll search for TODOs..."
    MainLoop-->>UI: Update display
    LLM-->>MainLoop: tool_use: GrepTool
    LLM-->>MainLoop: tool_use: ReadTool (multiple files)
    LLM-->>MainLoop: message_stop
    MainLoop->>ToolBatch: Execute tool batch
    par Parallel Execution
        ToolBatch->>Tool1: ReadTool.call() [Read-only]
        ToolBatch->>Tool2: GrepTool.call() [Read-only]
        Tool1-->>UI: Progress: "Reading file1.js"
        Tool2-->>UI: Progress: "Searching *.js"
        Tool1-->>ToolBatch: Result: File contents
        Tool2-->>ToolBatch: Result: 5 matches
    end
    ToolBatch->>MainLoop: Tool results
    MainLoop->>LLM: Continue with results
    LLM-->>MainLoop: tool_use: EditTool
    MainLoop->>ToolBatch: Execute write tool
    Note over ToolBatch, Tool3: Sequential Execution
    ToolBatch->>Tool3: EditTool.call() [Write]
    Tool3-->>UI: Progress: "Editing file1.js"
    Tool3-->>ToolBatch: Result: Success
    ToolBatch->>MainLoop: Edit complete
    MainLoop->>LLM: Continue with result
    LLM-->>MainLoop: text_delta: "Updated 5 TODOs..."
    MainLoop-->>UI: Final response
```

## ä¸»å¯¹è¯å¾ªç¯ï¼šä¸€ä¸ªæµå¼çŠ¶æ€æœº

Claude Code çš„æ ¸å¿ƒæ˜¯ `tt` å¼‚æ­¥ç”Ÿæˆå™¨å‡½æ•°â€”â€”ä¸€ä¸ªç¼–æ’æ•´ä¸ªå¯¹è¯æµç¨‹çš„å¤æ‚çŠ¶æ€æœºã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒçš„å®é™…ç»“æ„ï¼š

```typescript
// é‡æ„çš„ä¸»å¾ªç¯ç­¾åï¼Œå¸¦æœ‰æ—¶é—´æ³¨è§£
async function* tt(
  currentMessages: CliMessage[],         // å®Œæ•´å†å² - å†…å­˜: O(conversation_length)
  baseSystemPromptString: string,        // é™æ€æç¤ºè¯ - ~2KB
  currentGitContext: GitContext,         // Git çŠ¶æ€ - é€šå¸¸ ~1-5KB
  currentClaudeMdContents: ClaudeMdContent[], // é¡¹ç›®ä¸Šä¸‹æ–‡ - ~5-50KB
  permissionGranterFn: PermissionGranter, // æƒé™å›è°ƒ
  toolUseContext: ToolUseContext,         // å…±äº«ä¸Šä¸‹æ–‡ - ~10KB
  activeStreamingToolUse?: ToolUseBlock,  // æ¢å¤çŠ¶æ€
  loopState: {
    turnId: string,        // æœ¬è½®çš„ UUID
    turnCounter: number,   // é€’å½’æ·±åº¦
    compacted?: boolean,   // å†å²æ˜¯å¦è¢«å‹ç¼©
    isResuming?: boolean   // æ˜¯å¦ä»ä¿å­˜ä¸­æ¢å¤
  }
): AsyncGenerator<CliMessage, void, void> {
  // â”Œâ”€ é˜¶æ®µ 1: ä¸Šä¸‹æ–‡å‡†å¤‡ [~50-200ms]
  // â”œâ”€ é˜¶æ®µ 2: è‡ªåŠ¨å‹ç¼©æ£€æŸ¥ [è§¦å‘æ—¶ ~0-3000ms]
  // â”œâ”€ é˜¶æ®µ 3: ç³»ç»Ÿæç¤ºè¯ç»„è£… [~10-50ms]
  // â”œâ”€ é˜¶æ®µ 4: LLM æµå¤„ç† [~2000-10000ms]
  // â”œâ”€ é˜¶æ®µ 5: å·¥å…·æ‰§è¡Œ [æ¯ä¸ªå·¥å…· ~100-30000ms]
  // â””â”€ é˜¶æ®µ 6: é€’å½’æˆ–å®Œæˆ [~0ms]
}
```

### é˜¶æ®µ 1ï¼šä¸Šä¸‹æ–‡çª—å£ç®¡ç†

æ§åˆ¶æµä¸­çš„ç¬¬ä¸€ä¸ªå…³é”®å†³ç­–æ˜¯åˆ¤æ–­å¯¹è¯æ˜¯å¦éœ€è¦å‹ç¼©ï¼š

```typescript
// è‡ªåŠ¨å‹ç¼©é€»è¾‘ï¼ˆæ¨æ–­å®ç°ï¼‰
class ContextCompactionController {
  private static readonly COMPACTION_THRESHOLDS = {
    tokenCount: 100_000,      // æ¿€è¿›çš„ token é™åˆ¶
    messageCount: 200,        // æ¶ˆæ¯æ•°é‡å¤‡é€‰
    costThreshold: 5.00       // åŸºäºæˆæœ¬çš„è§¦å‘å™¨
  };

  static async shouldCompact(
    messages: CliMessage[],
    model: string
  ): Promise<boolean> {
    // å¿«é€Ÿè·¯å¾„ï¼šé¦–å…ˆæ£€æŸ¥æ¶ˆæ¯æ•°é‡
    if (messages.length < 50) return false;

    // æ˜‚è´µè·¯å¾„ï¼šè®¡ç®— token
    const tokenCount = await this.estimateTokens(messages, model);

    return tokenCount > this.COMPACTION_THRESHOLDS.tokenCount ||
           messages.length > this.COMPACTION_THRESHOLDS.messageCount;
  }

  static async compact(
    messages: CliMessage[],
    context: ToolUseContext
  ): Promise<CompactionResult> {
    // é˜¶æ®µ 1ï¼šè¯†åˆ«éœ€è¦ä¿ç•™çš„æ¶ˆæ¯
    const preserve = this.identifyPreservedMessages(messages);

    // é˜¶æ®µ 2ï¼šé€šè¿‡ LLM ç”Ÿæˆæ‘˜è¦
    const summary = await this.generateSummary(
      messages.filter(m => !preserve.has(m.uuid)),
      context
    );

    // é˜¶æ®µ 3ï¼šé‡å»ºæ¶ˆæ¯å†å²
    return {
      messages: [
        this.createSummaryMessage(summary),
        ...messages.filter(m => preserve.has(m.uuid))
      ],
      tokensaved: this.calculateSavings(messages, summary)
    };
  }
}
```

**æ€§èƒ½ç‰¹å¾**ï¼š
- Token è®¡æ•°ï¼šO(n)ï¼Œå…¶ä¸­ n æ˜¯æ¶ˆæ¯å†…å®¹æ€»é•¿åº¦
- æ‘˜è¦ç”Ÿæˆï¼šé¢å¤–ä¸€æ¬¡ LLM è°ƒç”¨ï¼ˆ~2-3sï¼‰
- å†…å­˜å½±å“ï¼šå‹ç¼©æœŸé—´ä¸´æ—¶åŒå€æ¶ˆæ¯å­˜å‚¨

### é˜¶æ®µ 2ï¼šåŠ¨æ€ç³»ç»Ÿæç¤ºè¯ç»„è£…

ç³»ç»Ÿæç¤ºè¯ç»„è£…å±•ç°äº†ä¸€ä¸ªå¤æ‚çš„ç¼“å­˜å’Œç»„åˆç­–ç•¥ï¼š

```typescript
// ç³»ç»Ÿæç¤ºè¯ç»„åˆæµæ°´çº¿
class SystemPromptAssembler {
  private static cache = new Map<string, {
    content: string,
    hash: string,
    expiry: number
  }>();

  static async assemble(
    basePrompt: string,
    claudeMd: ClaudeMdContent[],
    gitContext: GitContext,
    tools: ToolDefinition[],
    model: string
  ): Promise<string | ContentBlock[]> {
    // å¹¶è¡Œè·å–åŠ¨æ€ç»„ä»¶
    const [
      claudeMdSection,
      gitSection,
      directorySection,
      toolSection
    ] = await Promise.all([
      this.formatClaudeMd(claudeMd),
      this.formatGitContext(gitContext),
      this.getDirectoryStructure(),
      this.formatToolDefinitions(tools)
    ]);

    // æ¨¡å‹ç‰¹å®šé€‚é…
    const modelSection = this.getModelAdaptations(model);

    // ä½¿ç”¨æ™ºèƒ½æˆªæ–­è¿›è¡Œç»„åˆ
    return this.compose({
      base: basePrompt,           // ä¼˜å…ˆçº§ 1
      model: modelSection,        // ä¼˜å…ˆçº§ 2
      claudeMd: claudeMdSection,  // ä¼˜å…ˆçº§ 3
      git: gitSection,           // ä¼˜å…ˆçº§ 4
      directory: directorySection, // ä¼˜å…ˆçº§ 5
      tools: toolSection         // ä¼˜å…ˆçº§ 6
    });
  }

  private static getModelAdaptations(model: string): string {
    // æ¨¡å‹ç‰¹å®šçš„æç¤ºå·¥ç¨‹
    const adaptations = {
      'claude-3-opus': {
        style: 'detailed',
        instructions: 'Think step by step. Show your reasoning.',
        tokenBudget: 0.3  // ä¸Šä¸‹æ–‡çš„ 30% ç”¨äºæ¨ç†
      },
      'claude-3-sonnet': {
        style: 'balanced',
        instructions: 'Be concise but thorough.',
        tokenBudget: 0.2
      },
      'claude-3-haiku': {
        style: 'brief',
        instructions: 'Get to the point quickly.',
        tokenBudget: 0.1
      }
    };

    const config = adaptations[model] || adaptations['claude-3-sonnet'];
    return this.formatModelInstructions(config);
  }
}
```

### é˜¶æ®µ 3ï¼šæµå¼çŠ¶æ€æœº

LLM æµå¼å¤„ç†é˜¶æ®µå®ç°äº†ä¸€ä¸ªå¤æ‚çš„äº‹ä»¶é©±åŠ¨çŠ¶æ€æœºï¼š

```typescript
// æµäº‹ä»¶å¤„ç†çŠ¶æ€æœº
class StreamEventProcessor {
  private state: {
    phase: 'idle' | 'message_start' | 'content' | 'tool_input' | 'complete';
    currentMessage: Partial<CliMessage>;
    contentBlocks: ContentBlock[];
    activeToolInput?: {
      toolId: string;
      buffer: string;
      parser: StreamingToolInputParser;
    };
    metrics: {
      firstTokenLatency?: number;
      tokensPerSecond: number[];
    };
  };

  async *processStream(
    stream: AsyncIterable<StreamEvent>
  ): AsyncGenerator<UIEvent | CliMessage> {
    for await (const event of stream) {
      switch (event.type) {
        case 'message_start':
          this.state.phase = 'message_start';
          this.state.metrics.firstTokenLatency = Date.now() - startTime;
          yield { type: 'ui_state', data: { status: 'assistant_responding' } };
          break;

        case 'content_block_start':
          yield* this.handleContentBlockStart(event);
          break;

        case 'content_block_delta':
          yield* this.handleContentBlockDelta(event);
          break;

        case 'content_block_stop':
          yield* this.handleContentBlockStop(event);
          break;

        case 'message_stop':
          yield* this.finalizeMessage(event);
          break;

        case 'error':
          yield* this.handleError(event);
          break;
      }
    }
  }

  private async *handleContentBlockDelta(
    event: ContentBlockDeltaEvent
  ): AsyncGenerator<UIEvent> {
    const block = this.state.contentBlocks[event.index];

    switch (event.delta.type) {
      case 'text_delta':
        // æ–‡æœ¬çš„ç›´æ¥ UI æ›´æ–°
        block.text += event.delta.text;
        yield {
          type: 'ui_text_delta',
          data: {
            text: event.delta.text,
            blockIndex: event.index
          }
        };
        break;

      case 'input_json_delta':
        // ç´¯ç§¯å·¥å…·è¾“å…¥çš„ JSON
        if (this.state.activeToolInput) {
          this.state.activeToolInput.buffer += event.delta.partial_json;

          // åœ¨å…³é”®ç‚¹å°è¯•è§£æ
          if (event.delta.partial_json.includes('}') ||
              event.delta.partial_json.includes(']')) {
            const result = this.state.activeToolInput.parser.addChunk(
              event.delta.partial_json
            );

            if (result.complete) {
              block.input = result.value;
              yield {
                type: 'ui_tool_preview',
                data: {
                  toolId: this.state.activeToolInput.toolId,
                  input: result.value
                }
              };
            }
          }
        }
        break;
    }
  }
}
```

### é˜¶æ®µ 4ï¼šå·¥å…·æ‰§è¡Œæµæ°´çº¿

å·¥å…·æ‰§è¡Œç³»ç»Ÿå®ç°äº†ä¸€ä¸ªå¤æ‚çš„å¹¶è¡Œ/é¡ºåºæ‰§è¡Œç­–ç•¥ï¼š

```mermaid
graph TB
    subgraph "å·¥å…·è¯·æ±‚åˆ†æ"
        ToolRequests[Tool Use Blocks] --> Categorize{æŒ‰ç±»å‹åˆ†ç±»}
        Categorize -->|åªè¯»| ReadQueue[è¯»å–é˜Ÿåˆ—]
        Categorize -->|å†™å…¥/å‰¯ä½œç”¨| WriteQueue[å†™å…¥é˜Ÿåˆ—]
    end

    subgraph "å¹¶è¡Œæ‰§è¡Œæ± "
        ReadQueue --> ParallelPool[å¹¶è¡Œæ‰§è¡Œå™¨]
        ParallelPool --> Worker1[Worker 1]
        ParallelPool --> Worker2[Worker 2]
        ParallelPool --> WorkerN[Worker N]

        Worker1 --> Results1[Result 1]
        Worker2 --> Results2[Result 2]
        WorkerN --> ResultsN[Result N]
    end

    subgraph "é¡ºåºæ‰§è¡Œ"
        WriteQueue --> SeqExecutor[é¡ºåºæ‰§è¡Œå™¨]
        Results1 --> SeqExecutor
        Results2 --> SeqExecutor
        ResultsN --> SeqExecutor

        SeqExecutor --> WriteTool1[Write Tool 1]
        WriteTool1 --> WriteTool2[Write Tool 2]
        WriteTool2 --> FinalResults[æ‰€æœ‰ç»“æœ]
    end
```

```typescript
// å¹¶è¡Œæ‰§è¡Œç¼–æ’å™¨
class ToolExecutionOrchestrator {
  private static readonly CONCURRENCY_LIMIT = 10;

  static async *executeToolBatch(
    toolUses: ToolUseBlock[],
    context: ToolUseContext,
    permissionFn: PermissionGranter
  ): AsyncGenerator<CliMessage> {
    // é˜¶æ®µ 1ï¼šå·¥å…·åˆ†ç±»
    const { readOnly, writeTools } = this.categorizeTools(toolUses);

    // é˜¶æ®µ 2ï¼šå¹¶è¡Œæ‰§è¡Œåªè¯»å·¥å…·
    if (readOnly.length > 0) {
      yield* this.executeParallel(readOnly, context, permissionFn);
    }

    // é˜¶æ®µ 3ï¼šé¡ºåºæ‰§è¡Œå†™å…¥å·¥å…·
    for (const tool of writeTools) {
      yield* this.executeSequential(tool, context, permissionFn);
    }
  }

  private static async *executeParallel(
    tools: ToolUseBlock[],
    context: ToolUseContext,
    permissionFn: PermissionGranter
  ): AsyncGenerator<CliMessage> {
    const executions = tools.map(tool =>
      this.createToolExecution(tool, context, permissionFn)
    );

    // è‡ªå®šä¹‰å¹¶è¡Œæ˜ å°„ï¼Œå¸¦èƒŒå‹æ§åˆ¶
    yield* parallelMap(executions, this.CONCURRENCY_LIMIT);
  }
}

// parallelMap å®ç°
async function* parallelMap<T>(
  generators: AsyncGenerator<T>[],
  concurrency: number
): AsyncGenerator<T> {
  const executing = new Set<Promise<IteratorResult<T>>>();
  const pending = [...generators];

  // å¡«å……åˆå§‹æ’æ§½
  while (executing.size < concurrency && pending.length > 0) {
    const gen = pending.shift()!;
    executing.add(gen.next());
  }

  while (executing.size > 0) {
    // ç«èµ›ä¸‹ä¸€ä¸ªå®Œæˆ
    const result = await Promise.race(executing);
    executing.delete(result as any);

    if (!result.done) {
      // äº§å‡ºå€¼
      yield result.value;

      // ç»§ç»­è¿™ä¸ªç”Ÿæˆå™¨
      const nextPromise = result.generator.next();
      executing.add(nextPromise);
    }

    // å¦‚æœå¯ç”¨ï¼Œå¡«å……ç©ºæ’æ§½
    if (executing.size < concurrency && pending.length > 0) {
      const gen = pending.shift()!;
      executing.add(gen.next());
    }
  }
}
```

**æ‰§è¡Œæ—¶é—´åˆ†æ**ï¼š

| å·¥å…·ç±»å‹ | å¹¶å‘æ€§ | å…¸å‹å»¶è¿Ÿ | ç“¶é¢ˆ |
|---------|--------|---------|------|
| ReadTool | å¹¶è¡Œ (10) | 10-50ms | ç£ç›˜ I/O |
| GrepTool | å¹¶è¡Œ (10) | 100-500ms | CPU æ­£åˆ™è¡¨è¾¾å¼ |
| WebFetchTool | å¹¶è¡Œ (3) | 500-3000ms | ç½‘ç»œ |
| EditTool | é¡ºåº | 20-100ms | éªŒè¯ |
| BashTool | é¡ºåº | 50-10000ms | è¿›ç¨‹æ‰§è¡Œ |
| AgentTool | å¹¶è¡Œ (5) | 2000-20000ms | å­ LLM è°ƒç”¨ |

### é˜¶æ®µ 5ï¼šæƒé™æ§åˆ¶æµ

æƒé™ç³»ç»Ÿå®ç°äº†ä¸€ä¸ªå¤šçº§å†³ç­–æ ‘ï¼š

```typescript
// æƒé™å†³ç­–æµç¨‹
class PermissionController {
  static async checkPermission(
    tool: ToolDefinition,
    input: any,
    context: ToolPermissionContext
  ): Promise<PermissionDecision> {
    // çº§åˆ« 1ï¼šæ£€æŸ¥æ˜ç¡®æ‹’ç»è§„åˆ™ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    const denyRule = this.findMatchingRule(
      tool,
      input,
      context.alwaysDenyRules
    );
    if (denyRule) {
      return { behavior: 'deny', reason: denyRule };
    }

    // çº§åˆ« 2ï¼šæ£€æŸ¥æ¨¡å¼è¦†ç›–
    if (context.mode === 'bypassPermissions') {
      return { behavior: 'allow', reason: 'bypass_mode' };
    }

    if (context.mode === 'acceptEdits' &&
        this.isEditTool(tool) &&
        this.isPathSafe(input.path)) {
      return { behavior: 'allow', reason: 'accept_edits_mode' };
    }

    // çº§åˆ« 3ï¼šæ£€æŸ¥æ˜ç¡®å…è®¸è§„åˆ™
    const allowRule = this.findMatchingRule(
      tool,
      input,
      context.alwaysAllowRules
    );
    if (allowRule) {
      return { behavior: 'allow', reason: allowRule };
    }

    // çº§åˆ« 4ï¼šäº¤äº’å¼æç¤º
    return {
      behavior: 'ask',
      suggestions: this.generateRuleSuggestions(tool, input)
    };
  }

  private static findMatchingRule(
    tool: ToolDefinition,
    input: any,
    rules: Record<PermissionRuleScope, string[]>
  ): string | null {
    // ä¼˜å…ˆçº§é¡ºåºï¼šcliArg > localSettings > projectSettings > ...
    const scopes: PermissionRuleScope[] = [
      'cliArg', 'localSettings', 'projectSettings',
      'policySettings', 'userSettings'
    ];

    for (const scope of scopes) {
      const scopeRules = rules[scope] || [];
      for (const rule of scopeRules) {
        if (this.matchesRule(tool, input, rule)) {
          return `${scope}:${rule}`;
        }
      }
    }

    return null;
  }
}
```

### é˜¶æ®µ 6ï¼šé€’å½’å›åˆç®¡ç†

æ§åˆ¶æµä¸ºå¤šè½®äº¤äº’å®ç°äº†å°¾é€’å½’ï¼š

```typescript
// é€’å½’æ§åˆ¶å’ŒçŠ¶æ€ç®¡ç†
class TurnController {
  static async *manageTurn(
    messages: CliMessage[],
    toolResults: CliMessage[],
    context: FullContext,
    loopState: LoopState
  ): AsyncGenerator<CliMessage> {
    // æ£€æŸ¥é€’å½’æ·±åº¦
    if (loopState.turnCounter >= 10) {
      yield this.createSystemMessage(
        "Maximum conversation depth reached. Please start a new query."
      );
      return;
    }

    // å‡†å¤‡ä¸‹ä¸€è½®çŠ¶æ€
    const nextState = {
      ...loopState,
      turnCounter: loopState.turnCounter + 1,
      compacted: false  // é‡ç½®å‹ç¼©æ ‡å¿—
    };

    // åˆå¹¶æ¶ˆæ¯ä»¥è¿›è¡Œä¸‹ä¸€è½®
    const nextMessages = [
      ...messages,
      ...toolResults.sort(this.sortByToolRequestOrder)
    ];

    // å°¾é€’å½’
    yield* tt(
      nextMessages,
      context.basePrompt,
      context.gitContext,
      context.claudeMd,
      context.permissionFn,
      context.toolContext,
      undefined,  // æ²¡æœ‰æ´»åŠ¨çš„æµå¼å·¥å…·
      nextState
    );
  }
}
```

## é«˜çº§æ§åˆ¶æµæ¨¡å¼

### 1. è¾“å…¥è·¯ç”±çŠ¶æ€æœº

è¾“å…¥å¤„ç†å®ç°äº†ä¸€ä¸ªå¤æ‚çš„è·¯ç”±ç³»ç»Ÿï¼š

```mermaid
stateDiagram-v2
    [*] --> InputReceived
    InputReceived --> CommandDetection

    CommandDetection --> SlashCommand: starts with /
    CommandDetection --> BashMode: starts with !
    CommandDetection --> MemoryMode: starts with #
    CommandDetection --> PasteDetection: paste event
    CommandDetection --> NormalPrompt: default

    SlashCommand --> ExecuteCommand
    ExecuteCommand --> UpdateState
    UpdateState --> [*]

    BashMode --> CreateSyntheticTool
    CreateSyntheticTool --> MainLoop

    MemoryMode --> UpdateClaudeMd
    UpdateClaudeMd --> [*]

    PasteDetection --> DetectContent
    DetectContent --> ProcessImage: image detected
    DetectContent --> ProcessText: text only
    ProcessImage --> MainLoop
    ProcessText --> MainLoop

    NormalPrompt --> MainLoop
    MainLoop --> [*]
```

```typescript
// è¾“å…¥è·¯ç”±å™¨å®ç°
class InputRouter {
  static async routeInput(
    input: string,
    context: AppContext
  ): Promise<RouterAction> {
    // å¸¦ä¼˜å…ˆçº§çš„å‘½ä»¤æ£€æµ‹
    const matchers: [RegExp, InputHandler][] = [
      [/^\/(\w+)(.*)/, this.handleSlashCommand],
      [/^!(.+)/, this.handleBashMode],
      [/^#(.+)/, this.handleMemoryMode],
      [/^```[\s\S]+```$/, this.handleCodeBlock],
    ];

    for (const [pattern, handler] of matchers) {
      const match = input.match(pattern);
      if (match) {
        return handler(match, context);
      }
    }

    // é»˜è®¤ï¼šæ­£å¸¸æç¤º
    return {
      type: 'prompt',
      message: this.createUserMessage(input)
    };
  }

  private static handleBashMode(
    match: RegExpMatchArray,
    context: AppContext
  ): RouterAction {
    const command = match[1];

    // åˆ›å»ºå¸¦å·¥å…·ä½¿ç”¨çš„åˆæˆåŠ©æ‰‹æ¶ˆæ¯
    const syntheticMessages = [
      {
        type: 'user',
        message: {
          role: 'user',
          content: `Run this command: ${command}`
        }
      },
      {
        type: 'assistant',
        message: {
          role: 'assistant',
          content: [
            {
              type: 'text',
              text: 'I\'ll run that command for you.'
            },
            {
              type: 'tool_use',
              id: `bash_${Date.now()}`,
              name: 'BashTool',
              input: { command, sandbox: false }
            }
          ]
        }
      }
    ];

    return {
      type: 'synthetic_conversation',
      messages: syntheticMessages
    };
  }
}
```

### 2. æµèƒŒå‹ç®¡ç†

æµå¼ç³»ç»Ÿå®ç°äº†å¤æ‚çš„èƒŒå‹å¤„ç†ï¼š

```typescript
// æµçš„èƒŒå‹æ§åˆ¶
class StreamBackpressureController {
  private buffer: Array<StreamEvent> = [];
  private pressure = {
    current: 0,
    threshold: 1000,  // æœ€å¤§ç¼“å†²äº‹ä»¶æ•°
    paused: false
  };

  async *controlledStream(
    source: AsyncIterable<StreamEvent>
  ): AsyncGenerator<StreamEvent> {
    const iterator = source[Symbol.asyncIterator]();

    while (true) {
      // æ£€æŸ¥å‹åŠ›
      if (this.pressure.current > this.pressure.threshold) {
        this.pressure.paused = true;
        await this.waitForDrain();
      }

      const { done, value } = await iterator.next();
      if (done) break;

      // ç¼“å†²åŒºç®¡ç†
      if (this.shouldBuffer(value)) {
        this.buffer.push(value);
        this.pressure.current++;
      } else {
        // é«˜ä¼˜å…ˆçº§äº‹ä»¶ç«‹å³äº§å‡º
        yield value;
      }

      // å®šæœŸæ’ç©ºç¼“å†²åŒº
      if (this.buffer.length > 0 && !this.pressure.paused) {
        yield* this.drainBuffer();
      }
    }

    // æœ€åæ’ç©º
    yield* this.drainBuffer();
  }

  private shouldBuffer(event: StreamEvent): boolean {
    // ä¸ç¼“å†²å·¥å…·ç»“æœæˆ–é”™è¯¯
    return event.type === 'content_block_delta' &&
           event.delta.type === 'text_delta';
  }
}
```

### 3. AgentTool åˆ†å±‚æ§åˆ¶æµ

AgentTool å®ç°äº†ä¸€ä¸ªæœ‰è¶£çš„çˆ¶å­æ§åˆ¶ç»“æ„ï¼š

```mermaid
graph TB
    subgraph "ä¸»ä»£ç†"
        MainTT[Main tt Loop]
        MainContext[Main Context]
        MainTools[All Tools]
    end

    subgraph "AgentTool è°ƒç”¨"
        AgentRequest[AgentTool Request]
        TaskSplitter[Task Splitter]

        TaskSplitter --> SubTask1[Sub-task 1]
        TaskSplitter --> SubTask2[Sub-task 2]
        TaskSplitter --> SubTaskN[Sub-task N]
    end

    subgraph "å­ä»£ç† 1"
        SubLoop1[Sub tt Loop]
        SubContext1[Filtered Context]
        SubTools1[Tools - AgentTool]
    end

    subgraph "å­ä»£ç† 2"
        SubLoop2[Sub tt Loop]
        SubContext2[Filtered Context]
        SubTools2[Tools - AgentTool]
    end

    subgraph "ç»¼åˆ"
        Collector[Result Collector]
        Synthesizer[LLM Synthesizer]
        FinalResult[Synthesized Result]
    end

    MainTT --> AgentRequest
    AgentRequest --> TaskSplitter

    SubTask1 --> SubLoop1
    SubTask2 --> SubLoop2

    SubLoop1 --> Collector
    SubLoop2 --> Collector

    Collector --> Synthesizer
    Synthesizer --> FinalResult
    FinalResult --> MainTT
```

```typescript
// AgentTool åˆ†å±‚æ‰§è¡Œ
class AgentToolExecutor {
  static async *execute(
    input: AgentToolInput,
    context: ToolUseContext,
    parentMessage: CliMessage
  ): AsyncGenerator<ToolProgress | ToolResult> {
    // é˜¶æ®µ 1ï¼šä»»åŠ¡åˆ†æ
    const subtasks = this.analyzeTask(input.prompt);

    // é˜¶æ®µ 2ï¼šç”Ÿæˆå­ä»£ç†
    const subAgentPromises = subtasks.map(async (task, index) => {
      // åˆ›å»ºéš”ç¦»çš„ä¸Šä¸‹æ–‡
      const subContext = {
        ...context,
        tools: context.tools.filter(t => t.name !== 'AgentTool'),
        abortController: this.createLinkedAbort(context.abortController),
        options: {
          ...context.options,
          maxThinkingTokens: this.calculateTokenBudget(input.prompt)
        }
      };

      // è¿è¡Œå­ä»£ç†
      return this.runSubAgent(task, subContext, index);
    });

    // é˜¶æ®µ 3ï¼šå¸¦è¿›åº¦çš„å¹¶è¡Œæ‰§è¡Œ
    const results: SubAgentResult[] = [];
    for await (const update of this.trackProgress(subAgentPromises)) {
      if (update.type === 'progress') {
        yield {
          type: 'progress',
          toolUseID: parentMessage.id,
          data: update
        };
      } else {
        results.push(update.result);
      }
    }

    // é˜¶æ®µ 4ï¼šç»¼åˆ
    const synthesized = await this.synthesizeResults(results, input);

    yield {
      type: 'result',
      data: synthesized
    };
  }

  private static async synthesizeResults(
    results: SubAgentResult[],
    input: AgentToolInput
  ): Promise<string> {
    if (results.length === 1) {
      return results[0].content;
    }

    // é€šè¿‡ LLM è¿›è¡Œå¤šç»“æœç»¼åˆ
    const synthesisPrompt = `
      Synthesize these ${results.length} findings into a cohesive response:
      ${results.map((r, i) => `Finding ${i+1}:\n${r.content}`).join('\n\n')}

      Original task: ${input.prompt}
    `;

    const synthesizer = new SubAgentExecutor({
      prompt: synthesisPrompt,
      model: input.model || 'claude-3-haiku',  // ä½¿ç”¨å¿«é€Ÿæ¨¡å‹è¿›è¡Œç»¼åˆ
      isSynthesis: true
    });

    return synthesizer.run();
  }
}
```

### 4. é”™è¯¯æ¢å¤æ§åˆ¶æµ

ç³»ç»Ÿå®ç°äº†å¤æ‚çš„é”™è¯¯æ¢å¤ç­–ç•¥ï¼š

```typescript
// é”™è¯¯æ¢å¤çŠ¶æ€æœº
class ErrorRecoveryController {
  private static recoveryStrategies = {
    'rate_limit': this.handleRateLimit,
    'context_overflow': this.handleContextOverflow,
    'tool_error': this.handleToolError,
    'network_error': this.handleNetworkError,
    'permission_denied': this.handlePermissionDenied
  };

  static async *handleError(
    error: any,
    context: ErrorContext
  ): AsyncGenerator<CliMessage> {
    const errorType = this.classifyError(error);
    const strategy = this.recoveryStrategies[errorType];

    if (strategy) {
      yield* strategy(error, context);
    } else {
      // é€šç”¨é”™è¯¯å¤„ç†
      yield this.createErrorMessage(error);
    }
  }

  private static async *handleContextOverflow(
    error: ContextOverflowError,
    context: ErrorContext
  ): AsyncGenerator<CliMessage> {
    // ç­–ç•¥ 1ï¼šå°è¯•å‡å°‘ max_tokens
    if (error.details.requested_tokens > 4096) {
      yield this.createSystemMessage("Reducing response size...");

      const retry = await this.retryWithReducedTokens(
        context.request,
        Math.floor(error.details.requested_tokens * 0.7)
      );

      if (retry.success) {
        yield* retry.response;
        return;
      }
    }

    // ç­–ç•¥ 2ï¼šå¼ºåˆ¶å‹ç¼©
    yield this.createSystemMessage("Compacting conversation history...");
    const compacted = await this.forceCompaction(context.messages);

    // ä½¿ç”¨å‹ç¼©çš„å†å²é‡è¯•
    yield* this.retryWithMessages(compacted, context);
  }

  private static async *handleRateLimit(
    error: RateLimitError,
    context: ErrorContext
  ): AsyncGenerator<CliMessage> {
    // å¤šæä¾›å•†å›é€€
    const providers = ['anthropic', 'bedrock', 'vertex'];
    const current = context.provider;
    const alternatives = providers.filter(p => p !== current);

    for (const provider of alternatives) {
      yield this.createSystemMessage(
        `Rate limited on ${current}, trying ${provider}...`
      );

      try {
        const result = await this.retryWithProvider(
          context.request,
          provider
        );
        yield* result;
        return;
      } catch (e) {
        continue;
      }
    }

    // æ‰€æœ‰æä¾›å•†éƒ½è€—å°½
    yield this.createErrorMessage(
      "All providers are rate limited. Please try again later."
    );
  }
}
```

## æ€§èƒ½åˆ†æç‚¹

æ§åˆ¶æµåŒ…å«äº†æˆ˜ç•¥æ€§çš„åˆ†æç‚¹ï¼š

```typescript
// æ€§èƒ½æµ‹é‡é›†æˆ
class PerformanceProfiler {
  private static spans = new Map<string, PerformanceSpan>();

  static instrument<T extends AsyncGenerator>(
    name: string,
    generator: T
  ): T {
    return (async function* () {
      const span = tracer.startSpan(name);
      const start = performance.now();

      try {
        let itemCount = 0;
        for await (const item of generator) {
          itemCount++;

          // æµ‹é‡äº§å‡ºé—´éš”æ—¶é—´
          if (itemCount > 1) {
            span.addEvent('yield', {
              'yield.latency': performance.now() - lastYield
            });
          }

          yield item;
          lastYield = performance.now();
        }

        span.setAttributes({
          'generator.yield_count': itemCount,
          'generator.total_time': performance.now() - start
        });
      } finally {
        span.end();
      }
    })() as T;
  }
}
```
