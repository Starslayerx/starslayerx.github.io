{"categories":[],"pages":[],"posts":[{"link":"/posts/redis-bitmap/","text":"Bitmap 位图 Redis 的位图 bitmap 是由多个二进制位组成的数组, 数组中的每个二进制都有与之对应的偏移量(索引), 用户通过这些偏移量可以对位图中指定的一个或多个二进制位进行操作.\nRedis 为位图提供了一系列操作命令, 通过这些命令, 用户可以:\n设置或获取索引位上的二进制值 统计位图中有多少个二进制位被设置成了1 查找位图中, 第一个被设置为指定值的二进制位, 并返回其偏移量 对一个或多个位图执行逻辑并、逻辑或、逻辑异或以及逻辑非运算 将指定类型的整数存储到位图中 SETBIT: 设置二进制位的值 REDIS Collapse Copy SETBIT bitmap offset value Click to expand and view more 为位图指定偏移量上的二进制位设置值, 该命令会返回二进制位被设置之前的旧值作为结果.\n当执行 SETBIT 时, 如果位图不存在, 或者位图当前的大小无法满足用户想要执行的设置操作, 那么 Redis 将对被设置的位图进行扩展, 使得位图可以满足用户的设置请求. 由于位图的扩展以字节为单位, 所以扩展后的位图包含的二进制数量可能会比用户要求的稍多一些. 且在扩展的同时, 会将未设置的二进制位初始化为 0.\n与一些可以使用负数的 Redis 命令不同, SETBIT 命令只能使用正数偏移量, 尝试输入负数作为偏移量将引发一个错误\n复杂度: O(1) GETBIT: 获取二进制位的值 REDIS Collapse Copy GETBIT bitmap offset Click to expand and view more 与 SETBIT 命令一样, GETBIT 命令也只能接受正数作为偏移量.\n对于偏移量超过位图索引的命令, GETBIT 命令将返回 0 作为结果.\n复杂度: O(1) BITOCUNT: 统计被设置的二进制数量 REDIS Collapse Copy BITCOUNT key Click to expand and view more 对于值为 10010100 的位图 bitmap001, 可以通过执行以下命令来统计有多少个二进制位被设置成了1:\nREDIS Collapse Copy BITCOUNT bitmap001 (integer) 3 -- 这个位图有 3 个二进制位为 1 Click to expand and view more 此外, 还可以只统计位图指定直接范围内的二进制位\nREDIS Collapse Copy BITCOUNT bitmap [start end] Click to expand and view more start 参数和 end 参数与本章之前介绍的 SETBIT 命令和 GETBIT 命令的 offset 参数并不相同, 这两个参数用来指定字节偏移量而不是二进制位偏移量.\n例如通过以下命令计算位图 bitmap003 中第一个字节中 有多少个 1:\nREDIS Collapse Copy BITCOUNT bitmap003 0 0 Click to expand and view more BITCOUNT 命令的 start 参数和 end 参数的值不久可以是正数, 还可以是负数:\nREDIS Collapse Copy BITCOUNT bitmap003 -1 -1 Click to expand and view more 上面命令统计位图 bitmap003 最后一个字节中 1 的数量.\n复杂度: O(N) 示例: 用户行为记录器 为了分析用户行为并借此改善服务质量, 很多网站都会记录用户在网站的一举一动. 为此, 可以使用集和 Set 或者 HyperLogLog 来记录所有执行了指定行为的用户, 但这种做法有两种缺陷:\n如果使用集和来记录执行了指定行为的用户, 那么集和体积会随着用户数量的增大而变大, 从而消耗大量内存 如果使用 HyperLogLog 可以节约大量内存, 但由于其只是一个概率算法, 因此只能给出一个估算值. 并无法准确判断某个用户是否执行了这些指定行为, 这对精确分析算法带来了麻烦. 为了尽可能节约内存, 并精确记录每个用户是否执行了指定行为, 可以使用以下方法:\n对于每项行为, 一个用户要么执行了该行为, 要么没有执行该行为. 因此可以通过一个二进制位来记录. 通过将用户 ID 与位图中的二进制偏移量一一映射, 可以使用一个位图来记录所有执行了指定行为的用户: 比如偏移量为 10086 的二进制位就负责记录 ID 位 10086 的用户信息, 而偏移量位 12345 的二进制位则负责记录 ID 位 12345 的用户信息. 每当用户执行指定行为时, 调用 SETBIT 命令, 将用户在位图中对应的二进制位的值设置为 1 通过调用 GETBIT 命令并判断用户对应的二进制的值是否位1, 可以知道用户是否执行了指定行为 通过对位图执行 BITCOUNT 命令, 可以知道多少用户执行了指定行为 PYTHON Collapse Copy from redis import Redis def make_action_key(action): return \u0026#34;action_reorder::\u0026#34; + action class ActionRecorder: def __init__(self, client, action): self.client= client self.bitmap = make_action_key(action) def perform_by(self, user_id): \u0026#34;\u0026#34;\u0026#34;记录执行了指定行为的用户\u0026#34;\u0026#34;\u0026#34; self.client.setbit(self.bitmap, user_id) def is_performed_by(self, user_id): \u0026#34;\u0026#34;\u0026#34;检查用户是否执行了指定行为\u0026#34;\u0026#34;\u0026#34; return self.client.getbit(self.bitmap, user_id) def count_performed(self): \u0026#34;\u0026#34;\u0026#34;返回执行了指定行为的用户人数\u0026#34;\u0026#34;\u0026#34; return self.client.bitcount(self.bitmap) client = Redis() login_action = ActionRecorder(client, \u0026#34;login\u0026#34;) # 对以登陆用户进行记录 login_action.perform_by(10086) login_action.perform_by(255255) login_action.perform_by(987654321) # ID 为 10086 的用户登陆了 print(login_action.is_performed_by(10086)) # ID 为 555 的用户没有登陆 print(login_action.is_performed_by(555)) # 统计用户执行了登陆操作 print(login_action.count_performed()) Click to expand and view more BITPOS: 查找第一个指定的二进制值 REDIS Collapse Copy BITPOS bitmap value Click to expand and view more 例如, 通过下面命令, 可以知道位图 bitmap003 第一个被设置为 1 的二进制位所在的偏移量(索引):\nREDIS Collapse Copy BITPOS bitmap003 1 (integer) 0 -- 位图第一个被设置位 1 的二进制位的偏移量是 0 Click to expand and view more 默认情况下, BITPOS 会查找所有二进制位, 在有需要的情况下, 用户也可以通过可选的 start 参数和 end 参数, 让 BITPOS 命令只在指定字节范围内的二进制位中进行查找:\nREDIS Collapse Copy BITPOS bitmap value [start end] Click to expand and view more 返回结果为查找到位的整体偏移量, 而不是在 start 和 end 内的偏移量.\n和 BITCOUNT 命令以, BITPOS 命令的 start 和 end 参数也可以是负数.\n比如, 下面代码就展示了如何在位图 bitmap003 的倒数第一个字节中, 查找第一个值位 0 的二进制位:\nREDIS Collapse Copy BITPOS bitmap003 0 -1 -1 (integer) 17 Click to expand and view more 当用户尝试对一个不存在的位图或者一个唯有位都位 0 的位图, 执行查找值位 1 的二进制位时, BITPOS 命令将返回 -1 作为结果:\nREDIS Collapse Copy BITPOS not-exists-bitmap 1 -- 在不存在的位图中查找 (integer) -1 BITPOS all-0-bitmap 1 -- 在一个所有位都被设置为 0 的位图查找 (integer) -1 Click to expand and view more 复杂度: O(N), 其中 N 为查找涉及的字节数量 BITOP: 执行二进制位运算 用户可以通过 BITOP 命令, 对一个或多个位图执行指定的二进制位运算, 并将运算结果存储到指定的键中\nREDIS Collapse Copy BITOP operation result_key bitmap [bitmap ...] Click to expand and view more 其中, operation 参数值可以是 AND, OR, XOR, NOT 中的任意一个, 这 4 个值分别对应逻辑并、逻辑或、逻辑异或和逻辑非4种运算, 其中 AND, OR, XOR 这 3 种运算允许用户使用任意数量的位图作为输入, 而 NOT 只允许一个位图作为输入. BITOP 命令这将计算结果存储到指定键中后, 会返回被存储位图的字节长度.\n例如, 通过以下命令, 对位图 bitmap001, bitmap002, bitmap003 执行逻辑并运算, 然后将结果存储到键 and_result 中:\nPLAINTEXT Collapse Copy BITOP ADD and_result bitmap001 bitmap002 bitmap003 (integer) 3 -- 运算结果 and_result 位图的长度为 3 字节 Click to expand and view more 当 BITOP 命令在对两个长度不同的位图执行运算时, 会将长度较短的那个位图中不存在的二进制位看作 0.\n复杂度: O(N), 其中 N 位计算涉及的字节总数量 BITFIELD: 在位图中存储整数值 BITFIELD 命令允许用户在位图中的任意区域 field 存储指定长度的整数值, 并对这些整数值执行加法或减法操作.\nBITFIELD 命令支持 SET, GET, INCRBY, OVERFLOW 这 4 个子命令, 接下来将分别介绍这些子命令.\n根据偏移量对区域进行设置\nREDIS Collapse Copy BITFIELD bitmap SET type offset value Click to expand and view more 通过 SET 子命令, 在位图的指定偏移量 offset 上设置一个 type 类型的整数值 value. 其中:\noffset 参数用于指定设置的起始偏移量. 这个偏移量从 0 开始计算, 偏移量为 0 表示设置从位图的第 1 个二进制开始 type 参数用于指定被设置值的类型, 这个参数需要以 i 或 u 为前缀, 后跟被设置值的位长度 value 参数用于指定被设置的整数值, 这个值的类型应该和 type 参数指定的类型一致. 如果给定值的长度超过了 type 指定的类型, 那么将根据 type 参数指定的类型阶段给定值 举个例子, 下面命令, 从偏移量 0 开始, 这只一个8位长的无符号整数值 198\nREDIS Collapse Copy BITFIELD bitmap SET u8 0 198 (integer) 0 Click to expand and view more 从结果可以知道, 该位图之前存储的结果为 0.\nBITFIELD 命令允许用户在一次调用中执行多个子命令\nREDIS Collapse Copy BITFIELD bitmap SET u8 0 123 SET i23 20 10086 1) (integer) 198 2) (integer) 0 Click to expand and view more 除了上面介绍的基本功能, 还有一下方法可以实现, 这里不再介绍\n执行加法或减法操作 处理溢出 字符串命令对位图进行操作 ","title":"Redis Bitmap"},{"link":"/posts/redis-hyperloglog/","text":"之前曾介绍过使用 Redis 集和构建唯一计数器, 并将这个计数器用于计算网站的唯一房客 IP. 虽然使用集和实现唯一计数器可以实现该功能, 但这个方法有一个明显的缺陷: 随着被计数元素的不断增多, 唯一计数器占用的内存也会越来越大; 计数器越多, 他们的体积越大, 这一情况就会越严峻.\n以计算唯一访客 IP 为例:\n存储一个 IPv4 格式的 IP 地址最多需要 15 个字节 根据网站的规模不同, 每天出现的唯一 IP 可能会有数十万、数百万个 为了记录网站在不同时期的访客, 并进行相关的数据分析, 网站可能需要次序地记录每天的唯一访客 IP 数量 综上, 如果一个网站想要长时间记录访客 IP, 就必须创建多个唯一计数器. 如果访客比较多, 那么它创建的每个唯一计数器都将包含大量元素, 并因此占用相当一部分内存.\n为了高效解决计算机唯一访客 IP 数量这类问题, 其中一种方法就是 HyperLogLog.\nHyperLogLog 简介 HyperLogLog 是一个专门为了计算集和的基数而创建的概率算法, 对于一个给定的集和, HyperLogLog 可以计算出这个集合的近似基数: 近似基数并非集和的实际基数, 它可能会比实际的基数大一点或者小一点, 但误差会在一个合理范围内. 因此, 那些不需要知道实际基数的程序就可以把这个近似基数当作集合的基数来使用.\nHyperLogLog 的优点在于计算近似基础所需的内存并不会因为集和的大小而改变, 无论集和包含元素有多少个, HyperLogLog 进行计算所需的内存总是固定的, 无论集和包含元素多少个, HyperLogLog 进行计算所需的内存总是固定的, 并且是非常少的.\nPFADD: 对集和元素进行计数 REDIS Collapse Copy PFADD hyperloglog element [element ...] Click to expand and view more 根据给定元素是否已经进行过计数, PFADD 命令可能返回0, 也可能返回1:\n如果给定的所有元素都已经计数, 那么 PFADD 命令返回 0, 表示 HyperLogLog 计算出是近似基数没有发生变化 如果给定的的元素中出现了至少一个没有过进行计数的元素, 导致 HyperLogLog 计算出的近似基数发生了变化, 那么 PFADD 命令返回 1 复杂度: O(N), N 为给定元素数量\nPFCOUNT: 返回集和的近似基数 REDIS Collapse Copy PFCOUNT hyperloglog [hyperloglog ...] Click to expand and view more 使用 PFADD 命令对元素进行计数后, 用户可以通过执行 PFCOUNT 命令来获取 HyperLogLog 为集和计算出的近似基数.\n当用户给定的 HyperLogLog 不存在时, PFCOUNT 命令将返回 0 作为结果.\n当用户向 PFCOUNT 传入多个 HyperLogLog 时, PFCOUNT 命令将对所有给定的 HyperLogLog 执行并行计算, 然后返回并集计算出的近似基数.\nREDIS Collapse Copy PFADD alphabets1 \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34; PFADD alphabets2 \u0026#34;c\u0026#34; \u0026#34;d\u0026#34; \u0026#34;e\u0026#34; PFCOUNT alphabets1 alphabets2 \u0026gt; (integer) 5 Click to expand and view more 上面计算类似于\nREDIS Collapse Copy PFADD temp-hyperloglog \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34; \u0026#34;c\u0026#34; \u0026#34;d\u0026#34; \u0026#34;e\u0026#34; PFCOUNT temphyperloglog temp-hyperloglog \u0026gt; (integer) 5 Click to expand and view more 示例: 优化唯一计数器 PYTHON Collapse Copy from redis import Redis class UniqueCounter: def __init__(self, client, key): self.client = client self.key = key def count_in(self, item): \u0026#34;\u0026#34;\u0026#34;对给定的元素进行计数\u0026#34;\u0026#34;\u0026#34; self.client.pfadd(self.key, item) def get_result(self): \u0026#34;\u0026#34;\u0026#34;返回计数器的值\u0026#34;\u0026#34;\u0026#34; return self.client.pfcount(self.key) client = Redis(decode_responses=True) counter = UniqueCounter(client, \u0026#39;unique-ip-counter\u0026#39;) # 创建一个唯一 IP 计数器 counter.count_in(\u0026#39;1.1.1.1\u0026#39;) counter.count_in(\u0026#39;2.2.2.2\u0026#39;) counter.count_in(\u0026#39;3.3.3.3\u0026#39;) print(counter.get_result()) counter.count_in(\u0026#39;3.3.3.3\u0026#39;) print(counter.get_result()) Click to expand and view more 通过使用 HyperLogLog 实现的唯一计数器去取代集和实现的唯一计数器, 可以大副降低存储所需的内存.\n示例: 检测重复信息 在构建应用程序的过程中, 经常要处理广告等垃圾信息. 而发送者经常会使用不同的帐号, 发送相同的垃圾信息, 所有一种简单的方法就是找出重复 的信息: 如果两个用户发送了完全相同的信息, 那么这些信息很可能就是垃圾短信.\n判断两段信息是否相同并不是意见容易的事情, 如果使用一般的比较函数, 那复杂度就会很高: O(N*M), 其中 N 为信息的长度, M 为系统目前已有的信息数量.\n为了降低复杂度, 可以使用 HyperLogLog 来记录所有以发送的信息: 每当用户发送一条信息时, 程序就使用 PFADD 命令将这条信息添加到 HyperLogLog 中:\n如果命令返回 1, 说明这条信息未出现过 如果命令返回 0, 说明这条信息已出现过 由于 HyperLogLog 是概率算法, 所以即使信息长度非常长, HyperLogLog判断信息是否重复所需的时间也非常短.\nPYTHON Collapse Copy from redis import Redis class DuplicateChecker: def __init__(self, client, key): self.client = client self.key = key def is_duplicated(self, content): \u0026#34;\u0026#34;\u0026#34;在信息重复时返回 True, 未重复时返回 False\u0026#34;\u0026#34;\u0026#34; return self.client.pfadd(self.key, content) == 0 def unique_count(self): \u0026#34;\u0026#34;\u0026#34;返回检测器已经检查过的非重复信息数量\u0026#34;\u0026#34;\u0026#34; return self.client.pfcount(self.key) client = Redis(decode_responses=True) checker = DuplicateChecker(client, \u0026#39;duplicate-message-checker\u0026#39;) # 输入非重复信息 checker.is_duplicated(\u0026#34;hello world!\u0026#34;) checker.is_duplicated(\u0026#34;good morning!\u0026#34;) checker.is_duplicated(\u0026#34;bye bye\u0026#34;) print(checker.unique_count()) checker.is_duplicated(\u0026#34;hello world!\u0026#34;) Click to expand and view more PFMERGE: 计算多个 HyperLogLog 的并集 REDIS Collapse Copy PFMERGE destination hyperloglog [hyperloglog ...] Click to expand and view more 该命令可以对多个给定的 HyperLogLog 执行并行计算, 然后把计算得出的并集 HyperLogLog 保存到指定的键中.\n如果指定的键已存在, 则会覆盖原有的键, 执行成功后返回 OK.\nHyperLogLog 并集计算的近似基数接近于所有给定 HyperLogLog 的被计数集合的并集基数.\nREDIS Collapse Copy PFADD numbers1 128 256 512 PFADD numbers2 128 256 512 PFADD numbers3 128 512 1024 PFMERGE union-numbers numbers1 numbers2 numbers3 \u0026gt; OK PFCOUNT union-numbers \u0026gt; (integer) 4 Click to expand and view more PFCOUNT 与 PFMERGE PFCOUNT 命令在计算多个 HyperLogLog 的近似基数时会执行以下操作:\n在内部调用 PFMERGE 命令, 计算所有给定 HyperLogLog 的并集, 并将这个并集存储到一个临时的 HyperLogLog 中 对临时的 HyperLogLog 执行 PFCOUNT 命令, 得到它的近似基数 删除临时 HyperLogLog 向用户返回之前得到的近似基数 示例: 实现每周/月度/年度计数器 通过 PFMERGE 命令可以对多个 HyperLogLog 实现的唯一计数器执行并集计算, 从而实现每周/月度/年度计数器:\n通过对一周内每天的唯一访客 IP 计数器执行 PFMERGE 命令, 可以计算出那一周的唯一访客 IP 数量 通过对一个月每天的唯一访客 IP 计数器执行 PFMERGE 命令, 可以计数器那一个月的唯一访客 IP 数量 年度甚至更长时间的唯一访客 IP 数量也可以按照类似的方法计算 PYTHON Collapse Copy from redis import Redis class UniqueCounterMerger: def __init__(self, client): self.client = client def merge(self, destination, *hyperloglogs): self.client.pfmerge(destination, *hyperloglogs) client = Redis(decode_response=True) merger = UniqueCounterMerger(client) # 本周 7 天的计数器排名 counters = [ \u0026#39;unique_ip_counter:8-10\u0026#39;, \u0026#39;unique_ip_counter:8-11\u0026#39;, \u0026#39;unique_ip_counter:8-12\u0026#39;, \u0026#39;unique_ip_counter:8-13\u0026#39;, \u0026#39;unique_ip_counter:8-14\u0026#39;, \u0026#39;unique_ip_counter:8-15\u0026#39;, \u0026#39;unique_ip_counter:8-16\u0026#39;, ] # 计算并存储本周的唯一访客 IP 数量 merger.merger(\u0026#39;unique_ip_counter::No_33_week\u0026#39;, *counters) # 去本周的唯一访客 IP 数量 weekly_unique_visitors = client.pfcount(\u0026#39;unique_ip_counter::No_33_week\u0026#39;) print(f\u0026#34;本周唯一访客 IP 数量: {weekly_unique_visitors}\u0026#34;) Click to expand and view more ","title":"Redis HyperLogLog"},{"link":"/posts/morden-javascript-tutorial-part-1-fundamentals-06~10/","text":"2.6 Interaction: alert, prompt, confirm Will introduce alert, prompt and confirm in this chapter.\nalert It shows a message and waits for the user to press \u0026ldquo;OK\u0026rdquo;.\nJAVASCRIPT Collapse Copy alert(\u0026#34;Hello\u0026#34;); Click to expand and view more prompt This function prompt accepts two arguments\nJAVASCRIPT Collapse Copy result = prompt(title, [default]); Click to expand and view more It shows a modal window with a text message, an input field for the visitor, and the buttons OK/Cancel.\ntitle: The text to show the visitor. default: An optional second parameter, the initial value for the input field.\nThe square brackets in syntax [...]\nThe square brackets around default in the syntax above denote that the parameter is optional, not required.\nThe visitor can type something in the prompt input field and press OK. Then we get that text in the result. Or they can cancel the input by pressing Cancel or hitting the Esc key, then we get null as the result.\nFor instance:\nJAVASCRIPT Collapse Copy let age = prompt(\u0026#39;How old are you?\u0026#39;, 100); alert(`You are ${age} years old!`); // You are 100 years old! Click to expand and view more confirm The syntax:\nJAVASCRIPT Collapse Copy result = confirm(question); Click to expand and view more The function confirm shows a model window with a question and two buttons: Ok and Cancel.\nThe result is true if OK is pressed and false otherwise.\nJAVASCRIPT Collapse Copy let isBoss = confirm(\u0026#34;Are you the boss?\u0026#34;); alert( isBoss ); // true if OK is pressed Click to expand and view more 2.7 Type Conversions Most of the time, operators and function automatically convert the values into right type.\nFor example, alert function automatically converts any value to a string to show it. Mathematical operations convert values to numbers.\nString Conversion String conversion happens when we need the string form of a value.\nWe can also call the String(value) function to convert a value to a string.\nJAVASCRIPT Collapse Copy let value = true; alert(typeof value); // boolean value = String(value); // now value is a string \u0026#34;true\u0026#34; alert(typeof value); // string Click to expand and view more A false becomes \u0026quot;false\u0026quot;, null becomes \u0026quot;null\u0026quot;\nNumberic Conversion Numberic conversion is mathematical functions and expressions happens automatically.\nJAVASCRIPT Collapse Copy alert( \u0026#34;6\u0026#34; / \u0026#34;2\u0026#34; ); // 3, strings are converted to numbers Click to expand and view more We can use the Number(value) function t oexplicitly convert a value to a number:\nJAVASCRIPT Collapse Copy let str = \u0026#34;123\u0026#34;; alert(typeof str); // string let num = Number(str); // becomes a number 123 alert(typeof num); // number Click to expand and view more Explicit conversion is usually required when we read a value from a string-based source like a text form but expect a number to be entered.\nIf the string is not a valid number, the result of such a conversion is NaN.\nJAVASCRIPT Collapse Copy let age = Number(\u0026#34;an arbitrary string instead of a number\u0026#34;) alert(age); // NaN, conversion failed Click to expand and view more Value Becomes undefined NaN null 0 true and false 1 and 0 string Whitespaces (includes spaces, tabs, newline etc.) from the start and end are removed. if the remaining string is empty, the result is 0. Otherwise, the number is \u0026ldquo;read\u0026rdquo; from the string. An error gives NaN. Examples:\nJAVASCRIPT Collapse Copy alert( Number(\u0026#34; 123 \u0026#34;) ); // 123 alert( Number(\u0026#34;123z\u0026#34;) ); // NaN alert( Number(true) ); // 1 alert( Number(false) ); // 0 Click to expand and view more Please note that null and undefined behave differently here: null becomes 0 while undefined becomes NaN.\nMost mathematical operators also perform such conversion.\nBoolean Conversion Boolean conversion happens in logical operations but can also be performed explicitly with a call to Boolean(value).\nThe conversion rule:\nValues that are intuitively (直观地) \u0026ldquo;empty\u0026rdquo;, like 0, an empty string, null, undefined, and NaN, become false. Other values become true. JAVASCRIPT Collapse Copy alert( Boolean(1) ); // true alert( Boolean(0) ); // false alert( Boolean(\u0026#34;hello\u0026#34;) ); // true alert( Boolean(\u0026#34;\u0026#34;) ); // false Click to expand and view more Please note: the string with zero \u0026quot;0\u0026quot; is true\nSome languages (PHP) treat \u0026quot;0\u0026quot; as flase. But in JavaScript, a non-empty string is always true.\nJAVASCRIPT Collapse Copy alert( Boolean(\u0026#34;0\u0026#34;) ); // true alert( Boolean(\u0026#34; \u0026#34;) ); // spaces, also true (any non-empty string is true) Click to expand and view more 2.8 Basic operators, maths Terms: \u0026ldquo;unary\u0026rdquo;, \u0026ldquo;binary\u0026rdquo;, \u0026ldquo;operand\u0026rdquo; Let\u0026rsquo;s grasp some common terminology:\nAn operand is what operators are applied to.\nFor instance, in the multiplication of 5 * 2 there are two operands: the left operand is 5 and the right operand is 2.\nSometimes, people call these \u0026ldquo;arguments\u0026rdquo; instead of \u0026ldquo;operands\u0026rdquo;.\nAn operator is unary(单一的) if it has a single operand.\nFor example, the unary negation - reverses the sign of a number\nJAVASCRIPT Collapse Copy let x = 1; x = -x; alert( x ); // -1, unary negation was applied Click to expand and view more An operator is binary if it has two operands.\nThe same minus exists in binary form as well.\nJAVASCRIPT Collapse Copy let x = 1, y = 3; alert( y - x ); // 2, binary minus subtracts values Click to expand and view more Maths The following math operations are supported:\nAddition + Subtraction - Multiplication * Division / Remainder % Exponentiation ** Remainder % The remainder operator %, despite its apperance, is not related to percents.\nThe result of a % b is the remainder of the integer division of a by b.\nJAVASCRIPT Collapse Copy alert( 5 % 2 ); // 1, the remainder of 5 divided by 2 alert( 8 % 3 ); // 2, the remainder of 8 divided by 3 alert( 8 % 4 ); // 0, the remainder of 8 divided by 4 Click to expand and view more Exponentiation ** The exponentiation operator a ** b raises a to the power of b.\nIn school maths, we write that as a $a^b$.\nJAVASCRIPT Collapse Copy alert( 2 ** 2 ); // 4 alert( 2 ** 3 ); // 8 alert( 2 ** 4 ); // 16 Click to expand and view more The exponentiation operator is defined for non-integer numbers as well.\nJAVASCRIPT Collapse Copy alert( 4 ** (1/2) ); // 2 alert( 8 ** (1/3) ); // 2 Click to expand and view more String concatenation with binary + Usually, the plus operator + sums numbers.\nBut, if the binary + is applied to strings, it merges them:\nJAVASCRIPT Collapse Copy let s = \u0026#34;my\u0026#34; + \u0026#34;string\u0026#34;; alert(s); // mystring Click to expand and view more Note that if any operands is a string, then the other one is converted to a string too.\nJAVASCRIPT Collapse Copy alert( \u0026#39;1\u0026#39; + 2 ); // \u0026#34;12\u0026#34; alert( 2 + \u0026#39;1\u0026#39; ); // \u0026#34;21\u0026#34; Click to expand and view more It doesn\u0026rsquo;t matter whether the first operand is a string or the second one.\nHere\u0026rsquo;s a more complex example:\nJAVASCRIPT Collapse Copy alert( 2 + 2 + \u0026#39;1\u0026#39; ); // \u0026#34;41\u0026#34; and not \u0026#34;221\u0026#34; Click to expand and view more Here, operators work one after another. The first + sums two numbers, so it returns 4, then the next + adds the string 1 to it, so it\u0026rsquo;s like 4 + '1' = '41'.\nJAVASCRIPT Collapse Copy alert( \u0026#39;1\u0026#39; + 2 + 2 ); // \u0026#34;122\u0026#34; not \u0026#34;14\u0026#34; Click to expand and view more Here, the first operand is a string, the compiler treats the other two operands as strings too. The 2 gets concatenated to 1, so it\u0026rsquo;s like '1' + 2 = \u0026quot;12\u0026quot; and \u0026quot;12\u0026quot; + 2 = \u0026quot;122\u0026quot;.\nThe binary + is the only operator that supports strings in such a way. Other arithmetic operators work only with numbers and always convert their operands to numbers.\nHere\u0026rsquo;s the demo for subtraction and division:\nJAVASCRIPT Collapse Copy alert( 6 - \u0026#39;2\u0026#39; ); // 4, converts \u0026#39;2\u0026#39; to a number alert( \u0026#39;6\u0026#39; / \u0026#39;2\u0026#39; ); // 3, converts both operands to numbers Click to expand and view more Numberic conversion, unary + The plus + exists in to forms: the binary form that we used above and the unary form.\nThe unary plus or, in other words, the plus operator + applied to a single value, doesn\u0026rsquo;t do anything to numbers. But if the operand is not a number, the unary plus converts it into a number.\nFor example:\nJAVASCRIPT Collapse Copy let x = 1; alert( +x ); // 1 let y = -2; alert( +y ); // -2 // Converts non-numbers alert( +true ); // 1 alert( +\u0026#34;\u0026#34; ); // 0 Click to expand and view more It actually does the same thing as Number(...), but is shorter.\nThe need to convert strings to numbers arises (发生) very often. For example, if we are getting values from HTML form fields, they are usually string. What is we want to sum them?\nThe binary plus would add them as strings:\nJAVASCRIPT Collapse Copy let apples = \u0026#34;2\u0026#34;; let oranges = \u0026#34;3\u0026#34;; alert( apples + oranges ); // \u0026#34;23\u0026#34;, the binary plus concatenates (连接, 结合) strings Click to expand and view more If we want to treat them as numbers, we need to convert and sum them:\nJAVASCRIPT Collapse Copy let apples = \u0026#34;2\u0026#34;; let oranges = \u0026#34;3\u0026#34;; // both values converted to numbers before the binary plus alert( +apples + +oranges); // 5 // longer variant alert( Number(appels) + Number(oranges) ); // 5 Click to expand and view more Operator precedence 运算符优先级 There are many operators in JavaScript. Every operator has a corresponding precedence numberl The one with the lager number executes first. If we precedence is the same, the execution order is from left to right.\nHere’s an extract from the precedence table\nPrecedence Name Sign \u0026hellip; \u0026hellip; \u0026hellip; 14 unary plus + 14 unary negation - 13 exponentiation ** 12 multiplication * 12 division / 11 addition + 11 subtraction - \u0026hellip; \u0026hellip; \u0026hellip; 2 assignment = \u0026hellip; \u0026hellip; \u0026hellip; The \u0026ldquo;unary plus\u0026rdquo; has a priority of 14 which is higher than the 11 of \u0026ldquo;addition\u0026rdquo;. That\u0026rsquo;s why, in the expression \u0026ldquo;+apples + +oranges\u0026rdquo;, unary pluses work before the addition.\nAssignment Let\u0026rsquo;s note that an assignment = is also an operator. It is listed in the precedence table with the very low priority of 2.\nThat\u0026rsquo;s why, when we assign a variable, like x = 2 * 2 + 1, the calculations are down first and then the = is evaluated, storing the result in x.\nJAVASCRIPT Collapse Copy let x = 2 * 2 + 1; alert( x ); // 5 Click to expand and view more Assignment = returns a value\nAll operators in JavaScript return a value. That\u0026rsquo;s obvious of + and -, but also true for =.\nThe call x = value writes the value into x and then returns it.\nJAVASCRIPT Collapse Copy let a = 1; let b = 2; let c = 3 - (a = b + 1); alert( a ); // 3 alert( c ); // 0 Click to expand and view more We should understand how it works, because sometimes we see it in JavaScript libraries.\nAlthough, please don’t write the code like that. Such tricks definitely don’t make code clearer or readable.\nChaining assignments Another interesting feature is the ability to chain assignments:\nJAVASCRIPT Collapse Copy let a, b, c a = b = c = 2 + 2 alert( a ); // 4 alert( b ); // 4 alert( c ); // 4 Click to expand and view more Chained assignments from right to left. First, the rightmost expression 2 + 2 is evaluated and then assigned to the variables on the left: c, b and a. At the end, all the variables share a single value.\nOnce again, for the purposes of readbility it\u0026rsquo;s better to split such code into few lines:\nJAVASCRIPT Collapse Copy c = 2 + 2; b = c; a = b; Click to expand and view more That\u0026rsquo;s easier to read, especially when eye-scaning the code fast.\nModify-in-place We often need to apply an operator to a variable and store the new result in that some variable.\nJAVASCRIPT Collapse Copy let n = 2; n = n + 5; n = n * 2; Click to expand and view more This notation (符号表示; 记号; 标记) can be shortened using the operators += and *=:\nJAVASCRIPT Collapse Copy let n = 2; n += 5; // now n = 7 (same as n = n + 5) n *= 2; // now n = 14 (same as n = n * 2) alert( n ); // 14 Click to expand and view more Short \u0026ldquo;modify-and-assign\u0026rdquo; operators exist for all arithemtical (算术的) and bitwise (位运算的) operations: /=, -=, etc.\nSuch operators have the same precedence as a normal assignment, so they run most other calculations:\nJAVASCRIPT Collapse Copy let n = 2; n *= 3 + 5; // right part evaluated first, same as n *= 8 alert( n ); // 16 Click to expand and view more Increment / decrement Increment ++ incraeses a variable by 1:\nJAVASCRIPT Collapse Copy let counter = 2; counter++; alert( counter ); // 3 Click to expand and view more Decrement -- decreases a variable by 1:\nJAVASCRIPT Collapse Copy let counter = 2; counter--; alert( counter ); // 1 Click to expand and view more Important:\nIncrement / decrement can only be applied to variables. Trying to use it on a value like 5++ will give an error.\nBitwise operators Bitwise operators treat arguments as 32-bit integer numbers and work on the level of their binary representation.\nThese operators are not JavaScript-specific. They are supported in most programming languages.\nAND (\u0026amp;) OR (|) XOR (^) NOT (~) LEFT SHIFT (\u0026lt;\u0026lt;) RIGHT SHIFT (\u0026gt;\u0026gt;) ZERO-FILL RIGHT SHIFT (\u0026gt;\u0026gt;\u0026gt;) Comma The comma operator , is one of the rarest and most unusual operators. Sometiems, it\u0026rsquo;s used to write shorter code, so we need to know in order to understand what\u0026rsquo;s going on.\nThe comma operator allows us to evaluate several expressions, dividing them with a comma ,. Each of them is evaluated but only the result of the last one is returned.\nJAVASCRIPT Collapse Copy let a = (1 + 2, 3 + 4); alert( a ); // 7 Click to expand and view more Comma has a very low precedence\nComma\u0026rsquo;s precedence is lower than =, so parentheses () are important in the example above.\nWithout them: a = 1 + 2, 3 + 4 evaluates + first, summing the numbers into a = 3, 7, then the assignment operator = assigns a = 3, and the rest is ignored. It\u0026rsquo;s like (a = 1 + 2), 3 + 4\nWhy do we need an operator that throws away everyting except the last expression?\nSometimes, people use it in more complex constructs to put several actions in one line.\nJAVASCRIPT Collapse Copy // three operations in one line for (a = 1, b = 3, c = a * b; a \u0026lt; 10; a++) { ... } Click to expand and view more Such tricks are used in many JavaScript frameworks. That\u0026rsquo;s why we\u0026rsquo;re mentioning them. But usually they don\u0026rsquo;t improve code readability so we should think well before using them.\n2.9 Comparisons Comparsions operators in JavaScript:\nGreater/less than: a \u0026gt; b, a \u0026lt; b Greater/less than or equals: a \u0026gt;= b, a \u0026lt;= b Equals: a == b Not equals: a != b In this part we\u0026rsquo;ll learn more about different types of comparsions, how JavaScript makes them, including important peculiarities ( 特性) - \u0026ldquo;JavaScript quirks (小瑕疵, 古怪)\u0026rdquo;\nBoolean is the result All compatison operators return a boolean value:\ntrue: means \u0026ldquo;yes\u0026rdquo; or \u0026ldquo;truth\u0026rdquo; false: means \u0026ldquo;no\u0026rdquo;, \u0026ldquo;wrong\u0026rdquo; or \u0026ldquo;not the truth\u0026rdquo; JAVASCRIPT Collapse Copy alert( 2 \u0026gt; 1 ); // true (correct) alert( 2 == 1 ); // false (wrong) alert( 2 != 1 ); // true (correct) Click to expand and view more String comparison Too see whether a string is greater than another, JavaScript uses the so-called \u0026ldquo;dictionary\u0026rdquo; or \u0026ldquo;lexicographical\u0026rdquo; (按字母排序的) order.\nIn other words, strings are compared letter-by-letter.\nJAVASCRIPT Collapse Copy alert( \u0026#39;Z\u0026#39; \u0026gt; \u0026#39;A\u0026#39; ); // true alert( \u0026#39;Glow\u0026#39; \u0026gt; \u0026#39;Glee\u0026#39; ); //true alert( \u0026#39;Bee\u0026#39; \u0026gt; \u0026#39;Be\u0026#39; ); // true Click to expand and view more The algorithm to compare two strings is simple:\nCompare the first character of both strings. If the first character from the first string is greater (or less) than the other string’s, then the first string is greater (or less) than the second. Otherwise, if both strings’ first characters are the same, compare the second characters the same way. Repeat until the end of either string. If both strings end at the same length, then they are equal. Otherwise, the longer string is greater. Not a real dictionary, but Unicode order\nThe comparison algorithm given above is roughly equivalent to the ons used in dictionaries or phone books, but it\u0026rsquo;s exactly the same.\nFor instance, \u0026ldquo;a\u0026rdquo; is greater than \u0026ldquo;A\u0026rdquo;. Because the lowercase character has a greater index in the internal encoding table JavaScript uses (Unicode).\nComparison of different types When comparing values of different types, JavaScript converts the values to numbers.\nJAVASCRIPT Collapse Copy alert( \u0026#39;2\u0026#39; \u0026gt; 1 ); // true, string \u0026#39;2\u0026#39; becomes a number 2 alert( \u0026#39;01\u0026#39; == 1 ); // true, string \u0026#39;01\u0026#39; becomes a number 1 Click to expand and view more For boolean values, true becomes 1 and false becomes 0.\nJAVASCRIPT Collapse Copy alert( true == 1 ); // true aletr( false == 0 ); // true Click to expand and view more A funny consequence\nIt is possible that at the same time:\nTwo values are equal One of them is true as a boolean and other one is false as a boolean. JAVASCRIPT Collapse Copy let a = 0; alert( Boolean(a) ); // false let b = \u0026#34;0\u0026#34;; alert( Boolean(b) ); // true alert( a == b ); // true! Click to expand and view more Strict equality A regular equal check == has a problem. It cannot different 0 from false.\nJAVASCRIPT Collapse Copy alert( 0 == false ); // true Click to expand and view more The same thing happens with an empty string:\nJAVASCRIPT Collapse Copy alert( \u0026#39;\u0026#39; == false ); // true Click to expand and view more This happens because operands of different types are converted to numbers by the equality operator ==. An empty string, just like false, becomes a zero.\nA strict equality opertaor === checks the equality without type conversion.\nJAVASCRIPT Collapse Copy alert( 0 === false ); // false, because the types are different Click to expand and view more There is also a \u0026ldquo;strict non-equality\u0026rdquo; operator !== analogous 类似 to !=.\nThe strict equality operator is a bit longer to write, but makes it obvious what\u0026rsquo;s going on and leaves less room for errors.\nComparison with null and undefined There\u0026rsquo;s a non-intuitive behavior when null or undefined are compared to other values.\nFor a strict equality check ===\nJAVASCRIPT Collapse Copy alert( null === undefined ); // false Click to expand and view more For a non-strict check ==\nThere\u0026rsquo;s a special rule. These two are a \u0026ldquo;sweet couple\u0026rdquo;: they equal each other (==), but not any other value.\nJAVASCRIPT Collapse Copy alert( null == undefined ); // true Click to expand and view more For maths and other comparisons \u0026lt; \u0026gt; \u0026lt;= \u0026gt;=\nnull/undefined are converted to numbers: null becomes 0, while undefined becomes NaN.\nHere are some funny things.\nStrage result: null vs 0 Let\u0026rsquo;s compare null with a zero:\nJAVASCRIPT Collapse Copy alert( null \u0026gt; 0 ); // (1) false alert( null == 0 ); // (2) false alert( null \u0026gt;= 0 ); // (3) true Click to expand and view more The reason is that an equality check == and comparsions \u0026gt; \u0026lt; \u0026gt;= \u0026lt;= work differently. Comparisons convert null to a number, treating it as 0. That\u0026rsquo;s why (3) null \u0026gt;= 0 is true and (1) null \u0026gt; 0 is false.\nOn the other hand, the equality check == for undefined and null is defined such that, without any conversions, they equal each other and don\u0026rsquo;t equal anyting else. That\u0026rsquo;s why (2) null == 0 is false.\nJAVASCRIPT Collapse Copy alter( null == undefined ); // true alert( Boolean(undefined) ); // false, null 在宽松比较中只等于 undefined 和 自身 alert( Boolean(null) ); // false Click to expand and view more null 和 undefined 在宽松相等比较中, 只彼此相等, 不与任何其他除了自身值相等. An incomparable undefined The value undefined shouldn\u0026rsquo;t be compared to other values:\nPLAINTEXT Collapse Copy alert( undefined \u0026gt; 0 ); // false (1) alert( undefined \u0026lt; 0 ); // false (2) alert( undefined == 0 ); // false (3) Click to expand and view more We get these results because:\nComparsion (1) and (2) return false because undefined gets converted to NaN and NaN is a special numeric value which returns false for all comparisons. The equality check (3) returns false because undefined only equals null, undefined, and no other value. Avoid problems\nTreat any comparison with undefined/null except the strict equality === with exceptional care. Don\u0026rsquo;t use comparisons \u0026gt;= \u0026gt; \u0026lt; \u0026lt;= with a variable which may be null/undefined, unless you\u0026rsquo;re really sure of what you\u0026rsquo;re doing. If a variable can have these values, check for them separately. ","title":"Morden Javascript Tutorial Part 1- Fundamentals :06~10"},{"link":"/posts/morden-javascript-tutorial-part-1-fundamentals-01~05/","text":"2.1 Hellow Wrold Firtly, let\u0026rsquo;s see how to attach a script to a webpage. For server-side environments (like Node.js), you can execute this script with a command like node my.js\nThe \u0026ldquo;script\u0026rdquo; tag JavaScript programs can be inserted almost anywhere into an HTML docuemnt using the \u0026lt;script\u0026gt; tag\nHTML Collapse Copy \u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt; Before this script...\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt; alert( \u0026#39;Hello, World!\u0026#39; ); \u0026lt;/script\u0026gt; \u0026lt;p\u0026gt;...After the script...\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Click to expand and view more The \u0026lt;script\u0026gt; tag contains JavaScript code which is automatically executed when the browser process the tag.\nModern markup The \u0026lt;script\u0026gt; tag has a few attributes that are rarely used nowadays but can still be found in old code:\nThe type attribute: \u0026lt;script type=...\u0026gt; The old HTML standrad, HTML 4, required a script to have a type. Usually it was type=\u0026quot;text/javascript\u0026quot;. It\u0026rsquo;s not required anymore. Also, the modern HTML standrad totally changed the meaning of this attribute. Now, it can be used for JavaScript modules.\nThe language attribute: \u0026lt;script language=...\u0026gt; This attribute was meant to show the language of the script. This attrubute no longer makes sense because JavaScript is the default language. There is no need to use it.\nComments before and after scripts In really ancient books and guides, you may find comments inside \u0026lt;script\u0026gt; tage, like this:\nHTML Collapse Copy \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; \u0026lt;!-- ... //--\u0026gt;\u0026lt;/script\u0026gt; Click to expand and view more This trick isn\u0026rsquo;t used in modern JavaScript. This comments hide JavaScript code from old browser that didn\u0026rsquo;t know how to process the \u0026lt;script\u0026gt; tag. This kind of comment can help you identify really old code.\nExternal scripts If we have a lot of JavaScript code, web can put it into a separate file. Script files are attached to HTML with the src attribute:\nHTML Collapse Copy \u0026lt;script src=\u0026#34;/path/to/script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Click to expand and view more We can use a url as well.\nHTML Collapse Copy \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.11/lodash.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Click to expand and view more To attach serval scripts, use multiple tags:\nHTML Collapse Copy \u0026lt;script src=\u0026#34;/js/script1.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;/js/script2.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Click to expand and view more if src is set, the script content is ignored.\nA single \u0026lt;script\u0026gt; tag can\u0026rsquo;t have both the src attrubute and code inside.\nHTML Collapse Copy \u0026lt;script src=\u0026#34;file.js\u0026#34;\u0026gt; alert(1); // the content is ignored, because src is set \u0026lt;/script\u0026gt; Click to expand and view more We must choose either an external \u0026lt;script src=\u0026quot;...\u0026quot;\u0026gt; or a regulr \u0026lt;script\u0026gt; with code.\nHTML Collapse Copy \u0026lt;script src=\u0026#34;file.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; alert(1); \u0026lt;/script\u0026gt; Click to expand and view more 2.2 Code Structure Statements Statements are syntax constructs and commands that perform actions.\nWe can have as many statements in our code as we want. Statemets can be seperated with a semicolon.\nJAVASCRIPT Collapse Copy alert(\u0026#39;Hello\u0026#39;); alert(\u0026#39;World\u0026#39;); Click to expand and view more Semicolons A Semicolon may be omitted in most cases when a line break exists.\nJAVASCRIPT Collapse Copy alert(\u0026#39;Hello\u0026#39;) alert(\u0026#39;World\u0026#39;) Click to expand and view more Here, JavaScript interprets the line break as an \u0026ldquo;implicit\u0026rdquo; semicolon. This is called an automatic semicolon insertion\nAn example of an error\nJAVASCRIPT Collapse Copy alert(\u0026#34;Hello\u0026#34;); [1, 2].forEach(alert); Click to expand and view more Now remove the semicolon after the alert\nJAVASCRIPT Collapse Copy alert(\u0026#34;Hello\u0026#34;) [1, 2].forEach(alert); Click to expand and view more If we run this code, only the first Hello shows. That\u0026rsquo;s because JavaScript does not assume a semicolor before square brackets [...]. So, the code in the last example is threated as a single statement.\nHere is how the engine see it:\nJAVASCRIPT Collapse Copy alert(\u0026#34;Hello\u0026#34;)[1, 2].forEach(alert); Click to expand and view more It is possible to leave out semicolons most of the time. But it’s safer – especially for a beginner – to use them.\nComments Comments can be put into any place of a script. They don\u0026rsquo;t affect its execution because the engine simply ignores them.\nOne-line comments start with two forward slash characters //.\nJAVASCRIPT Collapse Copy // This comment occupies a line of its own alert(\u0026#39;Hello\u0026#39;); alert(\u0026#39;World\u0026#39;); // This comment follows the statement Click to expand and view more Multiple comments start with a forward slash and an asterisk /* and end with an asterisk adn a forward slash */.\nJAVASCRIPT Collapse Copy /* An example with two messages. This is a multiline comment. */ alert(\u0026#39;Hello\u0026#39;); alert(\u0026#39;World\u0026#39;); Click to expand and view more Nested comments are not supported!\nThere may not be /*...*/ inside another /*...*/\nJAVASCRIPT Collapse Copy /* /* nested comment ?!? */ */ alert( \u0026#39;World\u0026#39; ); Click to expand and view more 2.3 The Morden Mode, \u0026ldquo;use strict\u0026rdquo; For a long time, JavaScript evolved without compatibility issues. New features were add to the language while old functionality didn\u0026rsquo;t change.\nThat had the benefit of never breaking existing code. But the downside was that any mistake or an imperfect descision made by JavaScript\u0026rsquo;s creators got stuck in the language forever.\nThis was the case until 2009 when ECMAScript 5 appered. It add new features to the language and modified some of the existing ones. To keep the old code working, most such modifications are off by default. You need to explicitly enable them with a special directive: \u0026quot;use strict\u0026quot;\n\u0026ldquo;use strict\u0026rdquo; The directive looks like a string: \u0026quot;use strict\u0026quot; or 'use strict'. When it is located at the top or a script, the whole script works the \u0026ldquo;modern\u0026rdquo; way.\nJAVASCRIPT Collapse Copy \u0026#34;use strict\u0026#34; // This code works the morden way Click to expand and view more \u0026quot;use strict\u0026quot; can be put at the beginning of a function. Doing that enables strict mode in that function only. But usually people use it for the whole script.\nEnsure that \u0026ldquo;use strict\u0026rdquo; is at the top.\nAnd there\u0026rsquo;s no way to cancel use strict\nThere is no directive like \u0026quot;no use strict\u0026quot; that reverts the engine to old behavior. Once we enter strict mode, there’s no going back.\nBrowser console When you use a developer console to run code, please note that it doesn’t use strict by default.\nSometimes, when use strict makes a difference, you’ll get incorrect results.\nJAVASCRIPT Collapse Copy \u0026#39;use strict\u0026#39;; // \u0026lt;Shift+Enter for a newline\u0026gt; // ...your code \u0026lt;Enter to run\u0026gt; Click to expand and view more It works in most browsers, namely Firefox and Chrome. If it doesn’t, e.g. in an old browser, there’s an ugly, but reliable way to ensure use strict. Put it inside this kind of wrapper:\nJAVASCRIPT Collapse Copy (function() { \u0026#39;use strict\u0026#39;; // ...your code here... })() Click to expand and view more Should we \u0026ldquo;use strict\u0026rdquo;? The question may sound obvious, but it’s not so.\nOne could recommend to start scripts with \u0026quot;use strict\u0026quot;… But you know what’s cool?\nModern JavaScript suuports \u0026ldquo;classes\u0026rdquo; and \u0026ldquo;modules\u0026rdquo; - advanced language structures, that enable use strict automatically. So we don\u0026rsquo;t need to add the \u0026quot;use strict\u0026quot; directive, if we use them.\nLater, when your code is all in classes and modules, you may omit it.\n2.4 Variables To create a variable in JavaScript, use the let keyward.\nJAVASCRIPT Collapse Copy let messages; Click to expand and view more Now, we can put some data into it by using assignment operator =\nJAVASCRIPT Collapse Copy let message; message = \u0026#39;Hello\u0026#39;; Click to expand and view more To be concise, we can combine the variable declaration and assignment into a single line:\nJAVASCRIPT Collapse Copy let message = \u0026#39;Hello\u0026#39;; Click to expand and view more We can also declare multiple variables in one line:\nJAVASCRIPT Collapse Copy let user = \u0026#39;John\u0026#39;, age = 25, message = \u0026#39;Hello\u0026#39;; Click to expand and view more The multiline variant is a bit longer, but easier to read:\nJAVASCRIPT Collapse Copy let user = \u0026#39;John\u0026#39;; let age = 25; let message = \u0026#39;Hello\u0026#39;; Click to expand and view more Some people also define multiple variables in this multiline style:\nJAVASCRIPT Collapse Copy let user = \u0026#39;John\u0026#39; , age = 25 , message = \u0026#39;Hello\u0026#39;; Click to expand and view more Technically, all these variants do the same thing. So, it’s a matter of personal taste and aesthetics.\nvar instead of let\nIn older scripts, you may also find another keyword: var instead of let:\nJAVASCRIPT Collapse Copy var message = \u0026#39;Hello\u0026#39;; Click to expand and view more The var keyword is almost the same as let. It also declares a variable but in a slight diffent, \u0026ldquo;old-school\u0026rdquo; way.\nThere are subtle differences between let and var, but they do not matter to us yet.\nDeclaring twice triggers an error\nA variable should be declared only once.\nA repeated declaration of the same variable is an error:\nJAVASCRIPT Collapse Copy let message = \u0026#34;This\u0026#34;; // repeated \u0026#39;let\u0026#39; leads to an error let message = \u0026#34;That\u0026#34;; // SyntaxError: \u0026#39;message\u0026#39; has already been declared Click to expand and view more Variable naming There are two limitations on variable names in JavaScript:\nThe name must contain only letters, digits, or symbols $ and -. The first character must not be a digit. JAVASCRIPT Collapse Copy let userName; let test123; Click to expand and view more When the name contains multiple words, camelCase is commonly used. That is: words go one after another, each word execpt first starting with a captital letter: myVeryLongName.\nWhat\u0026rsquo;s intersting - the doller sign $ and the underscore _ can also be used in names. They are regular symbols, just like letters, without any special meaning.\nJAVASCRIPT Collapse Copy let $ = 1; // declared a variable with the name \u0026#34;$\u0026#34; let _ = 2; // and now a variable with the name \u0026#34;_\u0026#34; alert($ + _); // 3 Click to expand and view more Examples of incorrect variable names:\nJAVASCRIPT Collapse Copy let 1a; // cannot start with a digit let my-name; // hyphens \u0026#39;-\u0026#39; aren\u0026#39;t allowed in the name Click to expand and view more Case Matters\nVariables named apple and APPLE are two different variables.\nNon-Latin letters are allowed, but not recommended\nIt is possible to use any language, including Cyrillic letters, Chinese logograms and so on, like this:\nJAVASCRIPT Collapse Copy let имя = \u0026#39;...\u0026#39;; let 我 = \u0026#39;...\u0026#39;; Click to expand and view more Reserved names\nThere is a list of reserved words, which cannot be used as variable names because they are used by the language itself.\nFor example: let, class, return, and function are reserved.\nThe code blew gives a syntax error:\nJAVASCRIPT Collapse Copy let let = 5; // can\u0026#39;t name a variable \u0026#34;let\u0026#34;, error! let return = 5; // also can\u0026#39;t name it \u0026#34;return\u0026#34;, error! Click to expand and view more An assignment without use strict\nNormally, we need to define a variable before using it. But in the old times, it was technically possible to create a variable by a mere assignment of the value without using let. This still works now if we don\u0026rsquo;t put use strict in our script to maintain compatibility with old scripts.\nJAVASCRIPT Collapse Copy // note: no \u0026#34;use strict\u0026#34; in this example num = 5; // the variable \u0026#34;num\u0026#34; is created if it didn\u0026#39;t exist alert(num); // 5 Click to expand and view more This is a bad practice and would cause an error in strict mode:\nJAVASCRIPT Collapse Copy \u0026#34;use strict\u0026#34;; num = 5; // error: num is not defined Click to expand and view more Constants To declare a constant variable, use const instead of let:\nJAVASCRIPT Collapse Copy const myBirthday = \u0026#39;18.04.1982\u0026#39;; Click to expand and view more Variables declared using const are called \u0026ldquo;constants\u0026rdquo;; They cannot be reassigned. An attempt to do so would cause an error:\nJAVASCRIPT Collapse Copy const myBirthday = \u0026#39;18.04.1982\u0026#39;; myBirthday = \u0026#39;01.01.2001\u0026#39;; // error: can\u0026#39;t reassign the constatn! Click to expand and view more When a programmer is sure that a variable will never change, they can declare it with const to guarantee and communicate that fact to everyone.\nUppercase constants There is a widespred pratctice to use constants as aliases for difficult-to-remember values that are known before execution.\nSuch constants are named using capital letters and underscores.\nFor instance, let\u0026rsquo;s make constants for colors in so-called \u0026ldquo;web\u0026rdquo; (hexadecimal) format:\nJAVASCRIPT Collapse Copy const COLOR_RED = \u0026#34;#F00\u0026#34;; const COLOR_GREEN = \u0026#34;#0F0\u0026#34;; const COLOR_BLUE = \u0026#34;#00F\u0026#34;; const COLOR_ORANGE + \u0026#34;#FF7F00\u0026#34;; // ...when we need to pick a color let color = COLOR_ORANGE; alert(color); Click to expand and view more Benefits:\nCOlOR_ORANGE is much easier to understand that \u0026ldquo;#FF7F00\u0026rdquo;. It is much easier to mistype \u0026ldquo;#FF7F00\u0026rdquo; than COLOR_ORANGE. When reading the code, COLOR_ORANGE is much more meaningful than #FF7F00. This is when should we use capitals for a constant:\nBeing a \u0026ldquo;constant\u0026rdquo; just means that a variable\u0026rsquo;s value never changes. But some constants are known before execution and some constants are calculated in run-time, during the execution, but do not change after their initial assignment.\nFor instance:\nJAVASCRIPT Collapse Copy const pageLoadTime = /* time taken by a webpage to load */; Click to expand and view more The value of pageLoadTime is not known before the page load, so it\u0026rsquo;s named normally. But it\u0026rsquo;s still a constant because it doesn\u0026rsquo;t change after the assignment.\nIn other words, capital-named constants are only used as aliases for \u0026ldquo;hard-coded\u0026rdquo; values.\nName things right Talking about variables, there\u0026rsquo;s one more extremely important thing.\nA variable name should have a clean, obvious meaning, describing the data that is stores.\nVariable naming is one of the most important and complex skills in programming. A glance at variable names can reveal which cdoe was written by a beginner versus an experienced developer.\nIn a real project, most of the time is spent modifying and extending an existing code base rather than writing something completely separate from scratch. When we return to some code after doing something else for a while, it\u0026rsquo;s much easier to find information that is well-labelled. Or, in other words, when the variables have good names.\nPlease spend time thinking about the right name for a variable before declaring it. Doing so will repay you handsomely.\nSome good-to-follow rules are:\nUse human-readable names like userName or shoppingCart. Stay away from abbreviations or short names like a, b and c, unless you know what you\u0026rsquo;re doing. Make names maximallly descriptive and concise. Agree on terms within your team and your mind. Reuse or create?\nThere are some lazy programmers who, instead of declaring new variables, tend to reuse existing ones.\nAs a result, their variables are like boxes into which people different things without changding their stickers. What\u0026rsquo;s inside the box now? Who knows? We need to come closer and check.\nSuch programmers save a litte bit on variable declaration but lose ten time more on debugging.\nAn extra variable is good, not evil.\nMorden JavaScript minifiers and browsers optimize code well enough, so it won\u0026rsquo;t create performance issuse. Using different variables for different values can even help engine optimize your code.\n2.5 Data Types A value in JavaScript always of a certain type.\nThere are eight basic types in JavaScript.\nWe can put any type in a variable.\nJAVASCRIPT Collapse Copy // no error let message = \u0026#34;hello\u0026#34;; message = 123456; Click to expand and view more Programming languages that allow such things, such as JavaScript, are called \u0026ldquo;dynamically typed\u0026rdquo;, meaning that there exist data types, but variables are not bound to any of them.\nNumber JAVASCRIPT Collapse Copy let n = 123; n = 12.345; Click to expand and view more The number types represent both intger and floating point numbers.\nThere are many operations for numbers, e.g. multiplication *, division /, addition +, subtraction -, and so on.\nBesides regular numbers, there are so-called \u0026ldquo;special numberic values\u0026rdquo; which also belong to this data type: Infinity, -Infinity and NaN.\nInfinity represents the mathematical infinity ∞. It is a special value that\u0026rsquo;s greater than any number.\nWe can get it as a result of division by zero:\nJAVASCRIPT Collapse Copy alert(0 / 0); // Infinity Click to expand and view more Or just reference it directly:\nJAVASCRIPT Collapse Copy alert( Infinity ); // Infinity Click to expand and view more NaN represents a computational error. It is a result of an incorrect or an undefined mathematical operation, for instance:\nJAVASCRIPT Collapse Copy alert( \u0026#34;not a number\u0026#34; / 2 ); // NaN, such division is erroreous Click to expand and view more NaN is sticky. Any further mathematical operation on NaN returns NaN:\nJAVASCRIPT Collapse Copy alert( NaN + 1 ); // NaN alert( NaN * 3 ); // NaN alert( \u0026#34;not a number\u0026#34; / 2 - 1 ); // NaN Click to expand and view more So, if there\u0026rsquo;s a NaN somewhere in a mathematical expression, it propagates to the whole result.\nThere\u0026rsquo;s one exception to that: NaN ** 0 is 1.\nMathematical operations are safe\nDoing maths is \u0026ldquo;safe\u0026rdquo; in JavaScript. We can do anything: divide by zero, threat non-numeric strings as numbers, etc.\nThe script will never stop with a fatal error (\u0026ldquo;die\u0026rdquo;). At worst, we\u0026rsquo;ll get NaN as the result.\nBigInt In JavaScript, the \u0026ldquo;number\u0026rdquo; type cannot safely represent integer values larger than (2^{53} - 1), or less than -(2^{53} - 1) for negatives.\nTo be really precise, the \u0026ldquo;number\u0026rdquo; type can store larger integer (up to 1.7976931348623157 * 10^{308}), but outside of the safe integer range ±(2^{53}-1) there\u0026rsquo;ll be a precision error, because not all digits fit into the fixed 64-bit storage. So an \u0026ldquo;approximate\u0026rdquo; value may be stored.\nFor example, these two number are the same:\nJAVASCRIPT Collapse Copy console.log(9007199254740991 + 1); // 9007199254740992 console.log(9007199254740991 + 2); // 9007199254740992 Click to expand and view more So to say, all odd integers greater than (2^{53}-1) can’t be stored at all in the “number” type.\nFor most purposes ±(2^{53}-1) range is quite enough, but sometimes we need the entire range of really big integers, e.g. for cryptography or microsecond-precision timestamps.\nBigInt type was recently added to the language to represent integers of arbitrary length.\nA BigInt value is crented by appending n to the end of an integer:\nJAVASCRIPT Collapse Copy // the \u0026#34;n\u0026#34; at the end means it\u0026#39;s a BigInt const bigInt = 1234567890123456789012345678901234567890n; Click to expand and view more As BigInt rarely need, it be won\u0026rsquo;t coverd there. See this BigInt chapter when you need.\nString A string in JavaScript must be surround by qoutes.\nJAVASCRIPT Collapse Copy let str = \u0026#34;Hello\u0026#34;; let str2 = \u0026#39;Single qoutes are ok too\u0026#39;; let phrase = `can embed another ${str}`; Click to expand and view more In JavaScript, there are 3 types of quotes.\nDouble quotes: \u0026quot;Hello\u0026quot; Single quotes: 'Hell' Backtickes: Hello Backticks are \u0026ldquo;extended functionality\u0026rdquo; quotes.\nThey allow us to embed variables and expression into a string be wrapping them in ${...}, for example:\nJAVASCRIPT Collapse Copy let name = \u0026#34;John\u0026#34;; // embed a variable alert( `Hello, ${name}!` ); // Hello, John! // embed an expression alert( `the result is ${1 + 2}` ); // the result is 3 Click to expand and view more The expression inside ${…} is evaluated and the result becomes a part of the string.\nThere is no character type.\nIn some languages, there is a special “character” type for a single character. For example, in the C language and in Java it is called “char”.\nIn JavaScript, there is no such type. There’s only one type: string. A string may consist of zero characters (be empty), one character or many of them.\nBoolean (logical type) The boolean type has only two values: true and false.\nJAVASCRIPT Collapse Copy let nameFieldChecked = true; // yes, name field is checked let ageFieldChecked = false; // no, age field is not checked Click to expand and view more Boolean values also come as a result of comparisons:\nJAVASCRIPT Collapse Copy let isGreater = 4 \u0026gt; 1; alert( isGreater ); // true (the comparison result is \u0026#34;yes\u0026#34;) Click to expand and view more This \u0026ldquo;null\u0026rdquo; value The special null value does not belong to any of the types described above.\nIt forms a separate type of its won which contains only the null values:\nJAVASCRIPT Collapse Copy let age = null; Click to expand and view more In JavaScript, null is not a “reference to a non-existing object” or a “null pointer” like in some other languages.\nThe \u0026ldquo;undefined\u0026rdquo; value The special value undefined also stands apart.\nIt makes a type of its own, just like null.\nThe meaning of undefined is \u0026ldquo;value is not assigned\u0026rdquo;.\nif a variable is declared, but not assigned, then its value is undefined:\nJAVASCRIPT Collapse Copy let age; alert(age); // shows \u0026#34;undefined\u0026#34; Click to expand and view more Technically, it is possible to explicitly assign undefined to a variable:\nJAVASCRIPT Collapse Copy let age = 100; age = undefined; alert(age); // \u0026#34;undefined\u0026#34; Click to expand and view more …But we don’t recommend doing that. Normally, one uses null to assign an “empty” or “unknown” value to a variable, while undefined is reserved as a default initial value for unassigned things.\nObjects and Symbols The object type is special.\nAll other types are called \u0026ldquo;primitive\u0026rdquo; because their values can contain only a single thing. In contrast, objects are used to store collections of data and more complex entities.\nBeing that important, objects deserve a special treatment.\nThe typeof operator The typeof operator returns the type of the operand. (操作数的类型) It\u0026rsquo;s useful when we want to process values of different types differently or just want to do a quick check.\nA call to typeof x returns a string with the type name:\nJAVASCRIPT Collapse Copy typeof undefined // \u0026#34;undefined\u0026#34; typeof 0 // \u0026#34;number\u0026#34; typeof 10n // \u0026#34;bigint\u0026#34; typeof true // \u0026#34;boolean\u0026#34; typeof \u0026#34;foo\u0026#34; // \u0026#34;string\u0026#34; typeof Symbol(\u0026#34;id\u0026#34;) // \u0026#34;symbol\u0026#34; typeof Math // \u0026#34;object\u0026#34; (1) typeof null // \u0026#34;object\u0026#34; (2) typeof alert // \u0026#34;function\u0026#34; (3) Click to expand and view more Math is a build-in object that provides mathematical operations. The result of typeof null is \u0026quot;object\u0026quot;. That\u0026rsquo;s an offically recognized error in typeof, coming from very early days of JavaScript and kept for compatibility. Definitely, null is not an object. It is a special value with a separate type of its own. The result of typeof alert is \u0026quot;function\u0026quot;, because alert is a function. The typeof(x) syntax\ntypeof(x) is the same as typeof x.\nTo put it clear: typeof is an operator, not a function. The parentheses here aren\u0026rsquo;t a part of typeof. It\u0026rsquo;s the kind of parentheses used for mathematical grouping, like (2 + 1), but here they contain only one argument (x).\n","title":"Morden Javascript Tutorial Part 1 - Fundamentals :01~05"},{"link":"/posts/morden-javascript-tutorial-part-1-an-introduction/","text":"An Introduction to JavaScript Let’s see what’s so special about JavaScript, what we can achieve with it, and what other technologies play well with it.\nWhy is it call JavaScript? JavaScript initially called \u0026ldquo;Live Script\u0026rdquo;. But Java was popular at that time, so it was decided that positioning a new language as a \u0026ldquo;younger brother\u0026rdquo; of Java would help. But as it evolved, JavaScript became a fully independent language with its won specification called ECMAScript, and now it has no relation to Java at all.\nToday, JavaScript can execute on any device that has a special program called the JavaScript engine. The browser has an embedded engine called a \u0026ldquo;JavaScript virtual machine\u0026rdquo;.\nDifferent engines hav different \u0026ldquo;codenames\u0026rdquo;:\nV8: in Chrome, Opera and Edge SpiderMonkey: in Firefox What can in-browser JavaScript do? Morden JavaScript is a \u0026ldquo;safe\u0026rdquo; programming language. It does not provide low-level access to memory or CPU, because it was initially created for browsers which do not require it.\nNode.js supports functions that allow JavaScript to read/write arbitrary files, perform network requests, etc. In-browser JavaScript can do everything related to webpage manipulation, interaction with the user, and the webserver.\nAdd new HTML to the page, change the content and modify styles React to user actions like mouse clicks Send network requests Get and set cookies Remember the data on the client-side What can\u0026rsquo;t in-browser JavaScript do? For safety reasons, it can\u0026rsquo;t:\nLimited access to files.\nNo access to OS functions.\nRequire explicit permission with camera/microphone devices.\nDifferent tabs/windows generally do not know about each other.\nThis is called \u0026ldquo;Same Origin Policy\u0026rdquo; (同源策略).\nEasilly communicate over the server where the current page came from.\nIts ability to receive data from other sites/domains is crippled.\nIt requires explicit agreement from the remote side.\nSuch limitations do not exist if JavaScript is used outside of the browser, for example on a server.\nWhat makes JavaScript unique? Full integration with HTML/CSS Simple things are done simply Supported by all major browsers and enabled by default JavaScript is the only browser technology that combines these three things.\nLanguages \u0026ldquo;over\u0026rdquo; JavaScript The syntax of JavaScript not suit everyone\u0026rsquo;s needs. Recently a plethora of new languages appered, which are transpiled to JavaScript before they run in the browser.\nCoffeeScript is \u0026ldquo;syntactic sugar\u0026rdquo; for JavaScript. It introduces shorter syntax, allowing us to write clearer and more precise code. Ruby devs like it. TypeScript is concentrated on add \u0026ldquo;strict data typing\u0026rdquo; to simplify the development and support of complex systems. It\u0026rsquo;s developed by Microsoft. Flow also adds data typing, but in a different way. Developed by Facebook. Dart is a standalone languages that has its own engine that runs in non-browser environments, but also can transpiled to JavaScript. Developed by Google. [Brython] is a Python transpiler to JavaScript but enables the writing of applications in pure Python without JavaScript. [Kotlin] is a modern, concise and safe programming language that target the browser or Node. Developed by JetBrains. Manuals and Specifications Specification The ECMA-262 specification contains the most in-depth, detailed and formalized information about JavaScript.\nA new specification version is released every year. Between these releases, the latest specification draft is at https://tc39.es/ecma262/.\nTo read about new bleeding-edge features, including those that are “almost standard” (so-called “stage 3”), see proposals at https://github.com/tc39/proposals.\nManuals MDN (Mozillz) JavaScript Reference is the main manual with examples and other information. It\u0026rsquo;s great to get in-depth information about individual language functions, methods etc.\nCompatibility tables JavaScript is a developing language, new features get added regularly.\nTo see their support among browser-based and other engines, see:\nhttps://caniuse.com – per-feature tables of support, e.g. to see which engines support modern cryptography functions: https://caniuse.com/#feat=cryptography. https://kangax.github.io/compat-table – a table with language features and engines that support those or don’t support. ","title":"Morden Javascript Tutorial Part 1 - An Introduction"},{"link":"/posts/english-for-programmers-02/","text":"Unit2: Code Review \u0026amp; Testing this unit will cover:\nDifferentiate between various testing strategies Write professional guidelines Sound more natural and smooth when asking questions Use colloquial language in speaking to give and accept feedback vocabulary - None Pharses 词汇: 名词短语 Testing 测试是软件开发中的重要短语, 用于检查软件是否达到特定的标准和用户需求.\n使用这些名词语句来证明英语名词的专业性:\nNone Desciption Example time box an allocated period of time for completing a task - allcate a 2-hour time box for regression testing stress test a method to assess a system\u0026rsquo;s performance under heavy loads - simulate 1000 users accessing the login page at the same time sanity check 健全性测试 a quick check to verify that something is as expected - are the units of the output value correct? ad hoc test 临时测试 a test performed without predefined test cases or plans - input unexpected characters into a search bar edge case a problem that only happens in extreme situations - upload an empty, 0-byte file 一些名词短语也可以当作动词使用:\nCan you sanity check my email before I send it? I want to make sure there aren\u0026rsquo;t any errors. We have a lot to do today. Let\u0026rsquo;s time box this meeting so we stay on sechedule. BE CAREFUL: sanity check vs ad hoc test\nsanity check: similar to performing a review\nad hoc test: exploring issues using the tester\u0026rsquo;s knowledge\nYesterday, while doing ad hoc test, I came across some unexpected behaviour when I was randomly interacting with the system. Hey, I made a few changes to the codebase. Can you do a quick sanity check before I start testing? Parallel Structure 平行结构 Parallel structure: Using the same grammatical structure for two or more clauses in a sentence.\nExample:\n\u0026ldquo;In our coding guidelines, we emphasise writing clear comments, to follow naming conventions, and maintain consistent indentation.\u0026rdquo;\n注意到上面的动词了吗? (mixed verb forms)\nwriting = gerund form 动名词形式 to follow = infinitive form 不定式形式 maintain = base form\n为了达到平行结构, 将动词修改为相同形式. 由于上面例子由 \u0026rsquo;emphasise\u0026rsquo; 开始, 将其改成 -ing 形式:\nIn our coding guidelines, we emphasise writing clear comments, following naming conventions, and maintaining consistent indentation.\n平行结构的好处:\nmore professional more effective easier to read and follow You can apply this technique when writing:\ndocumentation code comments best practices guidelines Connected Speech 连贯的语言 When we talk in everyday conversations, our words shouln\u0026rsquo;t stand alone.\nInstead, some sound, words and phrases are merged together in what\u0026rsquo;s called connected speech. It\u0026rsquo;s a natural rhythm and flow taht make conversations sound more smooth.\nLet\u0026rsquo;s take a closer look at three different techniques that your can use while asking questions:\n同化 Assimilation\n将两个音素融合形成新音素.\n如\u0026quot;could you\u0026quot;中/d/与/j/融合发成/dʒ/, 形成\u0026quot;coujoo\u0026quot;的流畅发音. /d/ + /y/ = /dʒ/\n省略 Reduction\n缩短或省略特定音素.\n如\u0026quot;who is\u0026quot;中/oʊ/和/ɪ/压缩为长元音/uː/, 读作\u0026quot;hooz\u0026quot;\n连读 Linking\n将前词尾音与后词首音无缝连接，无停顿.\n如\u0026quot;how about\u0026quot;中/w/与/ə/自然衔接, 形成连贯语流.\nCode Review Tom: Hey Sophie!\nSophie: Hi! How are you?\nTom: All good, all good. So I\u0026rsquo;ve reviewed the changes that you made to the ETL pipeline. Overall, it looks great, but I\u0026rsquo;ve got a few points I\u0026rsquo;d like to go over.\nSophie: Sure ok, let me pull it up. Ok I\u0026rsquo;m ready, go ahead.\nTom: Fristly, in the data transformation phase, I noticed a nested loop structure that might impact performance when we go handle large datasets. Have you thought about optimising this bit?\nSophie: Yeah, I see what you mean. So, instead of a loop, what are you thinking?\nTom: I was thinking you could use a list comperhension for that part.\nSophie: Ok sure, let me go back and review it and I\u0026rsquo;ll give that a go.\nTom: In terms of error handing, I noticed some areas where execptions aren\u0026rsquo;t being caught properly. These are crucial since it means it\u0026rsquo;s not going to crash the entire system.\nSophie: Ok good point. I\u0026rsquo;ll have a go at adding some try-except blocks here and then I\u0026rsquo;ll go over the error logging to make sure we\u0026rsquo;ve got details if there are any exceptions.\nTom: Sound good. On a positive note, I really like how you refactored the data loading module. It\u0026rsquo;s much cleaner and easier to follow now.\nSophie: Oh yeah it was a bit of a mess to be honest so it did need a good tidy up. Any other points?\nTom: Nope I think that\u0026rsquo;s everything, overall, it\u0026rsquo;s looking really solid. I\u0026rsquo;ll leave some comments on the code with everything that I\u0026rsquo;ve mentioned for improvement, but great work overall. Well done.\nSophie: Perfect. Thank you. Thanks for the feedback. I\u0026rsquo;ll get started on those and then I\u0026rsquo;ll let you know when it\u0026rsquo;s good to go.\nTom: Alright. Thanks! Have a great day. Bye.\nSophie: Yep and you! Bye.\n词汇解释\ngo over: discuss pull it up: open the code on my scream have/give a go: try how you reafactored: the changes you made tidy up: reorganizing looking really solid: very well structured ","title":"English for Programmers - 02"},{"link":"/posts/english-for-programmers-01/","text":"Unit 1. Implementing Code This unit will cover:\nUse technical verbs to accurately define tasks and actoins Write commit messages in the corret Git format Confidently name the symbols used when writing code Understand vocabulary for syntax and programming rule vocaluary - action verbs 动词词汇 He optimised the queries to improve the response time.\noptimised: 提高 (improved) Can you implement the new feature we discussed yesterday?\nimplement: 实现 (put int action) The team will integrate a third-party API to get real-time data.\nintergrate: 整合 (combine) As our user base grows, we\u0026rsquo;ll need to scale our infrastructure.\nscale: 扩展 (increase capacity) Have you had a chance to refactor the code yet?\nrefactor: 重构 (change) The process it taking too long. How can we streamline it?\nstraemline: 简化 (simplify) Let\u0026rsquo;s execute the script before we go for lunch.\nexecute: 执行 (run) The settings haven\u0026rsquo;t been configured yet.\nconfigured: 配置 (set up) Note: optimise spelling\nBritish English \u0026lsquo;-ise\u0026rsquo; vs. Amercian English \u0026lsquo;-ize\u0026rsquo;\ngrammar - imperative present tense 语法: 祈使现在时 Imperative 祈使语气: 用来下达命令、发出请求、给予指示或建议的语气. 核心功能是告诉某人做某事. Present Tense 现在时: 这里的\u0026quot;现在时\u0026quot;并不是指描述现在正在发生的动作, 而是指这个动词形式 For readability and consistency in commit messages within a team, Git recommends using the Impreative Present Tense.\nGit 建议使用祈使命令式编写提交信息, 编写时将其看成给版本控制和其他开发者看的命令.\nTip: message 应该描述这个修改将实现的功能, 而不是已经编写的功能.\n下面是一个例子:\nRecommended Not Recommended Add new feature for user authentication. Resolve issue with data validation Added a new feature for user authentication. Resolved the issue with data validation 当编写 imperative 句子的时候, 可以省略 a/an/the\nKeyboard Symbols 键盘符号 想象一下, 你在一个团队中合作, 当他们查看你的代码并给予建议的时候, 某人说:\n\u0026ldquo;Can you try replacing the asterisk with an ampersand and adding a tilde after the pipe?\u0026rdquo;\nMe: ???\nSymbol English ! exlamation mark # hash ^ caret \u0026amp; ampersand * asterisk ( bracket / parentheses ~ tilde | pipe \\ backslash ` backtick Symbol English \u0026quot; double quote ' single quote / forward slash : colon ; semicolon \u0026lt; angle bracket , comma { curly bracket / braces [ square bracket _ underscore - hypen Kebab case is a naming convention where all letters are lowercase and words are sperated by hypen.\ne.g. my-variable\nSanke case is a naming convention where all letters are lowercase and words are separated by underscore.\ne.g. my_variable\nMany programming languages ues single qoutes or double qoutes to denote strings.\ne.g. \u0026quot;my variable\u0026quot;\nHTML tags are enclosed in angle brackets.\ne.g. \u0026lt;div\u0026gt;\n常见命名风格 形式示例 常见场景 特点 / 备注 camelCase 驼峰式 userProfile JavaScript 变量、函数名; Java、C# 方法名 首字母小写，后续单词首字母大写 PascalCase 大驼峰 UserProfile 类名(Java、C#、TypeScript)、组件名(React) 每个单词首字母大写 snake_case 蛇形命名 user_profile Python 变量/函数名; 数据库字段 单词用 _ 分隔, 全小写 SCREAMING_SNAKE_CASE 全大写蛇形 MAX_VALUE 常量(C、Python、Java) 全大写 + 下划线 kebab-case 烤肉串式 user-profile URL、CSS 属性、CSS 类名、配置项、文件名 单词用 - 分隔, 全小写. 不能当变量名(- 被视为减号) Train-Case 标题式 / Header-Case User-Profile 文档标题、部分配置(HTTP Header: Content-Type) 类似 PascalCase, 但用 - 分隔 dot.case user.profile 部分配置文件、键路径(MongoDB、Elasticsearch) 用 . 分隔单词 Space Case User Profile UI 文本、自然语言 单词直接空格分隔(不用于代码) listening syntax 你的朋友正在为你介绍一门新语言的语法 syntax (rule defining the structure of the symbols, punctuation and words of a programming language)\n音频在这里\n文本如下\nPLAINTEXT Collapse Copy Let me explain the syntax of my programming language. So firstly, variable names aren\u0026#39;t case sensitive and only contain alphanumberic characters. Secondly, comments can be denoted using an ampersand at the beginning. Thirdly, indentation is not mandatory but it is encouraged for readability. Fourthly, function names must start with a verb and be descriptive of purpose. And finally then, mathematical symbols are not allowed to be used. Click to expand and view more 词汇:\ncase sensitive: 大小写明感 alphanumberic: 字母数字 denote: 代表 ampersand: \u0026amp; indentation: 缩进 mandatory: 强制的 descriptive 描述的 ","title":"English for Programmers - 01"},{"link":"/posts/the-evolution-of-coding-in-the-ai-era/","text":"文章翻译: The Evolution of Coding in the AI Era\n人工智能时代的编码演变 2024 年 8 月 23 日 · Arvid Kahl 阅读时间：约 8 分钟\n几年前，我还是一个完全不同的程序员。巅峰时我能轻松浏览文档并主要写出能用的代码；状态差的时候，我会为了一个笔误或古怪的 bug 折腾好几个小时，毫无结果。\n那时我从来不会想到用 AI 来帮我 —— 因为它还不存在。\n但现在情况变了。\n我们生活在这样一个世界：不使用 AI 工具（AI tooling）来写代码的软件开发者，正逐渐变得少见。现在可用的技术要么极其便宜、要么免费，其实用性和影响力如此普遍，以至于过去五年或十年那种编程方式很可能被彻底替代。\n代价也是存在的。\n这种转变在生产力和速度上带来了若干好处，但也激发了很多恐惧，并暴露出值得探讨的潜在问题。\n作为一个使用 AI 工具来构建软件产品的人，我想思考我们为何走上这条路径、存在哪些风险，以及如何缓解这些风险。我也想探讨，这对那些刚开始学习编程并要在一个把 AI 视为软件开发常态的世界里构建产品的人意味着什么。\nAI 在编码中的力量 使用 AI 最大的明显优势很简单：它比你打字快。AI 生成代码的速度远超人类。即便是最近那些非 AI 的、高度复杂的代码编写工具，也比不上开源 AI 目前能做的速度与效率。这里所说的 AI 指的是专门以写代码为训练目标的大型语言模型（large language models，LLMs），或是通用到足以为用户生成代码的模型。像 ChatGPT、Claude 等都能写出代码，其中有些在产出能真正运行的软件方面表现更好。\n作为软件创业者，我必须在解决有趣技术挑战的意愿和业务需求之间找到平衡。任何能让我更快地写出高质量、可靠代码的方法，我都必须去尝试。当第一批 AI 编码助手进入市场时，我很快就注意到它们的威力。对于有经验的开发者来说，这些工具非常有用——它们能生成我可以快速审阅并决定接受或拒绝的代码。\n这就是关键：你必须懂得什么是好代码，才能批准好代码。\n有经验的编程背景会让这些工具变得更有价值。你实际上是在外包“写逻辑”这一过程，而你所做的则是持续不断地进行代码审查（code review）。AI 做的一切就像给你发来一个拉取请求（pull request）供你审阅。这带来两点含义：\n对有经验的开发者而言，这些工具对工作质量的影响是巨大的。\n对于正在学习编程的人来说，仍然有必要理解编码的核心原理，才能有效评判 AI 给出的结果。\n学习曲线与 AI 这是我看到人们最关心的核心问题：如果你靠 AI 学编程，你可能永远不会真正理解那些你需要用来评判代码的解决方案。你需要知道“配方”的原材料和工作原理，才能下厨；否则你只是把食物弄坏。对代码也是如此——你需要理解语法、语义、求值和执行的过程。\n在开发者成长路径的某个阶段，依赖 AI 生成代码可能会妨碍他们技能的发展。如果你不会写代码，就想象不出最终系统的全貌，也就无法判断自动生成的代码到底是什么、做了什么。\n直到现在，这种经验通常需要很长时间来积累。\n我看到很多人在这个问题上煽动恐惧。他们不满今天的人不再必须学习编程就能产出某种程度上有用的结果。他们担心人们永远无法获得理解代码工作原理的经验，只会产生平庸、不可维护的代码，而且这些人甚至在职业早期就能赚到钱。\n\u0026ldquo;现在的年轻人\u0026quot;现象 这让我想起一个反复出现的梗：人们总说“现在的年轻人不想工作了”。这是每十年就会重现一次的主题，是一种自我错觉式的看法。我看到一个流传的图集，里面有从去年追溯到几十年前、甚至到 1850 年代的旧报纸剪报，本质上都在说同一件事：年轻人有道德缺陷，因为他们不想工作了。\n我觉得很有趣：每个年代总有人认为“当年大家都想工作，但现在没人想工作了”。这种自我错觉已经重复了数百年，在技术领域我们也看到类似的模式。\n编程的发展演进 回顾编程的发展，我们也见证过类似的转变：\n从打孔卡到数字系统与机器语言（machine language）\n从机器语言到编译型语言（compiled languages）\n从编译型语言到解释型语言（interpreted languages）\n每当技术（或我们与技术交互的方式）发生“量子跃迁”，总会有一群传统主义者或纯粹主义者认为新事物正在导致知识的丧失。他们觉得这会让人们的能力退化，因为人们不再需要理解那么多关于编码或编程的底层细节。每一次，这些怀疑者最终都被证明是错的。\n当人们从机器语言转向编译型语言时，编程的可达性提高了。你不必理解寄存器是什么、什么是 jump-not-equal（条件跳转）事件；你只需要懂 if-then-else（条件语句）或变量赋值。只要掌握这些，就能构建出能运行的代码。\n从编译型语言到解释型语言的跃迁，使得像在 HTML 中嵌入 JavaScript、使用 PHP、Ruby on Rails，甚至 Java 变得更加普及。你只要把一个文件放到某处，并以正确方式加载，它就会按预期执行。这种可达性催生了更多有趣、更好的工具，而用这些工具建出的解决方案常常使之前的系统相形见绌。\n当下的跃迁：生成代码 我认为我们正处于（如果还没完全处于的话）又一次这样的跃迁之中。我们正在从“用程序指令告诉计算机怎么做”转向“通过提示（prompt）生成代码 —— 由提示产生的代码”。这又是抽象层级上的一次提升，离底层系统更远了一步。\n最近我亲身经历了这一点：我需要把一段转录文本（transcript）转换成 SRT 字幕文件（SRT subtitle file）格式，用于我自己的业务 Podscan。我没有自己写那段代码，而是让 Claude AI（Claude）在我写的代码雏形基础上，生成一个能把转录文本翻译成有效 SRT 数据的函数。结果是一个可靠可用的函数，能稳定完成任务。\n我对 Claude 说：“输入会是像这样的文本。”我贴了一段要转换的转录材料。然后我说：“我希望输出是有效的 SRT 数据。”然后敲下回车。出来的就是一个能工作的函数，能够把我的转录文本转成 SRT 文件。\n编码性质的变化 这次经历让我意识到：编码在演变。它不再是把每一行代码都敲出来，而是知道需要完成什么，并用指令（指示 AI）去让 AI 去做。函数的心智模型仍然重要——例如接收数据、按行拆分、处理每一行——但具体实现可以交给 AI 去完成。\n作为开发者的那部分我仍在努力接受这种变化。过去有趣的部分是解析数据、拆分行、提取时间戳、移动那一行文本、把文本放到下一行、然后把该行的索引放到文件的另一行。但在某种程度上，那已经不再是有趣的部分了。\n我敢打赌：在这个地球上的每一天，总有人在实现类似的功能。有人把一种文件变成另一种、把数据格式从 A 转成 B，而这个任务往往已经有人写好了库（library）来处理。我的意识到的是：开发者被高薪聘用、被需要，不是因为我们知道如何拆分一个文件并取出某一部分。\n开发者的真正价值 真正的价值在于：我能口头或文字上清晰表达需要发生的事情、阐明输入与输出、以及大致流程；我有能力说“我需要的输出是有效的 SRT，而你将得到的输入是这种结构化文本”。这就是当今的软件开发，也是未来软件开发会继续走向的方向。\n过去那种因为错过一个逗号就追踪每一行并制造 bug 的日子会消失。机器会为我们处理这些细节。剩下的将是架构设计——从宏观层面的完整应用设计（可能包含 17 个协同工作的部分），到微观层面的单个函数定义。\n编程教育的未来 我们正在把“执行代码”这一环节从编码中分离出来，而把“提示（prompting）与指令（instructing）”置于更重要的位置。要精确地提示与指令 AI，我们需要理解逻辑的心智模型、流程、数据结构和数据转换。\n也许教学会改变，就像 70、80 年代教授 BASIC、COBOL、C 或 Ada 时那样。也许未来的软件开发者更多被要求成为“指令者（instructors）”。越早理解：若要准确地提示与指示，你需要掌握逻辑模型、流程、数据结构和数据转换 —— 我们就能越快建立起面向未来开发者的课程体系，而这些开发者无需手动逐行深入每一段代码。\n把编码当作“编辑” 长期以来，我觉得写作人与软件开发者之间其实没什么不同：两者都是在写带有指示性的文本——一个是写给人看的，另一个是写给机器看的。现在我们在某种程度上正从“写作”转向“编辑”。我们在编辑别人（即 AI）所产出的“想法”，使之符合我们对目标受众的理解。\n书籍编辑的受众是出版方推送的读者；软件编辑的受众是系统、计算机以及执行由这些 AI 系统生成代码的解释系统（interpretive systems）。想写好书，你得懂编辑；想写好代码，你也得懂提示与指令的艺术。\n前路 前路可能并非一帆风顺。许多开发者对这种变化持防御态度，感到被冒犯：那些他们花多年时间掌握的技能，现在看起来可以被这么轻易地完成。很多开发者对这件事非常反感，因为编码本来就是他们费尽心血学来的技能，而现在代码生成这么容易似乎是在贬低他们的努力。\n但好处也是不可否认的。我个人从生成代码速度的提升中获益良多。对我而言，阅读、解析、理解和验证代码，总比从零构思代码要容易得多。这就是为什么编码现在与过去根本不同——我们不仅写代码的速度更快，理解与验证代码的速度也更快。AI 已经留下了深远的影响，我认为我们不会回到过去那种状态。\n在这个由 AI 辅助编码的新时代，我们作为开发者的角色在演变。我们正变成架构师、指令者和代码编辑者，而不再仅仅是编写者。虽然这个转变对部分人来说可能具有挑战性，但它也为软件开发中的创新与效率开辟了令人兴奋的新可能性。\n在前进的过程中，我们需要拥抱这种变化，同时确保自己在培养能够有效引导和指示 AI 去创建未来软件解决方案的技能。编码的未来已来，它是人类创造力与机器效率的激动人心的混合体。\n我的一些简短思考（要点提炼） 作者强调的是角色的转变：从“代码书写者”转向“系统架构师 / 指令者 / 编辑者”。关键能力从手写实现转为构建心智模型与有效提示（prompt engineering）。 对初学者的建议隐含着警告：即便有 AI，也必须打好基础（语法、数据结构、执行模型），否则无法评判 AI 的产出。 历史上每次抽象层级跃升（机器码→编译→解释）都曾遭遇抵触，但最终扩大了可达性与创新；AI 可能重复这一轨迹。 实务层面：AI 会替我们处理重复、机械的实现细节，开发者应把精力放在架构、边界条件、数据模型与系统整合上。 教育需要演进：课程可能从“教写代码”转为“教如何思考系统、设计流程与构造有效提示（prompt）”，同时保留核心编程原理的训练。 ","title":"The Evolution of Coding in the AI Era"},{"link":"/posts/service-implementation-patterns-for-microservice/","text":"Hexagonal architectures for microservices 微服务的六边形架构 六边形架构 Hexagonal Architecture 也被称为接口与适配器架构 Prots and Adapters Architecture, 是一种软件架构模式, 旨在实现高内聚、低耦合和可测试性的应用程序设计. 该架构由 Alistair Cockburn 发明, 他是敏捷宣言的签署者之一. 该架构是说, 在任何应用程序中, 都有一个核心逻辑实现服务, 并且在该服务周围\u0026quot;附加\u0026quot;上一些接口, 用于核心与外部组件的交互.\n例如, 一个 web API 就是一个适配器 adapter, 帮助核心逻辑与互联网上的 web 客户端交流. 对于数据库也是一样的, 其也是一个外部组件, 帮助服务维护数据. 如果我们需要, 应该要能迁移到其他的数据库, 并且服务仍然是相同的. 因此, 数据库也是一个适配器 adapter.\n上述架构可通过在核心业务逻辑层与适配器之间构建接口 ports 来实现.\n在处理核心业务逻辑与适配器之间的关系时, 应用依赖反转原则 dependency inversion principle:\n高层模块不应该依赖底层细节.\n相反, 两者都应该依赖抽象. 以数据存储为例, 我们应当通过统一的接口进行操作, 无需理解数据库的具体实现细节. 无论是 SQL 数据库、NoSQL 数据库还是缓存存储系统, 都应该使用相同的接口规范.\n抽象不应依赖于具体实现, 而具体实现应依赖于抽象.\n以业务层与数据层之间的接口设计为例, 必须确保接口不会因数据库实现细节的变动而修改, 相反地, 我们通过调整数据层实现来适配接口规范.这意味着数据层依赖于接口定义, 而非接口依赖于数据层实现.\n依赖反转的概念经常同控制反转与依赖注入的概念一同出现, 这些是相关但是不同的概念.\n依赖反转原则反转了什么? 这个原则改变了构建软件的思路, 与传统先实现底层细节然后再在其上构建接口的做饭相反, 依赖倒置原则鼓励我们先考虑接口, 然后再针对这些接口实现底层细节.\n","title":"Service Implementation Patterns for Microservice"},{"link":"/posts/dealing-with-grabage-in-python/","text":"Grabage Collection In Python 本篇文章介绍 Python 中的 Grabage Collection (GC) 机制介绍\nWhat\u0026rsquo;s Python Object? Python 对象中有三样东西: 类型(Type)、值(value)和引用计数(reference count), 当给变量命名时, Python 会自动检测其类型, 值在定义对象时声明, 引用计数是指该对象名称的数量.\n首先来看一个类\nPYTHON Collapse Copy class Person: def __init__(self, name, unique_id, spouse): self.name = name self.unique_id = unique_id self.spouse = spouse def __del__(self): print( # !r: 调用 repr() 来获取该对象的字符串表达式 # !s: str() # !a: ascii() f\u0026#34;Object {self.unique_id!r} is about to be removed from memory. Goodbye!\u0026#34; ) Click to expand and view more 该 Person 类有以下3个属性:\nname: 人名 unique_id: 唯一性 id spouse: 将为 None 或者将存储另一个 Person 对象 有一个特殊方法 __del__(), 这个特殊方法有一定的误导性. 该方法并不像 __len__() 与 len() 或者 __iter__() 与 iter() 那样与 del 关键字相关联. __del__() 特殊方法并不定义当对对象引用时 del 会发送什么, 相反, __del__() 是一个终结器 finaliser: 它在对象被消毁之前从内存中移除之间被调用.\n因此, __del__() 中 print() 调用的字符串仅在 Python 即将从内存中移除对象时显示.\n注意: del 方法并不会直接删除该对象, 而是会删除该对象的引用 Reference Counting 引用计数 在引用计数中, 引用总是被统计并存储在内存中, 如下示例:\nPYTHON Collapse Copy a = 50 b = a c = 50 print(id(a)) print(id(b)) print(id(c)) print(a is b) print(c is b) print(a is c) # 输出: 134367443832424 134367443832424 134367443832424 True True True Click to expand and view more 该示例的 id 都是相同的, 即为同一个变量, 此时引用计数为3, 如果使用 del 删除 a 和 b, c 仍然会存在, 因此此时引用计数为 1\n引用计数\n优点: 易于实现, 无需手动管理内存 (之所以引用计数, 就是因为py中变量赋值是增加一个引用, 而不是 c++/java 那样去内存中复制一个相同的对象) 缺点: 引用计数的对象存储在内存中, 对内存管理不利; 此外, 无法处理循环引用的问题 例如下面这种最简单的循环引用:\nPYTHON Collapse Copy a = [] a.append(a) print(a) # 输出 [[...]] Click to expand and view more 该对象 a 循环引用其自身, 无法靠引用计数法删除\nGenerational Garbage Collection 分代回收 分代垃圾回收是一种基于追踪系统 trace-based 的垃圾回收, 它可以打破循环引用并删除未使用的对象.\nPython 跟踪内存中的每个对象, 程序运行时创建3个列表: 第0代、第1代和第2代.\n新创建的对象被放入第0代列表, 会创建一个待丢弃对象的列表, 检测循环引用. 如果一个对象没有外部引用, 就会被丢弃. 在此过程中, 存活下来的对象被放入第1代列表, 相同的步骤应用于第1代列表. 从第1代列表中存活下来的对象被放入第2代列表. 第2代列表中的对象会一直保留到程序执行结束.\nPython 与其他编程语言的垃圾回收对比\n垃圾回收在不同的编程语言中工作方式不同, 以下是 Python 的垃圾回收机制与其他常见编程语言的比较:\nPython: 自动, 通常基于内存中对象的引用计数, 当对象的引用计数达到零时, 对象会自动被垃圾回收 Java: 自动, 当堆内存接近满时(即当老年代堆空间达到一定大小时)或经过一定时间后, 它会垃圾回收不再使用的对象 JavaScript: 自动, 通常使用标记-清除算法进行自动垃圾回收, 该算法标记可达或正在使用的对象, 并自动清除未标记的对 C++: 非自动, 必须通过手动分配和释放对象内存来完成垃圾回收 Rust: 没有垃圾回收(或者说是编译时垃圾回收), Rust 确实实现了一种自动内存管理机制, 它通过一种独特的所有权系统在编译时就确保内存安全, 从而避免了在运行时进行垃圾回收的需要 ","title":"Dealing With Grabage in Python"},{"link":"/posts/docker-workflow/","text":"The Docker Workflow 这篇文章介绍 Docker 工作流\nRevision Control 版本控制 Docker 有两种版本控制方式. 一个是用来跟踪文件系统层 layers (每个镜像的组成), 另一个是 tagging 标签系统.\nFilesystem layers 文件系统层 Linux 容器由堆叠文件系统层组成, 每一层由一个唯一的哈希标记, 每次 build 都在之前的修改之上. 这意味着, 每次 build 只需要重新构建修改过的层. 这节省了时间和网络带宽.\nImage Tags 镜像标签 第二种版本控制回答了一个问题: 之前部署的应用版本是? 非容器化应用的解决方案有很多种, 从 Git 发布标签到部署日志. Docker 有一个内置的处理机制: 每次 build 都有一个镜像标签. latest 经常被用来表示最新版本, 但由于这是一个浮动的标签, 因此在生产中使用并不好. 正确的做法应该是使用一个特定的版本.\nBuilding 构建镜像 Docker 的命令行工具包含一个 build 标志, 它会读取 Dockerfile 并产生一个 Docker 镜像. Dockerfile 中的每一条指令都会在镜像中生成一个新的层, 因此仅通过查看 Dockerfile 就能比较容易的推断出构建会做什么. 这样标准化的好处是, 任何熟悉 Dockerfile 的工程师都可以直接上手并修改任何其他应用的构建. Dockerfile 通常会提交到版本控制系统, 这也简化了对构建变更的追踪, 现代的多阶段构建还运行将构建环境与最终镜像分离, 为构建环境提供了像生产容器那样强大的可配置性.\n许多 Docker 构建只是一次性调用 docker image build 命令, 并生成一个镜像. 由于构建的逻辑大部分都写在 Dockerfile 里, 因此很容易为任何团队在 Jenkins 这样的构建系统中创建标准化的构建任务. 作为进一步标准化构建流程的举措, 许多公司已经统一使用 Linux 容器来从 Dockerfile 执行镜像构建, 像 Travis CI、CodeShip 这样的 SaaS 构建服务也对 Docker 构建提供原生支持.\nTesting 测试 虽然 Docker 本身并不包含内建的测试框架, 但容器的构建方式为使用 Linux 容器进行测试带来了一些优势.\n对生产应用的测试可以有多种形式, 从单元测试到在接近真实的环境中进行的完整集成测试. Docker 通过保证通过测试的制品就是最终投放生产的制品, 从而促进更可靠的测试. 这种保证可以通过使用容器的 Docker SHA 或自定义标签来实现, 确保始终发布的是同一版本的应用.\n由于容器按设计包含了它们的所有依赖, 因此在容器上运行的测试非常可靠. 例如, 如果某个单元测试框架报告在某个容器镜像上测试成功, 你可以比较确信在部署时不会遇到底层库版本导致的问题. 大多数其他技术很难做到这一点: 即便像 Java 的 WAR(Java Web Application ARchive)文件, 也通常不包含对应用服务器本身的测试. 而将相同的 Java 应用部署到 Linux 容器中, 通常会把像 Tomcat 这样的应用服务器一并包含进去, 整个栈就可以在发往生产之前进行冒烟测试.\n将应用以 Linux 容器形式交付的另一个次要好处是: 在多个应用通过类似 API 的远程方式相互通信的场景中, 一个应用的开发者可以方便地针对另一个服务中已为所需环境(例如 production 或 staging)打好标签的版本进行开发. 各团队的开发者无需成为其他服务的部署或实现专家, 便能继续开发自己的应用. 如果把场景扩展到包含无数微服务的面向服务架构, Linux 容器对那些需要深入应对微服务间大量 API 调用复杂性的开发人员或 QA 工程师来说, 能成为真正的救命稻草.\n在生产中运行 Linux 容器的组织中, 一个常见做法是: 自动化的集成测试会拉取一组按版本管理的不同服务的 Linux 容器, 匹配当前已部署的版本. 然后就可以使用这些与部署环境相同的版本对新服务做集成测试. 在异构语言环境下做到这一点以前通常需要大量定制工具, 但由于 Linux 容器提供了标准化, 这项工作现在变得相对容易实现.\nPackaging 打包 Docker构建过程会生成一个可视为独立构建产物的镜像, 尽管从技术层面看, 这些镜像可能由多个文件系统层组成. 无论您的应用程序采用何种编程语言编写, 或基于哪种 Linux 发行版运行, 最终都能获得一个分层结构的 Docker 镜像. 这一切都由 Docker 工具链自动构建和处理. 这种构建镜像正是Docker得名的\u0026quot;运输集装箱\u0026quot;隐喻: 它是一个统一的、可传输的单元, 通用工具链能够直接处理, 而无需关心其内部具体内容. 就像远洋货轮将所有货物装入标准钢制集装箱那样, 您的Docker工具链只需处理一种标准化包装: Docker镜像. 这种标准化机制极具价值, 它极大促进了不同应用程序间的工具复用, 意味着他人现成的容器工具也能直接处理您的构建镜像.\n传统需要大量自定义配置才能部署到新主机或开发系统的应用程序, 通过Docker实现了高度的可移植性. 容器构建完成后, 可以轻松部署到任何运行Docker服务的同架构系统上.\nDeploying 部署 不同企业使用的部署工具种类繁多, 难以尽数. 常见工具包括Shell脚本、Capistrano、Fabric、Ansible 以及内部定制工具, 每个团队通常有一两位掌握\u0026quot;部署魔法\u0026quot;的关键人员——当出现故障时, 整个团队都依赖他们恢复系统. Docker让这些问题迎刃而解, 其内置工具支持通过简单的一行命令即可完成构建产物在主机上的部署和启动.\n标准 Docker 客户端虽然每次只能部署到单台主机, 但现有大量工具可以轻松实现向 Docker 集群或其他兼容 Linux 容器主机的批量部署. 得益于 Docker 提供的标准化机制, 开发团队能够以极低的复杂度将构建产物部署到任何这类系统中.\nThe Docker Eocosystem 多年来, 围绕 Docker 已形成一个由开发者和系统管理员共同推动的庞大社区. 与 DevOps 运动相似, 这个社区通过用代码解决运维问题催生了更优秀的工具. 当 Docker 原生工具链存在功能缺口时, 其他公司和个人纷纷挺身而出进行补充, 其中许多工具同样以开源形式发布. 这意味着这些工具具备可扩展性, 任何企业都能根据自身需求进行定制化修改.\nOrchestration 编排 在增强 Docker 核心发行版及 Linux 容器体验的工具中, 首要类别当属编排与批量部署工具. 早期批量部署工具如 New Relic 的 Centurion、Spotify 的 Helios 以及 Ansible Docker 工具, 其工作方式仍近似传统部署工具, 但已将容器作为分发制品. 这些工具采用简单易实施的方案, 在无需引入过多复杂性的前提下即可获得 Docker 的大部分优势. 不过其中许多工具已被更强大灵活的方案(如Kubernetes)所取代.\n全自动调度器如 Kubernetes 或搭载 Marathon 调度器的 Apache Mesos 属于更强大的选择, 它们能近乎完全代管主机资源池. 其他商业解决方案也广泛应用 例如 HashiCorp 的 Nomad、Mesosphere 的 DC/OS(数据中心操作系统)以及 Rancher. 无论是开源还是商业选项, 其生态系统都在持续快速发展.\nImmutable atomic hosts 不可变原子主机 另一种能提升 Docker 使用体验的理念是不可变原子主机. 传统上, 服务器和虚拟机需要企业精心组装、配置和维护, 以提供支持广泛使用场景的多样化功能. 系统更新通常需要通过非原子操作完成, 主机配置可能存在多种偏差方式, 从而引发意外行为. 当今大多数运行中的系统都采用原地打补丁和更新的方式.\n相反, 在软件部署领域, 大多数人会选择部署完整的应用程序副本, 而非对运行中的系统进行补丁操作. 容器的部分吸引力在于它们能比传统部署模式更彻底地实现应用原子化.\n这是基于 Linux 的原子主机发行版(如 Red Hat 的 Fedora CoreOS、Bottlerocket OS等)的核心思想之一. 不仅应用程序应该能够轻松销毁和重新部署, 整个软件栈也应遵循相同理念. 这种模式有助于为整个技术栈提供高度一致性和弹性.\n不可变原子主机的典型特征包括: 最小化占用空间、专注于支持 Linux 容器和 Docker 的设计、支持原子化的操作系统更新与回滚, 这些操作可通过裸机或常见虚拟化平台上的多主机编排工具轻松控制.\nAdditional Tools 扩展工具 Docker 并非独立的解决方案. 虽然它具备强大的功能集, 但总会存在需要超越其原生能力的场景. 目前已经形成庞大的工具生态系统, 用于增强或扩展 Docker 功能. 一些优秀的生产工具通过 Docker API 实现集成, 例如用于监控的 Prometheus 和实现简易编排的 Ansible; 另一些则利用 Docker 的插件架构, 插件作为可执行程序, 遵循特定规范与Docker进行数据交互.\n还有更多优秀工具通过 API 对接或插件化运行的方式扩展 Docker 能力. 其中大量工具的出现是为了简化 Docker 在各云平台上的使用体验, 实现 Dockera 与云环境的无缝集成. 随着社区持续创新, 这个生态系统仍在不断扩张, 该领域持续涌现新的解决方案和工具.\n","title":"Docker - Workflow"},{"link":"/posts/docker-images-and-registeries/","text":"The Docker Images | Docker 镜像 Image、OCI Image、Docker Image、Container Image 都是指同一个概念镜像的不容叫法.\n镜像是一个轻量、只读且不可变的蓝图, 指定了应用运行所谁要的一切, 以及在 Docker 系统上如何运行. 就像是一份配方, 包括所有必要的原料, 诸如依赖、配置、环境设置和你的应用代码, 以及确保应用每次都能稳定运行的详细指令.\n可以把镜像类比为面向对象编程中的类: 定义结构和行为, 但不能直接与类交互, 需要创建实例.\nPulling and Inspecting an Image 拉取并查看镜像 镜像其实就是一个 JSON 对象, 可以这样拉取一个镜像\nPLAINTEXT Collapse Copy % docker pull celery:latest latest: Pulling from library/celery ef0380f84d05: Pull complete ada810c79ed7: Pull complete 4608a1c4fe47: Pull complete 58086cbb21fb: Pull complete a7bccb4a3faa: Pull complete 9de06a08ec25: Pull complete ad6feb8c6a6b: Pull complete 7568ca85d492: Pull complete 2d6f458f7411: Pull complete Digest: sha256:5c236059192a0389a2be21fc42d8db59411d953b7af5457faf501d4eec32dc31 Status: Downloaded newer image for celery:latest docker.io/library/celery:latest What\u0026#39;s next: View a summary of image vulnerabilities and recommendations → docker scout quickview celery:latest Click to expand and view more 现在查看镜像信息\nPLAINTEXT Collapse Copy % docker image inspect celery Click to expand and view more 这个命令会以 JSON 格式输出关于镜像的详细信息\nJSON Collapse Copy [ { \u0026#34;Id\u0026#34;: \u0026#34;sha256:e111a70eee6a42a68768ec0734a6b2f1ceab34b27e4c4325ed6a14d4f36c2568\u0026#34;, \u0026#34;RepoTags\u0026#34;: [ \u0026#34;celery:latest\u0026#34; ], \u0026#34;RepoDigests\u0026#34;: [ \u0026#34;celery@sha256:5c236059192a0389a2be21fc42d8db59411d953b7af5457faf501d4eec32dc31\u0026#34; ], \u0026#34;Parent\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2017-06-19T16:53:14.832853892Z\u0026#34;, \u0026#34;DockerVersion\u0026#34;: \u0026#34;17.03.1-ce\u0026#34;, \u0026#34;Author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Architecture\u0026#34;: \u0026#34;amd64\u0026#34;, \u0026#34;Os\u0026#34;: \u0026#34;linux\u0026#34;, \u0026#34;Size\u0026#34;: 215773711, \u0026#34;GraphDriver\u0026#34;: { \u0026#34;Data\u0026#34;: { \u0026#34;LowerDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/48895e03352004bc8ce3d6a639e808ba64b209349af83a3c75b481be2ed94938/diff:/var/lib/docker/overlay2/c845387bc00200c8fb7eb3e3305dba41fdb4ff2d9aa6c085fb0a6ad24c290c73/diff:/var/lib/docker/overlay2/17756520f50f2cbf3e556f44abb1c0b5b6789cd6f6df47246baaabcc3c14d8e0/diff:/var/lib/docker/overlay2/4d0e644e7332550ce97905e7784f5d9f96d9213c774a7204e2fd8b8aa3b11035/diff:/var/lib/docker/overlay2/5d44ed5515c803cd01048443fc3fa4d3372b48fb956d7574513f72a83ab83f66/diff:/var/lib/docker/overlay2/72ff0fa932bdc072f1beb1bc8ff782dc4b1fbde9a658307a698d4e0160d92797/diff:/var/lib/docker/overlay2/78b31a20c2e61a0d663de9c13830def1ae6d14c106dd3a78a581e0e40e7b4689/diff:/var/lib/docker/overlay2/d137d2107e48055ec9dcb33a81a136f0c6625f5e0a7439d1ccd972df8266edce/diff\u0026#34;, \u0026#34;MergedDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/4421a44d9ab8308305d3a051ca7672cb4d8e778bdbba66b8800348a805ee3dfc/merged\u0026#34;, \u0026#34;UpperDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/4421a44d9ab8308305d3a051ca7672cb4d8e778bdbba66b8800348a805ee3dfc/diff\u0026#34;, \u0026#34;WorkDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/4421a44d9ab8308305d3a051ca7672cb4d8e778bdbba66b8800348a805ee3dfc/work\u0026#34; }, \u0026#34;Name\u0026#34;: \u0026#34;overlay2\u0026#34; }, \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:007ab444b234be691d8dafd51839b7713324a261b16e2487bf4a3f989ded912d\u0026#34;, \u0026#34;sha256:e2a576046222da3c29f237fa2d751d18c7a8f875ddc32fc803466aeaf998b9ee\u0026#34;, \u0026#34;sha256:b5fa8e7e036448cb8c431f6b28eb1fbc4573c9330b197c7a0ba8e2292fa9fc2f\u0026#34;, \u0026#34;sha256:4437df14034b8c6be5537d719f45f305b8e3365e01abe23a2207ba0963618214\u0026#34;, \u0026#34;sha256:2b3426b547f7dade968deaaed73f75d25a883f6688f817ec0c3d1999b2a5c7cf\u0026#34;, \u0026#34;sha256:df324182704a2a1f6229c5712619b2f2f8e5c0e79c1c90c97b99f2c9e8f0a22d\u0026#34;, \u0026#34;sha256:bfac39c3713affaa50703d23c5a3dfd7a4f54bdae75af9ea23551cf221b3ae7c\u0026#34;, \u0026#34;sha256:5c5a2dec46e80510abd744b0d469feaa20a5c10d70c937748509577c5a280dfb\u0026#34;, \u0026#34;sha256:e4cff87cc854a86536342699faf3e67ce0c2ccf4b735d9998991a024e6fe4db6\u0026#34; ] }, \u0026#34;Metadata\u0026#34;: { \u0026#34;LastTagTime\u0026#34;: \u0026#34;0001-01-01T00:00:00Z\u0026#34; }, \u0026#34;Config\u0026#34;: { \u0026#34;ArgsEscaped\u0026#34;: true, \u0026#34;Cmd\u0026#34;: [ \u0026#34;celery\u0026#34;, \u0026#34;worker\u0026#34; ], \u0026#34;Entrypoint\u0026#34;: null, \u0026#34;Env\u0026#34;: [ \u0026#34;PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34;, \u0026#34;LANG=C.UTF-8\u0026#34;, \u0026#34;GPG_KEY=97FC712E4C024BBEA48A61ED3A5CA953F73C700D\u0026#34;, \u0026#34;PYTHON_VERSION=3.5.3\u0026#34;, \u0026#34;PYTHON_PIP_VERSION=9.0.1\u0026#34;, \u0026#34;CELERY_VERSION=3.1.25\u0026#34;, \u0026#34;CELERY_BROKER_URL=amqp://guest@rabbit\u0026#34; ], \u0026#34;Labels\u0026#34;: null, \u0026#34;OnBuild\u0026#34;: null, \u0026#34;User\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;Volumes\u0026#34;: null, \u0026#34;WorkingDir\u0026#34;: \u0026#34;/home/user\u0026#34; } } ] Click to expand and view more Docker 引擎在从镜像创建容器时, 会使用这个 JSON 对象, 该对象包含许多属性, 例如:\nId: 镜像的唯一标识符 RepoTags: 关联的标签 RepoDigests: 镜像的分发摘要 (用于校验) Created: 镜像创建时间戳 Author: 镜像创建者 当使用 docker image pull 命令而没有指定 tag 或版本时, Docker 会自动拉取以 latest 标记的镜像.\n这里一般是最新版本, 但注意 latest 知识一直约定, 并非所有镜像最新版本的 tag 都是 latest\nThe Layers Property | Layers 属性 镜像 JSON 对象中最关键的属性之一是 Layers, 如下\nJSON Collapse Copy { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:007ab444b234be691d8dafd51839b7713324a261b16e2487bf4a3f989ded912d\u0026#34;, \u0026#34;sha256:e2a576046222da3c29f237fa2d751d18c7a8f875ddc32fc803466aeaf998b9ee\u0026#34;, \u0026#34;sha256:b5fa8e7e036448cb8c431f6b28eb1fbc4573c9330b197c7a0ba8e2292fa9fc2f\u0026#34;, \u0026#34;sha256:4437df14034b8c6be5537d719f45f305b8e3365e01abe23a2207ba0963618214\u0026#34;, \u0026#34;sha256:2b3426b547f7dade968deaaed73f75d25a883f6688f817ec0c3d1999b2a5c7cf\u0026#34;, \u0026#34;sha256:df324182704a2a1f6229c5712619b2f2f8e5c0e79c1c90c97b99f2c9e8f0a22d\u0026#34;, \u0026#34;sha256:bfac39c3713affaa50703d23c5a3dfd7a4f54bdae75af9ea23551cf221b3ae7c\u0026#34;, \u0026#34;sha256:5c5a2dec46e80510abd744b0d469feaa20a5c10d70c937748509577c5a280dfb\u0026#34;, \u0026#34;sha256:e4cff87cc854a86536342699faf3e67ce0c2ccf4b735d9998991a024e6fe4db6\u0026#34; ] } Click to expand and view more What is Layer? | 什么是 Layer? 文章开头提到镜像包含所有必要信息(依赖 配置等), 在 Docker 中, 模块化和解耦是关键原则. Docker 中的 layer 本质是一组文件(或单个文件), 例如一个 Python 应用可能需要:\nPython 二进制文件 apt 包管理器 / 所需系统工具 最后是应用文件 (又一个 layer) layer 的好处在于: 一旦创建并存储了 Python 二进制的 layer, 任何需要它的镜像都可以直接引用它的位置. Docker 会按需获取它, 如果世界另一端的某人也需要相同的 Python Layer, 他们不需要重新创建或重复上传该层, 可以直接使用相同的 Layer. 这种做法运行我们共享、重用并高效管理资源. 更棒的是, 分层让本地的更加高效, 如果机器的另一个镜像已经下载了一些 layer, Docker 会智能地复用这些已存在的 layer, 而不是重复下载.\n简单来说: Layer 是一组文件, 而 Image 指明了它包含哪些层, 以及他们如何堆叠. 层的顺序很重要, 因为上层的文件可以屏蔽下层的文件.\n但是, 容器本身并不知道层或文件在层中的组织方式, 容器看到的是一个完整的文件系统. 这由 Docker 的存储驱动完成: 它将所有层的文件收集合并, 为容器呈现一个单一的文件系统.\n例如下面两个数据库镜像\nPLAINTEXT Collapse Copy $ docker pull redis Using default tag: latest latest: Pulling from library/redis af302e5c37e9: Pull complete # \u0026lt;\u0026lt;\u0026lt;\u0026lt;----- [1] 01b95e092fd0: Pull complete c111ca53a743: Pull complete f7d6cf14046e: Pull complete 589f36d317d9: Pull complete 94041d0cae8f: Pull complete 4f4fb700ef54: Pull complete 4f5f785c9703: Pull complete Digest: sha256:ca65ea36ae16e709b0f1c7534bc7e5b5ac2e5bb3c97236e4fec00e3625eb678d Status: Downloaded newer image for redis:latest docker.io/library/redis:latest $ docker pull postgres Using default tag: latest latest: Pulling from library/postgres af302e5c37e9: Already exists # \u0026lt;\u0026lt;\u0026lt;\u0026lt;----- Check this out, this layer was already fetched in [1] 23db180a1f67: Pull complete dc59dd9c8eb3: Pull complete aec09e638045: Pull complete 4dd47a683737: Pull complete 7cebbe7849b3: Pull complete dc4330b02129: Pull complete 498cc40b9fe9: Pull complete 6d3411bb4696: Pull complete 8f14f34d54d3: Pull complete 88d4f7416643: Pull complete e91ad5cfb8d0: Pull complete e0c4d5055fb9: Pull complete 254ee626d709: Pull complete Digest: sha256:87ec5e0a167dc7d4831729f9e1d2ee7b8597dcc49ccd9e43cc5f89e808d2adae Status: Downloaded newer image for postgres:latest docker.io/library/postgres:latest Click to expand and view more Base Layer 基础层 镜像中的 base layer 就像建筑的地基, 它是后续构建的起点. 通常 base layer 包含操作系统或运行环境所需的基础文件和工具. 每个 Docker 镜像都以 base layer 开始, 后续层在其基础上构建. 这个基础层保证了一致性, 并为应用提供了稳定的运行环境. 由于 base layer 可以在做个镜像之间重复使用, Docker 只需下载并存储一份, 从而提高效率并节省空间. 在上面的 Redis / Postgres 示例中, af302e5c37e9 就是 base layer.\nDigests 摘要 如前所述, layer 是可重用的, 所以 Docker 需要一种系统来高效存储、组织和定位他们. 这些数字就是 layer 的唯一地址, 使得他们可以被识别和重用, 每个 layer 都有一个基于其内容计算出来的哈希值, 准确的说是该层的 content-addressable identifier 内容寻址.\nDocker 会为 layer 中的每个文件计算哈希, 然后生成该 layer 的合并哈希. 这个哈希确保 layer 是唯一可寻址的, 从而让镜像可以指向它\n如果某个 layer 中的文件被更新了, 文件的哈希会改变, layer 的合并哈希也会改变, 而产生一个全新的、唯一的 layer.\nImage Digests 镜像摘要 PLAINTEXT Collapse Copy $ docker pull postgres Using default tag: latest latest: Pulling from library/postgres af302e5c37e9: Already exists 23db180a1f67: Pull complete ... 254ee626d709: Pull complete Digest: sha256:87ec5e0a167dc7d4831729f9e1d2ee7b8597dcc49ccd9e43cc5f89e808d2adae #\u0026lt;----- Distribution Hash Status: Downloaded newer image for postgres:latest docker.io/library/postgres:latest Click to expand and view more 每个镜像由一系列 layer 构成, 每个 layer 有自己的哈希, 这意味着整个镜像也可以有一个用于识别它的唯一哈希, 在 layer 列表后看到的那个值就是\nPLAINTEXT Collapse Copy Digest: sha256:87ec5e0a167dc7d4831729f9e1d2ee7b8597dcc49ccd9e43cc5f89e808d2adae Click to expand and view more 这个就是 image digest, 是整个镜像的唯一哈希值.\n镜像通常按名字拉取, 但 digest 在安全性方面非常关键, 用于确认拉取的镜像没有被篡改, 保证镜像的安全与真实性.\n镜像有两种类型的 digest 值:\nDistribution Digest: 压缩后镜像的哈希, 用于传输阶段 Content Digest: 每个未压缩 layer 的内容哈希 The Role of Comparession and Digest Verification 压缩与摘要检验的角色 在将镜像推送到 registry 之前, Docker 会对 layer 和镜像进行压缩以节省存储和网络流量. 压缩后会计算一个哈希, 并将其发送给 registry. registry 会基于接收到的内容, 重新计算哈希并与 DOcker 发来的哈希比较. 这个哈下就是 Distribution Digest. 当另一端拉取镜像时, Docker 会计算接收到内容的哈希并与原始的 Distribution Digest 比对, 确保镜像在传输过程中未被篡改.\nPLAINTEXT Collapse Copy # Content Hash $ docker image inspect redis ... \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:f5fe472da25334617e6e6467c7ebce41e0ae5580e5bd0ecbf0d573bacd560ecb\u0026#34;, # \u0026lt;--- Content Digest \u0026#34;sha256:3e62a323d3749bd1fc58ef850f0d6e5a9c901f71cc160426da9f6fb7507293ef\u0026#34;, \u0026#34;sha256:b5a15fcf554ab5310928776fceacdc57d225c145d96a3d3b62382a31684a6c7e\u0026#34;, ..., \u0026#34;sha256:ca15e9bb0d852a5e8c1d4c3264fa085f68197056b80da09003764bfa6dda5067\u0026#34; ] }, Click to expand and view more PLAINTEXT Collapse Copy # Distribution hash $ docker images --digests redis redis latest sha256:ca65ea36ae16e709b0f1c7534bc7e5b5ac2e5bb3c97236e4fec00e3625eb678d 4075a3f8c3f8 13 days ago 117MB Click to expand and view more Image Registry 镜像仓库 镜像仓库是容器镜像的存储中心, 各类软件, 像 Redis、Postgres、Node.js 这样的热门软件会把他们的容器化版本存放在这里. 这些仓库让用户可以方便地随时访问这些镜像, 虽然存在许多仓库, 但最广泛的是 Docker 的镜像仓库 - Docker Hub.\n当运行类似 docker pull \u0026lt;image-name\u0026gt; 的命令时, 其实在使用一个简写. 完整的命令包含注册中心 registry, 组织 organization 和标签 tag, 如下所示:\nPLAINTEXT Collapse Copy docker pull \u0026lt;registry\u0026gt;/\u0026lt;organization\u0026gt;/\u0026lt;repository\u0026gt;:\u0026lt;tag\u0026gt; # 例如 # docker pull docker.io/library/redis:latest # docker pull docker.io/fredj/sample:1.0 Click to expand and view more 当省略某些细节时, Docker 会做一些默认假设来补全:\nRegistry \u0026amp; Organization: 如果不指定, docker 默认使用 Docker Hub (docker.io), 并假设官方镜像位于 library 组织下 Tag: 如果不提供 tag, Docker 会拉取标记为 latest 的镜像 Repository: The Heart of the Registry | 仓库: 镜像仓库的核心 仓库 repository 是镜像仓库中的核心单位. 每个 registry 托管多个 repository, 每个 repository 代表一个应用或工具, 例如 redis、postgres、alpine、node. 在一个 repository 下可以有多个 tag, 每个 tag 对应镜像的一个具体版本.\n有点类似 Git: Docker 的 repository 有点类似, 可以包含多个带标签的版本. 例如:\nRedis 在 GitHub 上带有标签的发布 类似的, Docker 上的 Redis 仓库也有标签 Two Types of Repositories on Docker Hub | Docker Hub 上的两类仓库 官方仓库 Offical Repositories\n这些是经过 Docker 官方策划与验证的高质量镜像, 位于仓库的顶层, 因此可以不写组织名直接拉取, 例如:\nPLAINTEXT Collapse Copy docker pull ubuntu Click to expand and view more 这些官方仓库包含像 Redis、Ubuntu、Python、Node.js 等流行工具的镜像\nRegular Repositories 普通仓库\n这些由个人、团队或组织创建, 拉取普通仓库的镜像时通常需要指定组织, 例如:\nPLAINTEXT Collapse Copy docker pull mycompany/sample:1.0 Click to expand and view more Other Registries 其他仓库 虽然 Docker Hub 是默认选项, 但他并非唯一选择, 还有很多其他仓库, 例如:\nAWS Elastic Container Registry (ECR) Google Container Registry (GCR) GitHub Container Registry (GHCR) 从这些仓库拉取镜像时, 需要在命令中指定 registry 名称, 例如:\nPLAINTEXT Collapse Copy docker pull \u0026lt;registry\u0026gt;/\u0026lt;organization\u0026gt;/\u0026lt;repository\u0026gt;:\u0026lt;tag\u0026gt; # 例如 # docker pull ghcr.io/myteam/myapp:1.0 Click to expand and view more 不同的镜像仓库之所以能无缝工作, 是因为遵循了 OCI 标准, 它定义了镜像的创建与分发方式. 两个关键标准是:\nImage Specification: 定义容器镜像如何创建, 像一个通用的镜像蓝图规范 Distribution Specification: 规定镜像如何在注册中心之间共享和分发 只要注册中心和镜像遵循这些标准, 使用什么工具制作镜像, 把镜像发布到哪个 registry, 都能互相兼容, 像魔法一样地协同工作.\nConclusion 结论 Docker 镜像与层构成了容器化应用开发的骨干. 理解镜像如何构建, 存储与分发是掌握 Docker 的重要一步. 这些概念不仅是理论上的, 还是让容器轻量、可重用并高效的实用工具.\n","title":"Docker - Images and Registeries"},{"link":"/posts/docker-engine-and-netowrking/","text":"Docker 引擎(Docker Engine), 顾名思意，是 Docker 的核心. 它为 Docker 提供动力, 并承担所有繁重的工作. 本文将深入探讨这一关键组件的内部运作, 以便了解 Docker 在内核下是如何工作的.\nThe Evolution of the Docker Engine | Docker 引擎的演进 Docker 最初是一个巨大的单体(monolith), 所有代码都塞在同一个项目里. 对于 dotCloud来说, 这种方式一开始是可行的. 实际上, 这个方向运作得非常好, 以至于他们放弃了其他服务、把所有赌注都押在 Docker 上, 甚至把公司重命名为 Docker, Inc.\n一开始, Docker 是一个又大又混乱的单体应用. 随着时间推移, Docker, Inc. 发现这种做法不可持续, 他们需要把系统拆分出来:\n各个部分可以独立成长 更容易升级某些部分 - 可以替换旧组件而不影响整体 让社区更容易参与贡献 - 更小的组件意味着更多人能参与进来 更易跨平台 - 他们想要 Docker 在每个平台上运行, 而不只是 Linux 拆分的第一步是把客户端 client 剥离出来. 把客户端从大应用中抽出, 赋予它新职责: 把用户命令翻译成 Docker 引擎能理解的指令(也就是原来单体里\u0026quot;内核部分\u0026quot;的接口)\n此时, Docker 引擎主要有两部分:\nDaemon 守护进程: 处理容器、网络和卷 LXC: Docker 与 Linux 内核之间的中间层 Breaking Things for the Better 为了更好的架构而拆分 然而, 这个架构存在问题:\nLXC 仅限于 Linux, 若要支持 Windows 或 macOS 这就难办了 守护进程负担过重, 它做的事情太多, 需要\u0026quot;放轻松\u0026quot; 因此, Docker 放弃了 LXC, 缓存更灵活, 冯举平台适应性的 libcontainer. 同时, 他们也减轻了守护进程的职责, 把守护进程做成更简单的 API 接口, 供客户端与之通信.\n但这还不是终点. libcontainer 本身仍然太大、太笨重. 于是 Docker 把它进一步拆成更小的部分: docker-init、runc、containerd 和 shim, 每个组件只做一件事, 这带来了:\n更好的分工协作: 社区可以专注于特定组件 自由试验: 开发者可以像搭积木一样替换或组合部件 更清晰的设计: 不再是纠结在一起的杂乱代码 Specs and Standards 规范与标准 Docker 引擎严格遵循开放容器倡议 OCI 的协议和标准, 意味着你用 Docker 引擎构建的镜像, 只要目标平台也遵循 OCI 标准, 就能在别的容器平台上运行.\nDocker 引擎帮助你 build 构建、ship 分发和 run 运行符合 OCI 的镜像, 这三个阶段由三大标准引导:\nImage Specification 镜像规范: 该规范定义了容器镜像如何被创建, 相当于容器内部包含内容(依赖、配置等)的详细蓝图 Distribution Specification 分发规范: 该规范规定了容器镜像如何共享与传输, 相当于定义了一套\u0026quot;运输网络\u0026quot;的规则, 确保镜像能从 A 点到 B 点顺利传输 Runtime Specification 运行时规范: 该规范描述容器如何被执行和管理, 从启动/停止到与宿主系统交互, 即运行时的行为规则 历史部分就到这, 下面进入重点: 逐块剖析 Docker 的当前架构, 看看它们如何协同\nHow a Command is Processed in the Docker System? 一个命令是如何被处理的? 现在来拆解一下, 当运行如下命令时发生是事情:\nBASH Collapse Copy docker start my-container Click to expand and view more 这实际上是在和 Docker CLI (client) 打交道, CLI 就像是翻译器, 将输入的命令转换成 Docker daemon 守护进程能懂的东西.\n流程大致如下:\nCommand Translation 命令翻译: Docker CLI 将命令转换为一个 API 调用, 例如 REST 或 gRPC, CLI 会将输入命令翻译成这两种格式之一 Sending the Request 发送请求: 翻译完成后 CLI 将请求发送给 Docker daemon, 即守护进程, 是操作中心, 它接受请求、处理请求, 并在幕后完成实际工作 因此, 当输入 docker start my-container 的时候, CLI 会告诉守护进程, 守护进程收到后就开始工作, 协调一切将容器启动起来\nThe Daemon 守护进程 守护进程就像 Docker 的前台接待员, 它为客户端 (例如 Docker CLI) 提供一个接口, 通过高级抽象与 Docker 引擎交互. 当守护进程接到请求时, 他会验证并处理该命令, 然后将请求翻译为更低一级的指令, 交给另一个模块 containerd\ncontainerd 顺带一提: c 小写是风格选择; d 表示 daemon\nDocker 引擎的模块化设计意味着它被拆分为更小的组件, 模块化的好处是灵活与可扩展: 可以替换、更新或者扩展单个部件, 而不是修改整个系统\ncontainerd 是一个高层运行时(high-level runtime), 复杂从容器声明周期的整体角度进行管理, 就像项目经理:\n创建、启动、停止并删除容器 管理网络与卷 (volumes) 拉取镜像 (pull images) 处理容器级别的其他需求 当守护进程将命令发送给 containerd 时, containerd 会准备容器, 但不直接执行容器的实际进程, 它依赖一个更低层次的专用运行时 runc 来完成具体工作.\nrunc r 小写是 Unix 风格, c 指 container 容器\nrunc 的职责非常单一: 运行 OCI 容器, 这里的 OCI 指的是行业标准的容器和镜像协议, 为了兼容与互操作而存在.\n创建容器环境 启动容器进程 确保容器在宿主环境的边界内运行 虽然 runc 很重要, 但 containerd 与它的交互方式引入了额外的一些灵活性, containerd 并不直接与 runc 强耦合: 它通过一个抽象, shim 来与 runc 交互.\nShims 桥接进程 在 containerd 的上下文中, shim 是一个轻量级的进程, 位于 containerd 和实际的容器运行时之间. 它的主要作用是将 containerd 与运行时解耦, 保证灵活性与独立性, 这允许 containerd 管理容器, 而无需紧密耦合到特定运行时.\n当 containerd 启动一个容器时, 他会启动一个 shim 进程, shim 则调用运行时来设置容器. runc 完成诸如设置命名空间和 cgroups, 挂载文件系统, 启动容器化等\u0026quot;重活\u0026quot;. 但一旦容器启动, runc 就会退出, 留下 shim 来管理容器的声明周期交互. shim 功能如下:\n流程管理: 保持容器进程存活并处理信号 I/O 流: 保持日志并转发容器与 containerd 之间的输入/输出 声明周期事件: 监控并上报诸如容器终止等事件 如果所有底层运行时都遵循 OCI 运行时规范, 为什么 containerd 还需要 shim? 单胺是模块化和关注点分离:\n解耦: shim 抽象出容器特定的操作, 使 containerd 能专注于管理多个容器以及他们的网络与卷, 而不必处理每个容器的细节 灵活性: 有了 shim 就可以比较容易替换掉 runc, 改用同样遵守 OCI 的其他运行时, 架构因此能使用新技术 简化: 每个 shim 只处理一个容器, 这种分离确保单个应用容器的问题不会波及到其他容器 From Shim to Docker-init 当 shim 接手后, 它继续管理容器的生命周期. 不过, Docker 引擎还需要与容器内的进程交互, 比如确保日志、信号和资源得到适当处理. 这就是 docker-init 的作用, 它在容器内部充当 PID 1 的角色, 管理并清理容器化应用的资源.\nDocker-init: The Unsung Hero of Containers / 容器中的无明英雄 在每个容器内部, PID 1 是最关键的首个进程. 容器只要 PID 1 运行, 就存活. 所以, PID 1 的容器生命周期的基石. 当 containerd 需要停止或终止容器时, 他会依赖 PID 1 来确保容器内的所有子进程被正确清理. 如果 PID 1 退出, 所有关联的子进程会自动被终止.\ndocker-init 的关键作用之一是清理僵尸进程 zombie processes, 那些执行完没有被父进程回收的\u0026quot;被遗忘\u0026quot;的子进程. 这类进程若放任不管, 会逐渐占用系统资源. docker-init 会及时回收它们, 保持容器环境整洁与高效.\n另一项重要任务是处理系统信号(例如 SIGTERM 或 SIGINT), 许多容器化应用本身并不善于处理这些信号, 可能导致不完整或粗暴的关闭. docker-init 会捕捉这些信号, 并适当地转发, 保证容器内的应用能优雅地退出.\n作为 PID 1, docker-init 也为容器化应用提供了一个可预期且稳定的运行基础. 它的存在简化了容器生命周期的管理, 使容器更加稳定可靠.\n总之, docker-init 确保容器保持干净, 响应迅速并得到良好管理. 它不一定显眼, 但正是这些细小的贡献让容器变得可靠且高效.\nNetwork Ports and Unix Sockets 网络端口和Unix套节字 Docker CLI 和 docker daemon 可以通过 Unix Sockets 和 network ports 沟通. Docker, Inc. 已经向 Internet Assigned Numbers Authority(IANA)注册了3个端口, 用于Docker daemon 和 client:\nTCP port 2375 用于未加密连接 port 2376 用于 SSL 加密连接 port 2377 用于 Docker Swarm mode 在需要使用不同设置的场景下, 更换端口配置很容易. Docker 安装程序的默认设置是只使用 Unix 套接字与本地 Docker 守护进程通信. 这样做可以确保系统默认采用尽可能安全的安装方式. 这个选项同样可以方便地修改, 但强烈建议不要用网络端口来暴露 Docker, 因为 Docker 守护进程内部并没有用户认证和基于角色的访问控制. Unix 套接字在不同操作系统的路径可能不同, 但在大多数情况下可以在 /var/run/docker.sock 找到.\nContainer Networking 容器网络 尽管 Linux 容器在很大程度上是宿主机上运行的进程, 但在网络层他们通常表现得与其他进程很不一样. Docker 最初只支持一种网络模型, 但现在提供了多种稳健的配置, 可以曼珠大多数应用的需求. 大多数人以默认配置运行容器, 这称为桥接模式 Bridge Mode.\n要理解桥接模式, 最容易是把每个 Linux 容器看作是在私有网络上的一台主机. Docker 服务器充当一个虚拟桥 virtual bridge, 容器则是作为桥后的客户端. 桥只是一个把一侧流量转发到另一侧的网络设备. 因此, 可以将它想象成一个虚拟网络, 每个容器像附着在该网络上的主机. 实际上是: 每个容器都有一个虚拟以太网接口连接到 Docker 桥, 并未该虚拟接口分配一个 IP 地址. Docker 运行在宿主机上绑定并暴露单个或一组端口到容器, 以便外部世界可以通过这些端口访问容器, 流量很大程度上由 vpnkit 库来管理.\nDocker 从 未使用的 RFC 1918 私有子网块中分配私有子网, 它检测主机上有哪些网络块未被使用, 并把其中一个分配给虚拟网络. 该网络通过服务器上的一个名为 docker0 的接口桥接到宿主机的本地网络. 这意味着默认情况下, 所有容器都在同一个网络中, 可以直接相互通信. 但要达到宿主机或外部网络, 他们会通过 docker0 虚拟桥接接口转发出去.\n有多种方式配置 Docker 的网络层, 从分配自己的网络块到配置自定义桥接接口, 方式繁多让人眼花缭乱. 人们通常使用默认机制, 但有时需要更复杂或更贴合应用的配置.\nSummary 总结 Docker 引擎不仅仅是一款软件, 它是一套精心设计的模块化组件系统, 这些组件协同工作以实现容器的高效、可扩展与可移植. 从 CLI 中敲下命令, 到 runc、shim、docker-init 所处理的底层操作, 每个元素都扮演者明确且重要的角色.\n通过遵守严格的 OCI 标准, Docker 确保其生态系统不仅强大, 且具备通用兼容性. 这种遵循标准的做法建立了信任, 为开发者与企业提供了稳定的基础, 模块化架构简化了容器管理, 并鼓励创新, 允许每个组件独立演进与改善.\n理解 Docker 引擎不仅是知道容器如何工作, 更是认识其背后经过深思熟虑的工程设计. 正是这种工程让现代软件开发更快、更高效、更容易上手.\n","title":"Docker - Engine and Netowrking"},{"link":"/posts/docker-history/","text":"The Docker Story - Part1: Docker History docCloud - 也就是开发 Docker 的公司, 最初是一家 PaaS(平台即服务)公司, 他们在 PaaS 领域并没有太大的成功, 但他们构建了一个可以无缝管理客户系统与架构的工具: Docker. 2013 年, 他们决定放弃 PaaS 服务, 将全部精力投入到 Docker 这款产品上.\nContainers 容器 Docker 公司并没有发明容器这个概念. 实际上, 容器的概念已经演进了十多年, 很多参与者都做出了贡献, Linux 基金会和 Google 是推动整个生态走向成熟的重要力量.\n假如你在运营一家公司, 希望将应用上线, 以前需要做的事大概是:\n购买一台服务器 安装所有必要的应用和依赖 配置环境以匹配你的开发设置 部署应用 把服务器对外开放 看起来很简单, 但实际操作会很复杂:\n要手动跟踪并更新每个依赖和配置 如果出问题, 需要手动去修复 基础设施团队需要估算服务器规格(内存、CPU 等) — 为了防止流量高峰崩溃, 通常会配置更高的规格(过度配置) 那台高配服务器大多数时间只是闲置着, 做最少量的工作 不能轻易扩展或在同一服务器上运行多个应用, 因为每个应用都需要独立的运行环境 总之, 非常混乱\n后来出现了虚拟机(VM), 情况有了改善. 使用 VM 可以:\n在同一台服务器上运行多个隔离的环境 为 VM 做快照并在不同服务器间复用 不再重复重复地搭建环境，这是一个很大的进步 但 VM 也有缺点:\n重量级: 每个 VM 需要完整的操作系统，占用大量内存、CPU 和存储 性能开销大: 运行多个操作系统实例会带来额外开销, 性能相对较差 启动慢: 每个 VM 都需要启动自己的操作系统 占用空间多: 完整的操作系统镜像占用大量磁盘空间 于是容器出现了 — 它带来了颠覆性的改变\n容器是应用的轻量级、可移植打包. 它包含:\n你的应用 应用的所有依赖（库、二进制文件等） 配置文件 环境变量 运行所需的其他数据 容器非常灵活. 你可以有一个带最精简 Ubuntu 的容器, 另一个容器装 Node.js 应用, 或任何你需要的组合. 容器被设计得尽可能精简, 剔除了诸如 GUI、驱动等不必要项, 从而保持轻量.\n真正的关键是: 容器共享宿主机的操作系统内核(host OS kernel). 不同于 VM, 容器不需要自己的完整操作系统, 这节省了大量资源. 举例来说, 如果一台服务器能跑 10 个 VM, 那么同样的机器可能能跑 50 个容器, 这是性能与效率的巨大跃升\nThe Open Container Initiative (OCI) 开放容器倡议 OCI 由 Google、Linux 基金会和 Docker, Inc. 的人员发起, 定义了一些关键标准, 包括:\n镜像规范(Image Specification / Image-Spec): 定义容器镜像如何创建 运行时规范(Runtime Specification / Runtime-Spec): 标准化容器如何被执行和管理生命周期 分发规范(Distribution Specification / Distribution-Spec): 定义容器镜像如何共享与分发 这些规范保证了任何系统能以一致的方式创建、运行和管理容器\nThe Cloud Native Computing Foundation (CNCF) 云原生计算基金会 CNCF 成立于 2015 年, 使命是推动容器技术并让云原生计算成为现实. 它不像 OCI 那样直接制定标准, 而是专注于帮助与容器相关的项目成长并达到可投入生产的成熟度.\nCNCF 项目一般经历三个阶段:\nSandbox 沙箱: 实验性项目的试验场 Incubation 孵化: 对有前景的项目进行积极开发和完善 Graduation 毕业: 达到标准并可用于生产环境 当一个项目\u0026quot;毕业\u0026quot;时, 公司会知道它已经可靠到可以在自身基础设施上使用. 一个典型例子是 Kubernetes, 它作为 CNCF 项目成长, 现已成为现代基础设施的基石.\nThe Docker Inc, The Docker Platform 正如前面提到的, dotCloud 放弃了 PaaS，把重心放到 Docker, 并更名为 Docker, Inc. 他们把工具集称为 Docker Platform, Docker 平台主要由两大部分组成: 客户端(Client)和引擎(Engine). Docker 客户端(命令行界面 CLI)是与 Docker 引擎交互的方式.\nDocker CLI Docker CLI 是一组命令和指令, 用来与 Docker 引擎交互. 它通过提供一个对复杂内部系统的友好抽象来简化操作, Docker CLI 通过 gRPC API 与 Docker 引擎通信. 基本上, CLI 会把我们的命令(例如 docker ps、docker start、docker stop 等)翻译成 gRPC 请求并发送给 Docker 引擎, 然后再把执行结果以可读的形式显示在终端上.\nDocker Engine Docker 引擎是实际执行工作的地方. 它是一个模块化的应用, 包含许多关键组件. 把它想象成汽车发动机: 大多数人不知道引擎内部的具体细节, 但它能无缝工作. 类似地, 作为用户我们通过 CLI 与 Docker 引擎交互, 指示它去执行各种动作, 而不必了解内部所有细节. 然而, 要深入理解 Docker, 了解引擎内部发生了什么是很重要的.\nDocker 引擎向客户端暴露了一个 API 层, 客户端使用该 API 把命令转成 gRPC 调用并与服务器交互. Docker 引擎封装了创建、运行与管理容器所需的全部复杂性. 值得一提的是, Docker 引擎和 Docker CLI 都是用 Golang 语言编写的.\n","title":"Docker - History"},{"link":"/posts/how-ai-assistants-make-precise-edits-to-your-files/","text":"之前的文章介绍了如何制作一个基本的 AI 编程助手, 今天更近一步, 探讨 AI 助手如何对文件进行精确的修改.\n实际的 AI Agent 不会读取所有的项目代码, 一般只会读取当前文件的代码, 当需要时才会去读取相关的代码文件. 然而, 输出也不会输出要修改的整个文件的代码, 因为这样输出不仅很慢, 同时成本也很高, 会有大量重复代码导致浪费(以 deepseek 为例, 输出 token 的价格是输入 token 价格的3倍, 是缓存命中输入 token 价格的24倍!), 因此一般是让模型输出要修改的代码和修改后的代码.\n既然不能一次输出文件的所有代码, 这就引出了一个问题: 如何精确的修改代码文件? 首先要确定一种让模型准确地描述修改的格式, 并且提供健壮的格式匹配与错误重试机制(模型输出代码可能少个空格或者Tab), 这篇文章对这个问题做了探讨.\n将 AI agent 生成的代码直接修改到文件中是一项核心能力, 然而实际上这常常出乎意料的困难, agent 可能会提出一个代码修改方案, 但实际修改却失败, 例如\u0026quot;找不到匹配的上下文\u0026quot;之类的错误, 需要手动干预. 许多 AI 编程助手的开发者都遇到过这种情况, 虽然 AI 理解代码的意图, 但将这种理解转化为精确的文件修改却带来了重大的技术挑战.\nWhy Precise File Editing Matters 为什么精确的文件编辑至关重要 有效的文件编辑是编程助手的价值核心, 如果其不能可靠的修改文件, 需要人为手动修改, 就退化成了 AI 聊天引擎, 相比之下, 一个能够可靠自动化编辑的助手可以为开发者节省大量时间和认知负担.\n根本的挑战在于, LLM 缺乏直接的文件系统访问权限, 他们必须通过专门的工具来描述预期的修改, 然后这些工具或 API 解释指令并尝试执行, LLM 的描述与文件系统状态之间的这种交接是常见的问题来源.\n使用 GitHub Coplit、Aider、RooCode 或 Cursor 等工具的用户可能已经观察到这些问题: 编辑器无法找到正确的插入点、缩进不正确, 或者工具最终请求手动应用.\nWhat Will Cover 本文内容 本文将探讨几种编程助手系统的文件编辑机制: Codex、Aider、OpenHands、RooCode和Cursor. 对于开源系统(Codex、Aider、OpenHands、RooCode), 本文提供的见解来源于分析它们各自的代码库. 于闭源的Cursor, 见解则来自公开讨论及其团队的访谈.\n对于每个系统, 将分析:\n它如何从AI接收编辑指令 它如何解释和处理这些指令 它如何将更改应用到文件 它如何处理错误和边缘情况 它如何提供结果反馈 理解这些机制有助于深入了解自动化代码编辑的困难以及不同系统采用的日益复杂的解决方案.\nKey Concepts in AI Coding Agent 编程助手的核心概念 在继续之前, 先定义一些该领域常用的术语:\nPatch 补丁: 文件更改(添加、删除)的正式规范, 通常包含元数据, 如文件路径和应用的上下文. Diff 差异: 一种突出显示文本版本间逐行差异的范式, 通常使用 + 和 - 标识符, 侧重与内容变更 Search/Replace Block 搜索/替换块: 使用一种分隔符(例如 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; SEARCH, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; REPLACE) Context Lines 上下文行: 包含在 Patch 或 Diff 中围绕更改的未修改行, 用于精确定位修改点 Hunk 块: Patch 或 Diff 中的连续修改块, 包含上下文行和修改 Fuzzy Matching 模糊匹配: 用于查找文本字符串近似匹配的算法(例如 Levenshtein 距离), 处理微小差异 Indentation Preservation 缩进保留: 在文件编辑其间保持一致的空白缩进(Space、Tab), 对语法和可读性至关重要 Fench 围栏: 分隔符(例如```), 用于在文本或指令中清晰标记代码块的边界 The File Editing Workflow 文本编辑流程 大多数 AI 代码编辑系统遵循一个通用流程:\nPLAINTEXT Collapse Copy LLM(生成变更描述) → 工具(解析和应用) → 文件系统(状态变更) → 反馈(工具返回结果) → LLM(处理反馈) Click to expand and view more 上面流程中有这些挑战:\n1. Locating the Edit Target 定位编辑目标 LLM 通常基于目标文件可能已过时, 或不完整的视图进行操作, 在以下情况很难找到预期的编辑位置:\nLLM 上次访问后, 文件已修改 文件包含多个相似的代码片段 文件超出了 LLM 的上下文窗口量 当文件状态出现分歧时, 上下文不匹配很常见, 健壮的系统提供详细的错误反馈, 使LLM能够适应.\n2. Handling Multi-File Changes 处理多文件变更 代码修改经常涉及多个文件, 这引入了复杂性:\n确保相关编辑的一致性 管理文件之间的依赖关系 以正确的顺序应用修改 大多数系统通过按文件顺序处理编辑来解决这个问题\n3. Maintaing Code Style 保持代码风格 开发者要求遵守特定的格式约定, 自动化编辑必须保留:\n缩进风格 (空格/宽度) 行尾约定 注释格式 一致的间距模式 4. Managing Failures 管理错误 一个健壮的编辑系统应该优雅地处理失败:\n提供清晰的错误原因解释 提供诊断信息以帮助纠正 在初始失败时尝试替换策略 Common Edit Description Formats 常见的编辑描述格式 AI 系统使用多种格式来传达预期的更改:\nPatchs 补丁: 详细的添加/删除指令, 通常基于标准补丁格式 Diffs 差异: 显示原始状态和期望之间的差异 Search/Replace Blocks 查询/搜索块: 明确定义于查找/替换操作 Line Operations 行操作: 按行号指定编辑(不太常见, 效果很差) AI-Assisted Application AI辅助应用: 使用辅助AI模型专门应用复杂的更改 下面看看具体系统如何实现这些概念\nCodex: A Straightforward Patch-Based System 一个简单的基于补丁的系统 OpenAI 的 Codex CLI 使用一个相对简单、结构化的补丁格式, 其有效性部分源于 OpenAI 能够专门训练其模型以可靠地生成这种格式.\nThe Codex Patch Foramt | Codex 补丁格式 LLM 使用以下格式表达修改\nPLAINTEXT Collapse Copy *** Begin Patch *** [Operation] File: [filepath] @@ [text matching a line near the change] [context line (unchanged, starts with space)] - [line to remove (starts with -)] + [line to add (starts with +)] [another context line] *** End Patch Click to expand and view more 关键特性:\nOperation: 添加文件(Add File)、更新文件(Update File)或删除文件(Delete File) @@: 后面跟着编辑位置附近一行的文本内容(例如函数/类定义), 用于定位更改, 避免了对行号的依赖 Context lines: 上下文行, 以空格开头, 必须匹配现有文件内容且保持不变, 用于精确定位. 以 - 开头的行: 标记为要删除 以 + 开头的行: 标记为要添加 如下面这个例子\nPLAINTEXT Collapse Copy *** Begin Patch *** Update File: main.py @@ def main(): # This is the main function - print(\u0026#34;hello\u0026#34;) + print(\u0026#34;hello world!\u0026#34;) return None *** End Patch Click to expand and view more 这里, @@ def main(): 帮助定位函数, 而以空格开头的上下文行(# This is ... 和 return None) 精确定位了确切的编辑位置\n系统尝试精确匹配 @@ 行和上下文行, 如果失败, 则采用回退策略: 首先尝试删除行尾后的匹配, 然后尝试删除所有空白后的匹配, 这种灵活性考虑到了 LLM 视图与实际文件之间的微小差异, 一个补丁可以包含多个 @@ 部分以定位文件的不同部分.\nPatch Parsing and Application 补丁解析和应用 通过 apply_patch 工具接收到补丁后, 系统执行以下步骤:\n验证补丁结构是否正确 (*** Begin Patch / *** End Patch) 找到目标文件 加载目标文件的当前内容 将补丁解析为离散的操作 尝试将更改应用到加载的文件内容中 Fuzzy Matching for Robustness 健壮的模糊匹配 对上下文的渐进式匹配策略增加了健壮性:\n尝试精确匹配 如果失败, 尝试忽略行尾的匹配 如果失败, 尝试忽略所有的空白匹配 这有助于模型预期的文件内容, 和实际文件内容的微小差异\nError Handing and Feedback Mechanisms 错误匹配和反馈机制 Codex 在失败时提供结构化的 JSON 反馈, 帮助 LLM 进行纠正尝试\n上下文不匹配 (清晰地指出了不匹配和不同的行)\nJSON Collapse Copy { \u0026#34;exit_code\u0026#34;: 1, \u0026#34;stderr\u0026#34;: \u0026#34;Error: context line 3, \\\u0026#34; const response = await fetch(`/api/users/${userId}`);\\\u0026#34; does not match \\\u0026#34; const response = await fetch(`/api/users/${userId}`, { headers });\\\u0026#34;\u0026#34; } Click to expand and view more 文件未找到 (明确的文件访问错误)\nJSON Collapse Copy { \u0026#34;exit_code\u0026#34;: 1, \u0026#34;stderr\u0026#34;: \u0026#34;Error: File not found: src/api.js\u0026#34; } Click to expand and view more 无效的补丁格式 (特定的格式违反反馈)\nJSON Collapse Copy { \u0026#34;exit_code\u0026#34;: 1, \u0026#34;stderr\u0026#34;: \u0026#34;Error: Patch must start with *** Begin Patch\u0026#34; } Click to expand and view more 这种详细的结构化反馈允许 LLM 诊断失败, 并可能修正后重试\nExample: Real-World Edit Scenario 示例: 真实世界的编辑场景 下面来看看 Codex 如何处理一个真实的编辑场景, 假设要向一个获取用户数据的函数添加错误处理\nsrc/api.js 中的原始代码:\nJAVASCRIPT Collapse Copy async function fetchUserData(userId) { const response = await fetch(\u0026#39;/api/users/${userId}\u0026#39;); const data = await response.json(); return data; } Click to expand and view more LLM 生成一个补丁:\nPLAINTEXT Collapse Copy *** Begin Patch *** Update File: src/api.js @@ async function fetchUserData(userId) { - const response = await fetch(`/api/users/${userId}`); - const data = await response.json(); - return data; + try { + const response = await fetch(`/api/users/${userId}`); + if (!response.ok) { + throw new Error(`Failed to fetch user data: ${response.status}`); + } + const data = await response.json(); + return data; + } catch (error) { + console.error(`Error fetching user ${userId}:`, error); + throw error; + } } @@ function formatUserData(data) { - return data; + return { + id: data.id, + name: data.name, + email: data.email, + formattedDate: new Date(data.createdAt).toLocaleDateString() + }; } *** End Patch Click to expand and view more 这个例子显示了一个修改同一文件中两个不同函数的补丁, 每个函数都有自己的 @@ 上下文标记\nOpenAI\u0026rsquo;s Patch Format Standardization | OpenAI 的补丁格式标准化 随着 GPT-4.1 (2025-04) 的发布, OpenAI 发布了一个 \u0026ldquo;Prompt Cookbook\u0026rdquo;, 详细介绍了这种推荐的补丁个似乎和一个参考实现(apply_patch.py). 他们指出对 GPT-4.1 在此格式上进行了大量训练, 这有助于其在 Codex CLI 生态系统中的有效使用.\nOpenAI 的评论强调, 成功的格式通常避免使用行号, 并使用不同的分隔符清晰地提供要替换的代码及其替换内容, 这为可靠的 AI 驱动编辑提出了核心原则.\nAider: A Multi-Format Editing System | Aider: 一个多格式编辑系统 Aider 采用了一一种更灵活的方法, 支持多种编辑格式, 可以选择最合适任务或特定 LLM 的格式.\nPluggable Edit Format Architecture 可插拔的编辑格式架构 Aider 使用一个\u0026quot;编码器\u0026quot; Coder 类系统, 每个类负责处理特定的编辑格式:\nPYTHON Collapse Copy class Coder: # ... def get_edits(self): # 将 AI 响应解析为编辑操作 raise NotImplementedError def apply_edits(self, edits): # 将解析后的编辑应用到文件 raise NotImplementedError Click to expand and view more Supported Edit Formats in Aider | Aider 中支持的编辑格式 Aider 指出多种格式, 根据模型或用户配置 (--edit-format) 进行选择\nEditBlock Format (Search/Replace) 编辑块格式: 直观的格式, 清晰显示搜索/替换块\nPLAINTEXT Collapse Copy file.py \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; SEARCH # Code block to find ======= # Code block to replace with \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; REPLACE Click to expand and view more Unified Diff Format(udiff) 统一差异格式: 标准差异格式(diff -U0 风格), 适用于复杂更改\nPLAINTEXT Collapse Copy --- file.py +++ file.py @@ -10,7 + 10,7 @@ - return \u0026#34;old value\u0026#34; + return \u0026#34;new value\u0026#34; Click to expand and view more OpenAI Patch Format | OpenAI 补丁格式: Aider 实现了 OpenAI 的参考格式, 利用了 GPT-4.1 再此语法上的训练\nPLAINTEXT Collapse Copy *** Begin Patch *** Update File: file.py @@ class MyClass: def some_function(): - return \u0026#34;old\u0026#34; + return \u0026#34;new\u0026#34; *** End Patch Click to expand and view more 其他格式:\nwhole: LLM 返回完整的修改后文件内容, 简单, 但对于大文件可能效率地下. diff-fenced: 差异格式变体, 文件名在代码围栏内, 用户 Gemini 等模型 editor-diff / editor-whole: 用于特定内部模式的简化版本 Flexible Search Strategies 灵活的搜索策略 当应用搜索/替换块时, Aider 尝试按顺序使用多种匹配策略:\n精确匹配 空白不敏感匹配 保留缩进的匹配 使用 difflib 进行模糊匹配 这种分层方法增加了即使 SEARCH 块存在微小缺陷, 也能成功修改的可能性\nDetailed Error Reporting 详细的错误报告 Aider 在编辑失败时擅长提供信息丰富的反馈\nPLAINTEXT Collapse Copy # 1 SEARCH/REPLACE block failed to match! ## SearchReplaceNoExactMatch: This SEARCH block failed to exactly match lines in src/api.js \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; SEARCH async function fetchUserData(userId) { const response = await fetch(`/api/users/${userId}`); const data = await response.json(); return data; } ======= ... \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; REPLACE Did you mean to match some of these actual lines from src/api.js? async function fetchUserData(userId) { const response = await fetch(`/api/users/${userId}`); // Some comment here const data = await response.json(); return data; } The SEARCH section must exactly match an existing block of lines including all white space, comments, indentation, docstrings, etc # The other X SEARCH/REPLACE blocks were applied successfully. Don\u0026#39;t re-send them. Just reply with fixed versions of the blocks above that failed to match. Click to expand and view more 这种反馈比简单的失败消息要详细得多, 它解释了不匹配的原因, 建议了潜在的正确目标, 重申了匹配规则, 并指示 AI 如何继续, 这种详细的指示极大地提高了 AI 纠正错误修改的能力.\n在采用 OpenAI 格式的同时, Aider 通过更大的灵活性和更丰富的错误处理对齐进行了增强.\nOpenHands: Blending Traditional and AI-Assisted Editing / 融合传统和AI辅助编辑 OpenHands 主要依赖传统的编辑应用方法, 同时也包括一个可选的基于 LLM 的编辑功能\nTraditional Edit Application 传统编辑应用 OpenHands 主要使用传统的编辑方法, 内置支持检查不同的补丁格式, 包括: 统一差异(unified diffs)、git 差异、上下文差异(context diffs)、ed 脚本和 RCS ed 脚本(使用正则表表达式). 该系统支持几种传统的编辑方法:\n字符串替换 基于行的操作(按行号) 标准补丁应用工具 包括注入空白规范化之类的功能, 以处理补丁缩进的变化\nOptional LLM-Based Editing Feature 可选的基于LLM的编辑功能 OpenHands 允许配置一个单独的\u0026quot;草稿编辑器\u0026quot; LLM, 用于一个独特的编辑工作流程:\n目标识别: 主 LLM 指定要编辑的目标行范围 内容提取: 工具提取这个特定的代码段 LLM 重写: 提取的片段和所需要更改的描述被发送到专门的\u0026quot;草稿编辑器\u0026quot; LLM, 这个编辑器 LLM 可以有不同的配置(模型、温度), 针对编辑器进行了优化 文件重建: 工具从编辑器 LLM 接收修改后的片段, 并将其集成回收文件中, 替换原始行 为了确保草稿编辑器 LLM 产生正确的输出以供集成, 它会收到一个特定的系统提示, 指示它:\n生成修改后代码段的完整且准确的版本 如果某些部分需要保留, 则将任何占位符注释(如 # no changes needed before this line) 替换为原始段中的实际未更改的代码 确保在整个块中保持正确且一致的缩进 输出最终的、完整的编辑目录, 并精确地包括在指定的代码块中, 以便工具轻松解析 使用单独编辑器的 LLM 潜在好处:\n特定任务调优: 专门为代码修改优化参数 模型灵活性: 对推理和编辑使用不同的模型 聚焦提示: 向编辑器 LLM 提供特定的编辑提示词 重建过程仔细地组合了编辑前的内容、LLM 编辑的块和编辑后的内容, 可以执行可选的验证步骤, 如代码检查(linting). 这种基于 LLM 的编辑似乎是 OpenHands 中的一个可选的、可能是实验性的功能, 通常默认禁用.\nRooCode: Advanced Search and Format Preservation / 高级搜索和格式保留 RooCode 使用搜索/替换块格式, 其优势在于用于定位目标块的高级搜索算法, 以及在替换过程中对应代码格式的细致处理.\nAdvanced Search Strategy: Middle-Out Fuzzy Matching | 高级搜索策略: 由内而外的模糊匹配 当搜索块的精确匹配失败时, RooCode 通过其 MultiSearchReplaceDiffStrategy 采用\u0026quot;由内而外\u0026quot; (middle-out) 的模糊匹配方法\n估计区域: 在预期位置附近开始搜索 (可能由行号提示) 扩展搜索: 从这个中心点向外搜索 评分相似度: 使用 Levenshtein 距离等算法对搜索块与文件中潜在匹配项之间的相似度进行评分 选择最佳匹配: 选择超过定义阈值的最高分配项 这种策略对于大文件或行号略有不准的情况非常有效, 针对微小的上下文便宜提供了鲁棒性.\nEmphasis on Indentation Preservation 强制缩进保留 不正确的缩进是编辑文件常见的问题, RooCode 实现了一个复杂的系统来保留格式:\n捕获原始缩进: 记录原始文件中匹配行的确切前导空白 (空格/指标符) 分析相对缩进: 计算替换块中每行相对于其第一行或周围块的缩进 应用原始样式并保持相对结构: 重写应用捕获的原始缩进格式, 同时保持替换代计算出的相对缩进结构 这种缩进的细致关注对于代码可读性和语法正确性(尤其是 Python 等语言)至关重要\nRooCode 编辑过程示例\nPLAINTEXT Collapse Copy \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; SEARCH :start_line:10 ------- function calculateTotal(items) { return items.reduce((sum, item) =\u0026gt; sum + item, 0); } ======= function calculateTotal(items) { // Add 10% tax return items.reduce((sum, item) =\u0026gt; sum + (item * 1.1), 0); } \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; REPLACE Click to expand and view more RooCode 解析 diff:\n提取起始行 (10) 提取搜索块 (function calculateTotal...) 提取替换块 (function calculateTotal...) RooCode 应用 diff:\n读取文件的当前内容 使用模糊匹配找到搜索块的最佳匹配 应用替换并保留适当的缩进 显示差异视图供用户批准 如果批准则应用修改 反馈给 LLM:\n如果成功: \u0026ldquo;更改已成功应用到文件\u0026rdquo; 如果失败: 带有失败原因的详细错误信息 RooCode 将强大的模糊匹配与对维护代码格式完整性的强烈关注相结合\nCursor: Specialized AI for Change Application / 专注于变更应用的AI 当其他系统改进编辑格式或匹配算法时, Cursor 引入了一个专门的 AI 模型, 专门用于编辑过程的应用步骤.\n这直接解决了一个观察结果: 即使强大的 LLM 擅长代码生成和推理, 也可能难以生成格式完美、位置精确且可以通过简单算法干净应用的差异, 尤其是在复杂文件中.\nCursor 的方法设计两步 AI 过程:\nSketching 草图: 一个强大的主 LLM 生成预期的修改, 专注于核心逻辑, 而不是完美的差异算法, 这可能是代码的一个粗略描述 Applying 应用: 一个单独的、经过订制训练的 \u0026ldquo;Apply 应用\u0026rdquo; 模型接收这个草图. 这个专门的模型经过训练, 可以智能地将草图集成到现有的代码库中, 处理上下文、结构的细微差别, 以及输入草图中潜在的不完美之处. 它执行的操作不是简单的文本匹配, 旨在实现智能的代码集成. 这种策略将高级别的变更生成与详细的应用机制分离开来, 主 LLM 专注于更改什么, 而专业的 Apply 模型专注于如何将更改健壮且准确的集成到文件系统中.\n这里可以看到 Cursor 团队讨论这种方法\nEvolution and Convergence of Edit Formats 编辑格式的演进与融合 检查这些系统揭示了格式开发中的有趣模式:\nSearch/Replace Lineage 搜索/替换体系: Aider 的 EditBlock 格式 ( \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; / \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; ) 建立了一种直观的方法, 后来被 Cline 采用, RooCode 又在此基础上构建 OpenAI Patch 的影响: 随着 GPT-4.1 发布的特定补丁格式由于集中的模型训练而获得关注, Codex 原生使用它, 也被 Aider 作为一个选项采用 Underlying Priciples 底层原则: 尽管起源不同, 但成功的格式都趋同 OpenAI 指出的关键思想: 避免使用行号并清晰分隔原始代码和替换代码, 这些特性似乎是可靠的 AI 驱动编程的基础. Conculsion and Key Learnings 结论于关键要点 研究 AI 编程助手如何编辑文件揭示了设计复杂技术和演进策略的复杂过程.\n关键要点:\n格式很重要: 避免使用行号, 并清晰分隔前后代码的格式是普遍有效的, 尤其是在模型经过训练的情况下. 健壮的匹配关系很重要: 成功的系统采用分层匹配策略(先精确再逐渐模糊), 以在精度和处理微小差异的能力之间取得平衡. 缩进完整性能至关重要: 仔细保留空白和缩进, 对于代码正确性和开发者接受度至关重要 信息丰富的反馈支持纠正: 详细的错误消息, 对于 AI 诊断和修复失败的编辑至关重要 专业化展示前景: 使用专门的 AI 模型来处理特定的子任务, 如变更应用, 代表了一种提高可靠性的高级方法 Considerations for Tool Builders 给工具构建者的考虑因素 开发健壮的 AI 编辑工具涉及几个考虑因素:\n实施分层匹配: 从严格匹配开始, 并添加回退的模糊策略 优先考虑缩进保留: 投入精力准确维护格式 设计可操作的错误反馈: 提供具体、信息丰富的错误消息 利用现有格式和实现: 考虑已建立的格式, 并研究开源系统 ","title":"How AI Assistants Make Precise Edits to Your Files"},{"link":"/posts/make-an-ai-coding-agent-in-python/","text":"这篇文件介绍如何使用 Python 制作一个基础的 AI 编程助手\nMinimal AI Coding Agent 下面是一个 AI Coding Agent 至少需要的功能\nChat loop 对话循环 Call an LLM 调用大语言模型 Add tools to call 增加工具调用 Handle tool request 处理工具调用请求 Step 1: Chat Loop 首先, 聊天循环一直循环等待用户输入, Python 的 \u0026ldquo;input\u0026rdquo; 方法可以获取用户输入\nPYTHON Collapse Copy print(\u0026#34;Type q to quit\u0026#34;) while True: user_message = input(\u0026#34;You: \u0026#34;) if user_message == \u0026#34;q\u0026#34;: break ai_message = f\u0026#34;You said {user_message}... so insightful\u0026#34; print(ai_message) Click to expand and view more 目前主流的 LLM 都是无状态的, 所以需要我们手动的去管理对话上下文, 这里使用一个 fake_ai 函数模拟真实的 LLM 调用, 并包含 role 和 content 内容\nPYTHON Collapse Copy # step1.py import requests def fake_ai(message): latest_user_messages = messages[-1][\u0026#34;content\u0026#34;] ai_message = f\u0026#34;You said {latest_user_messages}... so insightful\u0026#34; return { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: ai_message, } print(\u0026#34;Press q to quit\u0026#34;) messages = [] while True: user_message = input(\u0026#34;You: \u0026#34;) if user_message == \u0026#34;q\u0026#34;: break messages.append({ \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_message, }) ai_message_obj = fake_ai(messages) print(\u0026#34;AI: \u0026#34; + ai_message_obj[\u0026#34;content\u0026#34;]) messages.append(ai_message_obj) Click to expand and view more Step2: Call an LLM 现在聊天循环已经设置好了正确的 API, 下面创建 llm 函数来替换 fake_ai.\nPYTHON Collapse Copy # step2.py def call_llm(messages): headers = { \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer $DASHSCOPE_API_KEY\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, } data = { \u0026#34;model\u0026#34;: \u0026#34;qwen-plus\u0026#34;, \u0026#34;messages\u0026#34;: messages, } base_url = \u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\u0026#34; try: response = requests.post(url, json=data, headers=headers) message = response.json()[\u0026#34;choices\u0026#34;][0][\u0026#34;message\u0026#34;] return message except Exception as e: return {\u0026#34;content\u0026#34;: f\u0026#34;Error: {e}\u0026#34;} while True: # ... ai_message_obj = call_llm(messages) # ... unchanged Click to expand and view more Step3: Add tools to call 哪些工具是需要的? 一个AI编码代理应该能够读取代码文件\n让我们从一个 read_file 工具开始. 我们要定义这个工具以及其参数, 然后将所有可用工具列表传递给 LLM, 当 LLM 认为某个响应需要调用工具, 它会返回一个内容为 None 的响应, 和一个要调用的工具列表.\nPLAINTEXT Collapse Copy # step3.py TOOL_SPECS = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;read_file\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Read the contents of a file\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;path\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The file path to read\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;path\u0026#34;] } } } ] def call_llm(messages): data = { \u0026#34;tools\u0026#34;: TOOL_SPECS, \u0026#34;tool_choice\u0026#34;: \u0026#34;auto\u0026#34;, } try: print(\u0026#34;Full message\u0026#34;) print(message) return message Click to expand and view more 现在, 已经完成了将工具传递给 LLM 的部分, 但是还没有处理工具调用\nStep4: Handle tool requests 虽然 LLM 可以请求调用, 但是需要程序来调用代码以添加上下文或执行操作. LLM 通常会向用户返回一个包含所有新增上下文的最终消息. 在这里需要:\nA: 检查是否存在 tool_calls 键 B: 将这条调用消息添加到消息列表 C: 调用用过, 并将调用结果添加到消息列表 D: 最后一次调用 LLM, 并传入所有的上下文 PLAINTEXT Collapse Copy # step4.py def handel_tool(tool_call): # TODO: need to call a read read_file function content = \u0026#34;This secret is diving deep\u0026#34; return { \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call[\u0026#34;id\u0026#34;], \u0026#34;content\u0026#34;: content, } while True: # ... unchanged ai_message_obj = call_llm(messages) # A: 判断 AI 是否想调用工具 if \u0026#34;tool_calls\u0026#34; in ai_message_obj and ai_message_obj[\u0026#34;tool_calls\u0026#34;]: # B: 添加带有工具调用的 AI 信息 messages.append(ai_message_obj) # C: 执行每个工具, 并获取结果 for tool_call in ai_message_obj[\u0026#34;tool_callls\u0026#34;]: tool_result = handle_tool(tool_call) messages.append(tool_result) # D: 获取 AI 的响应 final_response = call_llm(responses) print(f\u0026#34;AI: {final_response[\u0026#34;content\u0026#34;]}\u0026#34;) messages.append(final_response) else: # 默认流程 print(f\u0026#34;AI: {ai_message_obj[\u0026#34;content\u0026#34;]}\u0026#34;) messages.append(ai_message_obj) Click to expand and view more 下面是工具函数, 以及执行工具的函数\nPLAINTEXT Collapse Copy # step4_1.py def read_file(path): \u0026#34;\u0026#34;\u0026#34;读取 path 路径文件内容\u0026#34;\u0026#34;\u0026#34; try: with open(path, \u0026#34;r\u0026#34;) as f: content = f.read() except Exception as e: return f\u0026#34;Error reading file: {str(e)}\u0026#34; def handle_tool(tool_call): \u0026#34;\u0026#34;\u0026#34;执行一个 tool call 并返回值\u0026#34;\u0026#34;\u0026#34; tool_name = tool_call[\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;] tool_args = json.loads(tool_call[\u0026#34;function\u0026#34;][\u0026#34;arguments\u0026#34;]) print(f\u0026#34;[Exexuting {tool_name}...]\u0026#34;) if tool_name == \u0026#34;read_file\u0026#34;: result = read_file(**tool_args) else: result = f\u0026#34;Unknown tool: {tool_name}\u0026#34; return { \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call[\u0026#34;id\u0026#34;], \u0026#34;content\u0026#34;: result, } Click to expand and view more 恭喜! 现在所有步骤都已经完成了, 聊天循环, LLM 调用, 工具传递给 LLM 调用 并 调用工具.\n现在已经完成了让 AI 读取文件的功能, 然后就可以让 AI 查看我们的代码, 并给出建议.\n完整代码实现 (仅依赖 python 标准库运行)\nPLAINTEXT Collapse Copy import requests import os import json TOOL_SPECS = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;read_file\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Read the content of a file.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;:{ \u0026#34;path\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The file path to read\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;path\u0026#34;] } } } ] def read_file(path): \u0026#34;\u0026#34;\u0026#34;Read the content of a file\u0026#34;\u0026#34;\u0026#34; try: with open(path, \u0026#34;r\u0026#34;) as f: content = f.read() return content except Exception as e: return f\u0026#34;Error reading file: {str(e)}\u0026#34; def handle_tool(tool_call): \u0026#34;\u0026#34;\u0026#34;Execute a single tool call and return the result\u0026#34;\u0026#34;\u0026#34; tool_name = tool_call[\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;] tool_args = json.loads(tool_call[\u0026#34;function\u0026#34;][\u0026#34;arguments\u0026#34;]) print(f\u0026#34;[Executing {tool_name}...]\u0026#34;) if tool_name == \u0026#34;read_file\u0026#34;: result = read_file(**tool_args) else: result = f\u0026#34;Unknow tool: {tool_name}\u0026#34; return { \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call[\u0026#34;id\u0026#34;], \u0026#34;content\u0026#34;: result, } def call_llm(messages): api_key = \u0026#34;sk-...\u0026#34; headers = { \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {api_key}\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, } data = { \u0026#34;model\u0026#34;: \u0026#34;deepseek-v3\u0026#34;, \u0026#34;messages\u0026#34;: messages, \u0026#34;tools\u0026#34;: TOOL_SPECS, \u0026#34;tool_choice\u0026#34;: \u0026#34;auto\u0026#34;, } url = \u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\u0026#34; try: response = requests.post(url, json=data, headers=headers) message = response.json()[\u0026#34;choices\u0026#34;][0][\u0026#34;message\u0026#34;] return message except: print(\u0026#34;error\u0026#34;) raise Exception(\u0026#34;bad\u0026#34;) def fake_ai(messages): latest_user_message = messages[-1][\u0026#34;content\u0026#34;] return f\u0026#34;AI: You said {latest_user_message}... so insightful \u0026#34; print(\u0026#34;Press q to quit\u0026#34;) messages = [] while True: user_message = input(\u0026#34;You: \u0026#34;) if user_message == \u0026#34;q\u0026#34;: break messages.append({ \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_message, }) ai_message_obj = call_llm(messages) # Check if AI wants to use tools if \u0026#34;tool_calls\u0026#34; in ai_message_obj and ai_message_obj[\u0026#34;tool_calls\u0026#34;]: messages.append(ai_message_obj) for tool_call in ai_message_obj[\u0026#34;tool_calls\u0026#34;]: tool_result = handle_tool(tool_call) messages.append(tool_result) final_response = call_llm(messages) print(f\u0026#34;AI: {final_response[\u0026#34;content\u0026#34;]}\u0026#34;) messages.append(final_response) else: print(f\u0026#34;AI: {ai_message_obj[\u0026#34;content\u0026#34;]}\u0026#34;) messages.append(ai_message_obj) Click to expand and view more 运行示例:\nPLAINTEXT Collapse Copy % uv run minimal-aiagent.py Press q to quit You: 你好, 介绍一下你自己. AI: 你好！我是一个智能助手，可以帮助你回答各种问题、提供建议或执行一些任务。无论是学习、工作还是日常生活相关的问题，你都可以问我。我没有 实体，但可以通过文字与你交流。请问有什么可以帮你的吗？ You: 读取一下 code_example.cc 文件里面的代码, 解释一下这个文件里面的代码实现了什么? [Executing read_file...] AI: `code_example.cc` 文件实现了一个优化的 KMP（Knuth-Morris-Pratt）字符串匹配算法。以下是代码的主要功能和逻辑： ### 1. **算法实现** - **`getNextval` 函数**： 生成模式串 `P` 的 `nextval` 数组，用于优化 KMP 算法中的回溯过程。`nextval` 数组在匹配失败时，提供更高效的跳转位置。 - 通过比较模式串的前缀和后缀，动态更新 `nextval` 数组。 - 如果字符匹配，继续向后比较；否则，利用 `nextval` 数组跳转。 - **`KMP_optimized` 函数**： 使用 `nextval` 数组在主串 `T` 中查找模式串 `P` 的首次出现位置。 - 如果匹配成功，返回模式串在主串中的起始位置；否则返回 `-1`。 ### 2. **示例运行** - **`main` 函数**： 提供了一个示例： - 主串（`text`）：`\u0026#34;ABABABABCABABABABD\u0026#34;` - 模式串（`pattern`）：`\u0026#34;ABABABD\u0026#34;` - 调用 `KMP_optimized` 进行匹配，并输出结果。 ### 3. **优化点** - 使用 `nextval` 数组进一步减少不必要的比较，相比普通 KMP 算法更高效。 ### 4. **输出结果** 运行后会输出匹配结果，例如： 主串: ABABABABCABABABABD 模式串: ABABABD 使用 nextval 数组，匹配成功，起始位置: 9 总结：该文件实现了一个优化的 KMP 字符串搜索算法，适用于高效查找子串位置。 You: q Click to expand and view more A Step Further 下面让我们更进一步:\n使用 agent 为 write_file 函数提出修改建议 允许 agent 写入名为 README.md 的文件 允许 agent 写入文件以创建 list_file 列出文件的功能 这需要处理链式工具调用, 因为编辑文件是 read + write 的操作 对比三个文件需要 read + read + read 的操作 编辑一个不熟悉格式的文件可能需要 read + web_reasearch + list + read + write 操作 Let AI suggest the \u0026ldquo;write file\u0026rdquo; function 我们可以使用刚刚编写的 agent 来完成写入文件函数的功能:\n复制一份代码到 step4_2.py 运行 minimal-aiagent.py 提示词: 你是一名资深工程师. 请查看 step4_2.py 文件, 如何添加一个 write_file 工具让 agent 修改文件? 要确保编写的工具与文件中的代码类型匹配, 最后展示代码更改. 示例:\nPLAINTEXT Collapse Copy % uv run minimal-aiagent.py Press q to quit You: 你是一名资深工程师. 请查看 step4_2.py 文件, 如何添加一个 write_file 工具让 agent 修改文件? 要确保编写的工具与文件中的代码类型匹配, 最后展示代码更改. [Executing read_file...] AI: 为了添加 `write_file` 工具，我们需要在 `TOOL_SPECS` 中添加一个新的工具定义，并实现 `write_file` 函数。以下是修改后的代码： import requests import os import json TOOL_SPECS = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;read_file\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Read the content of a file.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;path\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The file path to read\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;path\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;write_file\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Write content to a file.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;path\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The file path to write\u0026#34; }, \u0026#34;content\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The content to write\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;path\u0026#34;, \u0026#34;content\u0026#34;] } } } ] def read_file(path): \u0026#34;\u0026#34;\u0026#34;Read the content of a file\u0026#34;\u0026#34;\u0026#34; try: with open(path, \u0026#34;r\u0026#34;) as f: content = f.read() return content except Exception as e: return f\u0026#34;Error reading file: {str(e)}\u0026#34; def write_file(path, content): \u0026#34;\u0026#34;\u0026#34;Write content to a file\u0026#34;\u0026#34;\u0026#34; try: with open(path, \u0026#34;w\u0026#34;) as f: f.write(content) return \u0026#34;File written successfully.\u0026#34; except Exception as e: return f\u0026#34;Error writing file: {str(e)}\u0026#34; def handle_tool(tool_call): \u0026#34;\u0026#34;\u0026#34;Execute a single tool call and return the result\u0026#34;\u0026#34;\u0026#34; tool_name = tool_call[\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;] tool_args = json.loads(tool_call[\u0026#34;function\u0026#34;][\u0026#34;arguments\u0026#34;]) print(f\u0026#34;[Executing {tool_name}...]\u0026#34;) if tool_name == \u0026#34;read_file\u0026#34;: result = read_file(**tool_args) elif tool_name == \u0026#34;write_file\u0026#34;: result = write_file(**tool_args) else: result = f\u0026#34;Unknown tool: {tool_name}\u0026#34; return { \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call[\u0026#34;id\u0026#34;], \u0026#34;content\u0026#34;: result, } def call_llm(messages): api_key = \u0026#34;sk-...\u0026#34; headers = { \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {api_key}\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, } data = { \u0026#34;model\u0026#34;: \u0026#34;deepseek-v3\u0026#34;, \u0026#34;messages\u0026#34;: messages, \u0026#34;tools\u0026#34;: TOOL_SPECS, \u0026#34;tool_choice\u0026#34;: \u0026#34;auto\u0026#34;, } url = \u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\u0026#34; try: response = requests.post(url, json=data, headers=headers) message = response.json()[\u0026#34;choices\u0026#34;][0][\u0026#34;message\u0026#34;] return message except: print(\u0026#34;error\u0026#34;) raise Exception(\u0026#34;bad\u0026#34;) def fake_ai(messages): latest_user_message = messages[-1][\u0026#34;content\u0026#34;] return f\u0026#34;AI: You said {latest_user_message}... so insightful \u0026#34; print(\u0026#34;Press q to quit\u0026#34;) messages = [] while True: user_message = input(\u0026#34;You: \u0026#34;) if user_message == \u0026#34;q\u0026#34;: break messages.append({ \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_message, }) ai_message_obj = call_llm(messages) # Check if AI wants to use tools if \u0026#34;tool_calls\u0026#34; in ai_message_obj and ai_message_obj[\u0026#34;tool_calls\u0026#34;]: messages.append(ai_message_obj) for tool_call in ai_message_obj[\u0026#34;tool_calls\u0026#34;]: tool_result = handle_tool(tool_call) messages.append(tool_result) final_response = call_llm(messages) print(f\u0026#34;AI: {final_response[\u0026#39;content\u0026#39;]}\u0026#34;) messages.append(final_response) else: print(f\u0026#34;AI: {ai_message_obj[\u0026#39;content\u0026#39;]}\u0026#34;) messages.append(ai_message_obj) ### 主要变更： 1. **添加 `write_file` 工具定义**： - 在 `TOOL_SPECS` 列表中添加了一个新的工具定义，支持 `path` 和 `content` 参数。 2. **实现 `write_file` 函数**： - 新增 `write_file` 函数，用于将内容写入文件。 3. **扩展 `handle_tool` 函数**： - 在 `handle_tool` 中添加了对 `write_file` 工具的支持。 现在，Agent 可以通过调用 `write_file` 工具修改文件内容。 You: q Click to expand and view more 太棒了! 现在这个 coding agent 已经在帮助我们编写代码和改进代理本身了.\n为了确保 agent 不会错误的修改其他地方的文件, 这里通过保证修改的文件在父目录下面来改进写入文件功能\nPYTHON Collapse Copy # Define safe directory (current directory only) SAFE_DIR = os.path.abspath(os.getcwd()) def is_safe_path(path): \u0026#34;\u0026#34;\u0026#34;Check if path is within the safe directory\u0026#34;\u0026#34;\u0026#34; # Resolve the absolute path abs_path = os.path.abspath(path) # Check if it\u0026#39;s within the safe directory return abs_path.startswith(SAFE_DIR) def write_file(path, content): \u0026#34;\u0026#34;\u0026#34;Write content to a file\u0026#34;\u0026#34;\u0026#34; if not is_safe_path(path): return f\u0026#34;Error: Access denied - path outside safe directory\u0026#34; try: with open(path, \u0026#34;w\u0026#34;) as f: f.write(content) return \u0026#34;File successfully written\u0026#34; except Exception as e: return f\u0026#34;Error writing file: {str(e)}\u0026#34; Click to expand and view more 请自行判断风险\n下面冒险运行最新的 step4_2.py 代码:\nPLAINTEXT Collapse Copy % uv run step4_2.py Press q to quit You: 向 README.md 文件中写入这段文本: \u0026#34;# AI Agent 编写的这段话\u0026#34; [Executing write_file...] AI: The text \u0026#34;# AI Age编写的这段话\u0026#34; has been successfully written to the README.md file. You: q % cat README.md ───────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── │ File: README.md ───────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── 1 │ # AI Age编写的这段话 ───────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Click to expand and view more Let AI write the \u0026ldquo;list files\u0026rdquo; with recursive tool calling 让 AI 编写 list_files 方法来递归调用工具\n现在这个 coding agent 能够修改文件了, 它可以为新的 list_files 函数提出代码更改建议，并将这些更改写入磁盘. 再次强调, 注意风险.\n然而, 修改一个文件需要两个链式工具调用: 1.read 2.write 比较三个文件则需要三个链式工具调用: 1.read 2.read 3.read 重构: 递归工具调用\nPYTHON Collapse Copy # step4_3.py def handle_message(messages, ai_message_obj): # Check if AI wants to use tools if \u0026#39;tool_calls\u0026#39; in ai_message_obj and ai_message_obj[\u0026#39;tool_calls\u0026#39;]: # Add AI message with tool calls messages.append(ai_message_obj) # Execute each tool and add results for tool_call in ai_message_obj[\u0026#39;tool_calls\u0026#39;]: tool_result = handle_tool(tool_call) messages.append(tool_result) # Get final response from AI final_response = call_llm(messages) print(f\u0026#34;maybe final response: {final_response[\u0026#39;content\u0026#39;]}\u0026#34;) if \u0026#39;tool_calls\u0026#39; in final_response and ai_message_obj[\u0026#39;tool_calls\u0026#39;]: handle_message(messages, final_response) else: print(f\u0026#34;AI: {ai_message_obj[\u0026#39;content\u0026#39;]}\u0026#34;) messages.append(ai_message_obj) return while True: # ... ai_message_obj = call_llm(messages) handle_message(messages, ai_message_obj) Click to expand and view more 运行示例:\nPLAINTEXT Collapse Copy % uv run step4_3.py Press q to quit You: step1.py 和 step2.py 这两个文件有什么区别? [Executing read_file...] [Executing read_file...] maybe final response: `step1.py` 和 `step2.py` 的主要区别如下： 1. **工具支持**: - `step1.py` 只支持 `read_file` 一个工具。 - `step2.py` 新增了 `write_file` 工具，支持文件的读取和写入。 2. **函数实现**: - `step2.py` 中新增了 `write_file` 函数的实现，用于写入文件内容。 3. **消息处理逻辑**: - `step1.py` 在处理工具调用时直接返回最终响应。 - `step2.py` 引入了 `handle_message` 函数，支持递归处理多轮工具调用，确保所有工具调用完成后才返回最终响应。 4. **代码结构**: - `step2.py` 的代码结构更加模块化，将消息处理逻辑封装到了 `handle_message` 函数中，提升了可读性和复用性。 总结：`step2.py` 是 `step1.py` 的扩展版本，增加了文件写入功能，并优化了工具调用的处理逻辑。 Click to expand and view more 现在再来编写 list_files\nPLAINTEXT Collapse Copy % uv run step4_3.py Press q to quit You: 阅读 step4_4.py，在 TOOL_SPEC 中为 list_files 添加相应功能，并创建执行该操作的函数。不要删除任何现有功能（例如 read file 和 write file）。你是一名资深工程师，请进行深入思考（ultrathink）。完成后，再次读取该文件以确认所有功能仍然存在：聊天循环、调用 LLM、处理工具调用， 以及所有工具（read file、write file 和新增的 list file）。 [Executing read_file...] ... [Executing write_file...] maybe final response: 现在，我将重新读取 `step4_4.py` 文件，以验证所有功能是否完整： [Executing read_file...] maybe final response: ### 验证结果： 1. **功能完整性**： - 保留了原有的 `read_file` 和 `write_file` 功能。 - 新增了 `list_files` 功能，其工具规范已添加到 `TOOL_SPECS` 中。 - 更新了 `handle_tool` 函数以支持 `list_files` 调用。 2. **代码逻辑**： - 聊天循环、LLM 调用、工具调用处理均未受影响。 - 新增的 `list_files` 函数逻辑清晰，能够正确列出目录中的文件。 3. **测试验证**： - 可以通过实际调用 `list_files` 工具验证其功能。 - 现有工具（如 `read_file` 和 `write_file`）仍可正常使用。 ### 下一步： 如果需要进一步测试或扩展功能，请随时告知！ You: q Click to expand and view more 上面可以看到, 链式调用工作了! agent 修改后对比代码的变化:\nPLAINTEXT Collapse Copy % diff --color step4_3.py step4_4.py 42a43,59 \u0026gt; }, \u0026gt; { \u0026gt; \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026gt; \u0026#34;function\u0026#34;: { \u0026gt; \u0026#34;name\u0026#34;: \u0026#34;list_files\u0026#34;, \u0026gt; \u0026#34;description\u0026#34;: \u0026#34;List files in a directory.\u0026#34;, \u0026gt; \u0026#34;parameters\u0026#34;: { \u0026gt; \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026gt; \u0026#34;properties\u0026#34;: { \u0026gt; \u0026#34;directory\u0026#34;: { \u0026gt; \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026gt; \u0026#34;description\u0026#34;: \u0026#34;The directory path to list files from\u0026#34; \u0026gt; } \u0026gt; }, \u0026gt; \u0026#34;required\u0026#34;: [\u0026#34;directory\u0026#34;] \u0026gt; } \u0026gt; } 63a81,88 \u0026gt; def list_files(directory): \u0026gt; \u0026#34;\u0026#34;\u0026#34;List files in a directory\u0026#34;\u0026#34;\u0026#34; \u0026gt; try: \u0026gt; files = os.listdir(directory) \u0026gt; return {\u0026#34;files\u0026#34;: files} \u0026gt; except Exception as e: \u0026gt; return f\u0026#34;Error listing files: {str(e)}\u0026#34; \u0026gt; 74a100,101 \u0026gt; elif tool_name == \u0026#34;list_files\u0026#34;: \u0026gt; result = list_files(**tool_args) 81c108 \u0026lt; \u0026#34;content\u0026#34;: result, --- \u0026gt; \u0026#34;content\u0026#34;: json.dumps(result), 148c175 \u0026lt; handle_message(messages, ai_message_obj) --- \u0026gt; handle_message(messages, ai_message_obj) \\ No newline at end of file Click to expand and view more 然后测试新的代码\nPLAINTEXT Collapse Copy % uv run step4_4.py Press q to quit You: 列出所有文件 [Executing list_files...] maybe final response: 当前目录下的文件有： - `code_example.cc` - `step4_4.py` - `step2.py` - `README.md` - `step4_3.py` - `step1.py` You: q Click to expand and view more 最后给出完整实现\nPLAINTEXT Collapse Copy # step4_4.py import requests import os import json TOOL_SPECS = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;read_file\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Read the content of a file.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;path\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The file path to read\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;path\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;write_file\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Write content to a file.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;path\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The file path to write\u0026#34; }, \u0026#34;content\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The content to write\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;path\u0026#34;, \u0026#34;content\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;list_files\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;List files in a directory.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;directory\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The directory path to list files from\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;directory\u0026#34;] } } } ] def read_file(path): \u0026#34;\u0026#34;\u0026#34;Read the content of a file\u0026#34;\u0026#34;\u0026#34; try: with open(path, \u0026#34;r\u0026#34;) as f: content = f.read() return content except Exception as e: return f\u0026#34;Error reading file: {str(e)}\u0026#34; def write_file(path, content): \u0026#34;\u0026#34;\u0026#34;Write content to a file\u0026#34;\u0026#34;\u0026#34; try: with open(path, \u0026#34;w\u0026#34;) as f: f.write(content) return \u0026#34;File written successfully.\u0026#34; except Exception as e: return f\u0026#34;Error writing file: {str(e)}\u0026#34; def list_files(directory): \u0026#34;\u0026#34;\u0026#34;List files in a directory\u0026#34;\u0026#34;\u0026#34; try: files = os.listdir(directory) return {\u0026#34;files\u0026#34;: files} except Exception as e: return f\u0026#34;Error listing files: {str(e)}\u0026#34; def handle_tool(tool_call): \u0026#34;\u0026#34;\u0026#34;Execute a single tool call and return the result\u0026#34;\u0026#34;\u0026#34; tool_name = tool_call[\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;] tool_args = json.loads(tool_call[\u0026#34;function\u0026#34;][\u0026#34;arguments\u0026#34;]) print(f\u0026#34;[Executing {tool_name}...]\u0026#34;) if tool_name == \u0026#34;read_file\u0026#34;: result = read_file(**tool_args) elif tool_name == \u0026#34;write_file\u0026#34;: result = write_file(**tool_args) elif tool_name == \u0026#34;list_files\u0026#34;: result = list_files(**tool_args) else: result = f\u0026#34;Unknown tool: {tool_name}\u0026#34; return { \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call[\u0026#34;id\u0026#34;], \u0026#34;content\u0026#34;: json.dumps(result), } def call_llm(messages): api_key = \u0026#34;sk-...\u0026#34; headers = { \u0026#34;Authorization\u0026#34;: f\u0026#34;Bearer {api_key}\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, } data = { \u0026#34;model\u0026#34;: \u0026#34;deepseek-v3\u0026#34;, \u0026#34;messages\u0026#34;: messages, \u0026#34;tools\u0026#34;: TOOL_SPECS, \u0026#34;tool_choice\u0026#34;: \u0026#34;auto\u0026#34;, } url = \u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\u0026#34; try: response = requests.post(url, json=data, headers=headers) message = response.json()[\u0026#34;choices\u0026#34;][0][\u0026#34;message\u0026#34;] return message except: print(\u0026#34;error\u0026#34;) raise Exception(\u0026#34;bad\u0026#34;) def fake_ai(messages): latest_user_message = messages[-1][\u0026#34;content\u0026#34;] return f\u0026#34;AI: You said {latest_user_message}... so insightful \u0026#34; print(\u0026#34;Press q to quit\u0026#34;) messages = [] def handle_message(messages, ai_message_obj): \u0026#34;\u0026#34;\u0026#34;注意: messages 会被修改\u0026#34;\u0026#34;\u0026#34; if \u0026#34;tool_calls\u0026#34; in ai_message_obj and ai_message_obj[\u0026#34;tool_calls\u0026#34;]: # Add AI message with tool calls messages.append(ai_message_obj) # Execute each tool and add results for tool_call in ai_message_obj[\u0026#34;tool_calls\u0026#34;]: tool_result = handle_tool(tool_call) messages.append(tool_result) # Get final response from AI final_response = call_llm(messages) print(f\u0026#34;maybe final response: {final_response[\u0026#39;content\u0026#39;]}\u0026#34;) if \u0026#34;tool_calls\u0026#34; in final_response and ai_message_obj[\u0026#34;tool_calls\u0026#34;]: handle_message(messages, final_response) else: print(f\u0026#34;AI: {ai_message_obj[\u0026#39;content\u0026#39;]}\u0026#34;) messages.append(ai_message_obj) return while True: user_message = input(\u0026#34;You: \u0026#34;) if user_message == \u0026#34;q\u0026#34;: break messages.append({ \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_message, }) ai_message_obj = call_llm(messages) handle_message(messages, ai_message_obj) Click to expand and view more Summary 基础部分已经完成, 可以看到这个 coding agent 已经可以读取文件 + 修改文件 + 列出目录下所有文件, 但仍有大量的改进空间:\nagent 没有进行多步工具调用和消息循环, 如果要对比5个文件, 可能只调用两个就结束了 agent 没有规划能力, 这一般是 AI 编程助手的默认能力 没有网络搜索能力 使用 Rust 重写 ","title":"Make an AI Coding Agent in python"},{"link":"/posts/kmp-algorithm/","text":"KMP 算法 思想 KMP 算法, 全程 Knuth-Morris-Pratt 算法, 是一种高效的字符串匹配算法. 它的核心思想是:\n在匹配过程中, 当发生文本串(text)与模式串(pattern)不匹配时, 能够利用已匹配过的部分信息, 智能地移动模式串, 从而避免从头开始匹配, 达到提高匹配效率的目的.\nKMP算法的巧妙之处在于:\n它认为, 当发生不匹配时, 将模式串仅仅右移一位是\u0026quot;愚蠢\u0026quot;的. 当某个地方不匹配时, 表明前面实际上有部分内容已经匹配了. 如果直接从头开始匹配, 就浪费了这些信息. 有时前面已经匹配部分会有\u0026quot;重复\u0026quot;的性质, 可以利用这种性质, 让子串一次多移动几步, 从而加速匹配速度.\n举例 主串S和模式串P\nPLAINTEXT Collapse Copy S = BBC ABCDAB ABCDABCDABDE P = ABCDABD Click to expand and view more 当匹配到下面这种情况时:\nPLAINTEXT Collapse Copy S = BBC ABCDAB ABCDABCDABDE P = ABCDABD Click to expand and view more 这里的 D 和上面空格不匹配, 此时保理匹配就直接向右移动一位, 但是通过观察已经匹配的部分 \u0026ldquo;ABCDAB\u0026rdquo; 可以发现, 该部分有相同的前后缀 \u0026ldquo;AB\u0026rdquo;, 因此可以直接将子串的 \u0026ldquo;A\u0026rdquo; 对准主串中后缀 \u0026ldquo;AB\u0026rdquo; 里面的 \u0026ldquo;A\u0026rdquo;:\nPLAINTEXT Collapse Copy S = BBC ABCDAB ABCDABCDABDE P = ABCDABD Click to expand and view more 此时, S 的指针不用改变, 将 P 的指针回到 \u0026ldquo;C\u0026rdquo; 的位置就行了. 通过这种方法, 大大提升了效率.\n这里的思想就是: 如果已匹配部分有相同的最大前后缀, 那么当发生不匹配时, 可以直接将已匹配部分的, 模式串的前缀对准主串的后缀, 对应 j = next[j](或者有的地方是 j = next[j - 1]), 就可以一次多移动几步, 而不是朴素算法的一步.\n此外, KMP 不仅是利用了 \u0026ldquo;最大相同前后缀\u0026rdquo; 来移动多步模式串的思想, 即使在模式串没有任何 \u0026ldquo;最大相同前后缀\u0026rdquo; 的时候, 其时间复杂度仍然为 O(m + n)\n看下面这个例子:\nPLAINTEXT Collapse Copy 文本: X Y C D E F G 模式: X Y Z Click to expand and view more 这里 Z 和 C 不匹配, 朴素算法会将 i 回溯到 Y, j 回溯到 X:\nPLAINTEXT Collapse Copy 文本: X Y C D E F G 模式: X Y Z Click to expand and view more 而 KMP 算法此时的 next = [0, 0, 0], 因此将 j 回溯到 X (j=0), 而 i 不变, 因为它知道前面已匹配的部分中, 没有任何可以利用的前后缀信息, 因此可以一次移动很多步\nPLAINTEXT Collapse Copy 文本: X Y C D E F G 模式: X Y Z Click to expand and view more 再来看一个已匹配部分的前缀有公共前后缀的例子:\nPLAINTEXT Collapse Copy 文本: A B A C B ... 模式: A B A C D Click to expand and view more 这里发现 D 不匹配, 已匹配部分为 \u0026ldquo;ABAC\u0026rdquo;, 其没有任何公共前后缀, 虽然 \u0026ldquo;ABA\u0026rdquo; 有公共前后缀 \u0026ldquo;A\u0026rdquo;, 但是这个信息在这里并没有用, 因为我们知道\u0026quot;AB\u0026quot; 和 \u0026ldquo;AC\u0026rdquo; 是不匹配的, 因此不用移动成这样:\nPLAINTEXT Collapse Copy 文本: A B A C B ... 模式: A B A C D Click to expand and view more 而是直接移动成这样\nPLAINTEXT Collapse Copy 文本: A B A C B ... 模式: A B A C D Click to expand and view more 所以, KMP 的思想不仅仅是利用了 \u0026ldquo;最大公共前后缀\u0026rdquo; 来加速匹配速度, 同时也利用了, 当没有 \u0026ldquo;公共前后缀\u0026rdquo; 的情况加速匹配速度的思想. 在 KMP 中, 主串的指针 i 是永不回溯的, 要回溯的只有模式串的指针 j.\n实现 PM (Partial Match) 表\nPM 表是\u0026quot;部分匹配表\u0026quot;, 用于构造 next 数组, 对于子串 P = \u0026quot;ABCDABD\u0026quot; 为例, 计算其 PM 表:\n\u0026ldquo;A\u0026rdquo;: 前后缀集和都为空, 最大前后缀长度为 0. \u0026ldquo;AB\u0026rdquo;: 前缀为{\u0026ldquo;A\u0026rdquo;}, 后缀为{\u0026ldquo;B\u0026rdquo;}, 无相等的, 也为 0. \u0026ldquo;ABC\u0026rdquo;: 前缀为{\u0026ldquo;A\u0026rdquo;, \u0026ldquo;AB\u0026rdquo;}, 后缀为{\u0026ldquo;C\u0026rdquo;, \u0026ldquo;BC\u0026rdquo;}, 也没有相等的, 长度为 0. \u0026ldquo;ABCD\u0026rdquo;: 前缀为{\u0026ldquo;A\u0026rdquo;, \u0026ldquo;AB\u0026rdquo;, \u0026ldquo;ABC\u0026rdquo;}, 后缀为{\u0026ldquo;D\u0026rdquo;, \u0026ldquo;CD\u0026rdquo;, \u0026ldquo;BCD\u0026rdquo;}. 没有相等的, 长度为 0. \u0026ldquo;ABCDA\u0026rdquo;: 前缀为{\u0026ldquo;A\u0026rdquo;, \u0026ldquo;AB\u0026rdquo;, \u0026ldquo;ABC\u0026rdquo;, \u0026ldquo;ABCD\u0026rdquo;}, 后缀为{\u0026ldquo;A\u0026rdquo;, \u0026ldquo;DA\u0026rdquo;, \u0026ldquo;CDA\u0026rdquo;, \u0026ldquo;BCDA\u0026rdquo;}, 最长前后缀为 \u0026ldquo;A\u0026rdquo;, 长度为 1. \u0026ldquo;ABCDAB\u0026rdquo;: 前缀为{\u0026ldquo;A\u0026rdquo;, \u0026ldquo;AB\u0026rdquo;, \u0026hellip;}, 后缀为{\u0026ldquo;B\u0026rdquo;, \u0026ldquo;AB\u0026rdquo;, \u0026hellip;}, 最长相等的是 \u0026ldquo;AB\u0026rdquo;, 长度为 2. \u0026ldquo;ABCDABD\u0026rdquo;: 前缀为{\u0026ldquo;A\u0026rdquo;, \u0026hellip;}, 后缀为{\u0026ldquo;D\u0026rdquo;, \u0026hellip;}, 没有相等的, 长度为 0. 故得到模式串 P = \u0026quot;ABCDABD\u0026quot; 的 PM 表为 [0, 0, 0, 0, 1, 2, 0]\nnext 数组\nnext 数组就是在代码中实际使用的数组, 一般有两种方法, 当 P[j] 匹配失败的时候, 会使用 j = next[j] 或者 j = next[j - 1] 的方法来进行回溯, 下面介绍第一种:\n0. PM 表为 [0, 0, 0, 0, 1, 2, 0]\n将 PM 表向右移动一位: [_, 0, 0, 0, 0, 1, 2] 在开头补上 -1: [-1, 0, 0, 0, 0, 1, 2] next[0] = 0 LPS 数组法: KMP 匹配失败时 j = next[j - 1] CPP Collapse Copy void getNext_standard(string\u0026amp; P, vector\u0026lt;int\u0026gt;\u0026amp; next) { int m = P.length(); next.resize(m); next[0] = 0; // 单个字符没有前后缀 int j = 0; // j 记录最长前后缀的长度 // i 从 1 开始遍历模式串 for (int i = 1; i \u0026lt; m; ++i) { // 如果当前字符不匹配, j 回溯 // j \u0026gt; 0 防止越界 while (j \u0026gt; 0 \u0026amp;\u0026amp; P[i] != P[j]) { // j 回溯到上一个子串最长相同前后缀的长度 j = next[j - 1]; } // 如果匹配, j + 1 if (P[i] == P[j]) { ++j; } } } Click to expand and view more next[0] = -1 哨兵法: KMP 匹配失败时 j = next[j] CPP Collapse Copy void getNext_sentinel(const std::string\u0026amp; P, std::vector\u0026lt;int\u0026gt;\u0026amp; next) { int m = P.length(); next.resize(m); // next[0] 设置为 -1 作为哨兵 next[0] = -1; // i 遍历模式串，j 记录最长相等前后缀长度 // 注意这里 j 的初始值是 -1，与 next[0] 对应 int i = 0, j = -1; // 循环直到遍历完模式串 while (i \u0026lt; m - 1) { // 当 j 为 -1 或当前字符匹配时，i 和 j 同时向后移动 if (j == -1 || P[i] == P[j]) { i++; j++; // 更新 next[i] next[i] = j; } else { // 当字符不匹配时，j 回溯到 next[j] j = next[j]; } } } Click to expand and view more nextval 数组\nnext 数组已经很高效了, 但还可以进一步优化为 nextval 数组, 考虑一下情况:\nPLAINTEXT Collapse Copy S: A A A B \u0026lt;- i P: A A A A \u0026lt;- j Click to expand and view more 这时 P[3] 和 S[3] 不匹配, 根据 P 的 next 数组 [-1, 0, 1, 2, 3] 可知下一次匹配应该是这样:\nPLAINTEXT Collapse Copy S: A A A B P: A A A A ^ j Click to expand and view more 这时候发现, 之前的 P[3] 和现在 j 回退后指向的 P[2] 都是 \u0026ldquo;A\u0026rdquo;, 因此肯定不匹配, 故应该继续回退.\n这里就是 nextval 数组的优化, 也是唯一和 next 数组不同的地方:\n当 P[j] == P[next[j]] 的时候, 这回退是没有意义的, 因此要继续回退, 直到 P[k] 和 P[j] 不同的位置 k\n在 next 数组基础上实现 PLAINTEXT Collapse Copy // 基于 next 数组计算 nextval 数组 void getNextval(const string\u0026amp; P, vector\u0026lt;int\u0026gt;\u0026amp; nextval) { int m = P.length(); vector\u0026lt;int\u0026gt; next(m); getNext(P, next); // 首先计算 next 数组 nextval.resize(m); nextval[0] = 0; // nextval[0] 同样为 0 for (int i = 1; i \u0026lt; m; ++i) { // 如果 P[i] 等于 P[next[i] - 1]，说明当前最长相等前后缀的下一个字符与当前字符相同 if (next[i] \u0026gt; 0 \u0026amp;\u0026amp; P[i] == P[next[i] - 1]) { // 回溯到 next[i] 的 nextval 值 nextval[i] = nextval[next[i] - 1]; } else { // 否则，nextval[i] 就等于 next[i] nextval[i] = next[i]; } } } Click to expand and view more 直接计算 nextval 数组 CPP Collapse Copy void getNextval(const string\u0026amp; P, vector\u0026lt;int\u0026gt;\u0026amp; nextval) { int m = P.length(); nextval.resize(m); // j 记录最长相等前后缀的长度 int j = 0; // nextval[0] 始终为 0 nextval[0] = 0; // i 从 1 开始遍历模式串 for (int i = 1; i \u0026lt; m; ++i) { // 如果当前字符不匹配，j 回溯 while (j \u0026gt; 0 \u0026amp;\u0026amp; P[i] != P[j]) { // 注意：这里利用 nextval 数组自身进行回溯 j = nextval[j - 1]; } // 如果字符匹配，j 增加 1 if (P[i] == P[j]) { j++; } // 更新 nextval[i] // 关键逻辑: 如果 P[i] 和 P[j] 相等，那么 nextval[i] 的值等于 nextval[j] // 否则, nextval[i] 等于 j if (j \u0026gt; 0 \u0026amp;\u0026amp; P[i] == P[j]) { // 与 next 区别点 nextval[i] = nextval[j]; } else { nextval[i] = j; } } } Click to expand and view more KMP In Action 下面使用 c++ 代码来完成 KMP 算法\nCPP Collapse Copy #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; // KMP 算法中的 next 数组计算 (常规版本) void getNext(const string\u0026amp; P, vector\u0026lt;int\u0026gt;\u0026amp; next) { int m = P.length(); next.resize(m); int j = 0; next[0] = 0; for (int i = 1; i \u0026lt; m; ++i) { while (j \u0026gt; 0 \u0026amp;\u0026amp; P[i] != P[j]) { j = next[j - 1]; } if (P[i] == P[j]) { j++; } next[i] = j; } } // 完整的 KMP 匹配算法 int KMP_standard(const string\u0026amp; T, const string\u0026amp; P) { int n = T.length(); int m = P.length(); if (m == 0) return 0; // 计算 next 数组 vector\u0026lt;int\u0026gt; next; getNext(P, next); int i = 0; // 主串指针 int j = 0; // 模式串指针 while (i \u0026lt; n) { // 如果字符匹配，两个指针同时后移 if (T[i] == P[j]) { i++; j++; } // 匹配成功，返回起始位置 if (j == m) { // j = next[j-1]; // 如果需要查找所有匹配，则继续 return i - j; } // 匹配失败 if (i \u0026lt; n \u0026amp;\u0026amp; T[i] != P[j]) { // 如果 j \u0026gt; 0, 说明模式串可以回溯 if (j \u0026gt; 0) { j = next[j - 1]; } else { // 如果 j 已经是 0, 说明无法回溯, 主串指针后移 i++; } } } return -1; // 匹配失败 } int main() { string text = \u0026#34;ABABABABCABABABABD\u0026#34;; string pattern = \u0026#34;ABABABD\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;主串: \u0026#34; \u0026lt;\u0026lt; text \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;模式串: \u0026#34; \u0026lt;\u0026lt; pattern \u0026lt;\u0026lt; endl; int pos = KMP_standard(text, pattern); if (pos != -1) { cout \u0026lt;\u0026lt; \u0026#34;使用标准 next 数组, 匹配成功, 起始位置: \u0026#34; \u0026lt;\u0026lt; pos \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;使用标准 next 数组, 匹配失败\u0026#34; \u0026lt;\u0026lt; endl; } return 0; } Click to expand and view more ","title":"KMP Algorithm"},{"link":"/posts/redis-ordered-set/","text":"Redis 的有序集和(ordered set)同时具有\u0026quot;有序\u0026quot;和\u0026quot;集和\u0026quot;两种性质, 这种结构中每个元素都由一个成员和一个与成员相关联的分值组成, 其中成员与字符串方式存储, 而分值以64位双精度浮点数格式存储.\n例如下面一个记录薪水的集和:\n成员 分值 \u0026ldquo;perter\u0026rdquo; 3500 \u0026ldquo;bob\u0026rdquo; 3800 \u0026ldquo;jack\u0026rdquo; 4500 \u0026ldquo;tom\u0026rdquo; 5000 \u0026ldquo;mary\u0026rdquo; 5500 与集和一样, 有序集和中的元素都是唯一的, 同时, 成员将按照分值大小进行排序.\n有序集和分值除了可以是数字外, 还可以是字符串 \u0026ldquo;+inf\u0026rdquo; 或者 \u0026ldquo;-inf\u0026rdquo;, 这两个特殊值分别表示无穷大和无穷小.\n虽然有序集和的成员不可相同, 但是分值可以是相同的, 当两个或多个成员拥有相同的分值时，Redis 将按照这些成员在字典序中的大小对其进行排列.\n有序集合是Redis提供的所有数据结构中最为灵活的一种, 它可以以多种不同的方式获取数据, 比如根据成员获取分值、根据分值获取成员、根据成员的排名获取成员、根据指定的分值范围获取多个成员等.\nZADD: 添加或更新成员\nPLAINTEXT Collapse Copy ZADD sorted_set socre number [score number ...] Click to expand and view more 默认情况下, ZADD 命令将返回成功添加的新成员数量作为返回值, 对于更新操作会返回0(未添加新成员).\n使用 XX | NX 选项来显示地指示命令 只更新 或 只添加操作\nPLAINTEXT Collapse Copy ZADD sorted [XX|NX] socre member [socre member ...] Click to expand and view more 若要返回所有被修改的成员数量(新添加 + 更新数量), 可使用 CH 选项\nPLAINTEXT Collapse Copy ZADD sorted_set [CH] socre number [score number ...] Click to expand and view more 复杂度: O(M * log(N)) 其中 M 为给定成员数量, N 为有序集和的成员数量\nZREM: 移除指定的成员\nPLAINTEXT Collapse Copy ZREM sorted_set member [member ...] Click to expand and view more ZREM 会返回被移除成员的数量作为返回值, 如果给定的某个成员不存在, 则会自动忽略该成员.\n复杂度: O(M * log(N)), 其中 M 为给定成员的数量, N 为有序集和中包含的成员数量.\nZSCORE: 获取成员的分值\nPLAINTEXT Collapse Copy ZSCORE sorted_set member Click to expand and view more 如果给定的 member 不存在, 将返回空值\n复杂度: O(1)\nZINCRBY: 对成员的分值进行自增或自减操作\nPLAINTEXT Collapse Copy ZINCRBY sorted_set increment member Click to expand and view more 该命令完成操作后, 将返回成员当前分值, increment 为正数时就是自增操作, 为负数时就是自减操作.\n如果命令给定的有序集和或者成员不存在, 则相当于 ZADD 命令, 会自动创建对应的值.\n复杂度: O(log(N))\nZCARD: 获取有序集和的大小\nPLAINTEXT Collapse Copy ZCARD sorted_set Click to expand and view more 返回集和中成员数量, 若不存在则返回0.\n复杂度: O(1)\nZRANK、ZREVRANK: 取得给定成员在有序集和中的排名\nPLAINTEXT Collapse Copy ZRANK sorted_set member # 升序 ZREVRANK sorted_set member # 降序 Click to expand and view more 若给定的集和或者成员不存在, 则返回空值.\n复杂度: O(log(N))\nZRANGE、ZREVRANGE: 获取索引范围内的成员\nPLAINTEXT Collapse Copy ZRANGE sorted_set start end # 升序 ZREVRANGE sorted_set start end # 降序 Click to expand and view more 索引范围为 [start, end], 即这两个索引上的成员也会包含在命令返回的结果当中, 索引从0开始. 此外, 还可以使用负数索引, 索引最后一个从 -1 开始.\n默认情况下, ZRANGE 和 ZREVRANGE 命令只会返回指定索引范围内的成员, 如果用户想要获取这些成员以及其分值, 可以使用 WITHSCORES 选项\nPLAINTEXT Collapse Copy ZRANGE sorted_set start end [WITHSCORES] ZREVRANGE sorted_set start end [WITHSCORES] Click to expand and view more 如果给定的有序集和不存在, 则会返回一个空列表.\n复杂度: O(M + log(N)), 其中 M 为命令返回成员数量, N 为有序集和成员数量.\n示例: 排行榜 在网站上经常会有各种各样的排行榜. 比如, 音乐网站上可能有试听排行榜, 下载排行榜等. 而视屏网站上可能看到观看排行榜, 收藏排行榜等. 甚至 GitHub 项目托管网站也有 star 排行榜.\n下面代码实现了一个排行榜程序:\n这个程序使用 ZADD 命令向排行榜中添加被排序的元素及分数, 并使用 ZREVRANK 命令获取元素在排行榜中的排名, 以及使用 ZSCORE 命令去获取元素的分数 当不再需要对某个元素进行排序的时候, 可以调用 ZREM 命令实现 remove() 方法, 从排行榜中移除该元素 如果用户想要修改某个被排序的元素的分数, 则调用 ZINCRBY 命令实现的 increase_score() 方法或者 decrease_score() 方法即可 当用户想要获取排行榜前N位的元素及其分数时, 只需要调用由 ZREVRANGE 命令实现的 top() 方法即可 PYTHON Collapse Copy class RankingList: def __init__(self, client, key): self.client = client self.key = key def set_score(self, item, score): \u0026#34;\u0026#34;\u0026#34;为排行榜中指定元素设置分数, 不存在的元素会被添加到排行榜中\u0026#34;\u0026#34;\u0026#34; self.client.zadd(self.key, {item: score}) def get_score(self, item): \u0026#34;\u0026#34;\u0026#34;获取排行榜中指定元素的分数\u0026#34;\u0026#34;\u0026#34; return self.client.zscore(self.key, item) def remove(self, item): \u0026#34;\u0026#34;\u0026#34;从排行榜中删除指定的元素\u0026#34;\u0026#34;\u0026#34; self.client.zrem(self.key, item) def increase_score(self, item, increment): \u0026#34;\u0026#34;\u0026#34;将给定的元素分数增加 increment 分\u0026#34;\u0026#34;\u0026#34; self.client.zincrby(self.key, increment, item) def decrease_score(self, item, decrement): \u0026#34;\u0026#34;\u0026#34;将给定的元素减少 increment 分\u0026#34;\u0026#34;\u0026#34; self.client.zincrby(self.key, 0-decrement, item) def get_rank(self, item): \u0026#34;\u0026#34;\u0026#34;获取给定元素排行榜中的排名\u0026#34;\u0026#34;\u0026#34; rank = self.client.zrevrank(self.key, item) if rank is not None: return rank + 1 # Redis 排名从0开始 def top(self, n, with_score=False): \u0026#34;\u0026#34;\u0026#34;获取排行榜中得分最高的元素\u0026#34;\u0026#34;\u0026#34; return self.client.zrevrange(self.key, 0, n-1, withsores=with_score) Click to expand and view more ZRANGEBYSCORE、ZREVRANGEBYSCORE: 获取分值范围内的成员\nPLAINTEXT Collapse Copy ZRANGEBYSCORE sorted_set min max ZREVRANGEBYSCORE sorted_set max min Click to expand and view more 命令的 min 参数和 max 参数分别用于指定用户想要获取的最小分值和最大分值, 要注意这两条命令接受最大最小值的顺序正好相反.\n该命令也可以使用 WITHSCORES 参数来同时获取成员及其分值 PLAINTEXT Collapse Copy ZRANGEBYSCORE sorted_set min max [WITHSCORES] ZREVRANGEBYSCORE sorted_set max min [WITHSCORES] Click to expand and view more 默认情况下, 该命令会返回范围内的所有成员, 有时成员数量很多, 就可以使用 LIMIT 选项来限制命令返回的成员数量. PLAINTEXT Collapse Copy ZRANGEBYSCORE sorted_set min max [LIMIT offset count] ZREVRANGEBYSCORE sorted_set min max [LIMIT offset count] Click to expand and view more 其中, offset 是指从满足 min 和 max 的元素中, 跳过前面的 offset 个元素, count 是从 offset 之后开始, 返回接下来的 count 个元素.\n如果要使用开区间而不是闭区间, 在分词的前面加上一个分括号 PLAINTEXT Collapse Copy ZRANGEBYSCORE salary (3500 (5000 WITHSCORES Click to expand and view more 这样会返回分值大于3500, 小于5000的成员.\n最后, 还可以使用无限值作为分值范围 PLAINTEXT Collapse Copy ZRANGEBYSCORE salary -inf (5000 WITHSCORES Click to expand and view more 复杂度: O(log(N) + M), N 为有序集和的成员数量, M 为命令返回的成员数量\nZCOUNT: 统计指定分词范围内的成员数量\nPLAINTEXT Collapse Copy ZCOUNT sorted_set min max Click to expand and view more 复杂度: O(N)\n示例: 时间线 在互联网上, 很多网站都会根据发布的内容来对时间进行排序:\n博客系统按照文章发布时间的先后, 将最近发布的文章放在前面 新闻网站会按照新闻的发布时间, 把最新的新闻放在网站前面 类似的情形还有很多, 通过对这类行为进行抽象, 写出下面的时间线程序:\n把被添加到时间线里的元素用作成员, 与元素相关的时间戳用作分值, 将元素和时间戳添加到集和中 将时间线中的元素按照时间戳的大小排序 通过对时间线中的元素执行 ZREVRANGE 或者 ZREVRANGEBYSCORE 命令, 用户可以通过分页的方式取出时间线中的元素, 或者从时间线中取出指定时间区间内的元素 PYTHON Collapse Copy class Timeline: def __init__(self, client, key): self.client = client self.key = key def add(self, item, time): \u0026#34;\u0026#34;\u0026#34;将元素添加到时间线中\u0026#34;\u0026#34;\u0026#34; self.client.zadd(self.key, {item: time}) def remove(self, item): \u0026#34;\u0026#34;\u0026#34;将元素从时间线中移除\u0026#34;\u0026#34;\u0026#34; self.client.zrem(self.key, item) def count(self): \u0026#34;\u0026#34;\u0026#34;返回时间线包含的元素数量\u0026#34;\u0026#34;\u0026#34; return self.client.zcard(self.key) def pagging(self, number, count, with_time=False): \u0026#34;\u0026#34;\u0026#34; 按照每页 count 个元素, 取出时间线第 number 页上的所有元素, 将元素按照时间戳逆序排序 with_time 表示是否返回时间信息 \u0026#34;\u0026#34;\u0026#34; start_index = (number - 1) * count end_index = number * count - 1 return self.client.zrevrange(self.key, start_index, end_index, with_time) def fetch_by_time_range(self, min_time, max_time, number, count, with_time=False): \u0026#34;\u0026#34;\u0026#34; 按照每页 count 个元素, 取出时间线第 number 页上的所有元素, 按照时间戳逆序排序 with_time 表示是否返回时间信息 \u0026#34;\u0026#34;\u0026#34; start_index = (number - 1) * count end_index = start_index + count - 1 return self.client.zrevrangebyscore(self.key, max_time, min_time, start_index, end_index, withscores=with_time) Click to expand and view more ZREMRANGEBYRANK: 移除指定排名范围内的成员\nPLAINTEXT Collapse Copy ZREMRANGEBYRANK sorted_set start end Click to expand and view more 该命令可以从升序排列的有序集和中移除位于指定排名范围内的成员, 然后返回被移除成员的数量\nstart-\u0026gt;end 可以是正数, 也可以使用负数 end-\u0026gt;start\nZUNIONSTORE、ZINTERSTORE: 有序集和的并集运算和交集运算\nPLAINTEXT Collapse Copy ZUNIONSTORE destination numbers sorted_set [sorted_set ...] ZINTERSOTRE destination numbers sorted_set [sorted_set ...] Click to expand and view more 其中, numbers 用于指定参与计算的有序集和数量, 计算结果会存储到 destination 参数指定的键中, 最后返回计算结果包含的成员数量作为返回值\n此外, 还可以决定使用什么方法来获得集和成员的分值: PLAINTEXT Collapse Copy ZUNIONSTORE destination numbers sorted_set [sorted_set ...] [AGGREGATE SUM|MIN|MAX] ZINTERSTORE destination numbers sorted_set [sorted_set ...] [AGGREGATE SUM|MIN|MAX] Click to expand and view more 如果上面的聚合函数不够用, 还可以为每个集和设置权重 PLAINTEXT Collapse Copy ZUNIONSTORE destination numbers sorted_set [sorted ...] [WEIGHTS weight [weight ...]] Click to expand and view more 复杂度: ZUNIONSTORE - O(N * log(N)), ZINTERSTORE - O(N * log(N) * M)\n还有很多其他关于有序集和的内容, 这里就不再讨论了.\n","title":"Redis Ordered Set"},{"link":"/posts/asyncio-vs-gevents-in-python/","text":"python 中 asyncio 和 gevent 是两种协程(在一个线程内实现并发)的实现, 这篇文章对比介绍这两者实现.\n下面先介绍一下基础概念:\nCoroutines 协程 在 Python 中, 协程是可以暂停和继续运行的函数, 使得其是否适合并发编程. 定义使用 async def 语法, 协程运行编写非阻塞的操作. 在协程内, await 关键字用于暂停执行, 直到给定的任务完成, 从而运行其他协程在此其间并发运行.\nEvent Loop 事件循环 事件循环是一种控制结构, 它不断地处理一系列事件, 处理任务并管理程序的执行流程. 等待事件发生, 处理后再等待下一个事件. 这种机制确保程序能够以高效有序的方式响应事件, 例如用户输入、计时器或者消息.\n下面是事件循环如何管理协程:\n任务提交: 当向事件循环提交一个协程时, 其被封装在一个 Task 对象中, 然后任务被安排在事件循环上运行.\n内部队列: 事件循环使用几个内部数据结构来管理和调度这些任务\n就绪队列 (Ready Queue): 包含可以立即运行的任务. I/O 选择器 (I/O Selector): 监控文件描述符, 并根据 I/O 准备情况调度任务 计划回调 (Scheduled Callbacks): 管理计划在一定延迟后运行的任务. 调度: 事件循环不断检查这些队列和数据结构, 以确定哪些任务已准备好执行. 然后它运行这些任务, 在遇到 await 语句时, 根据需要暂停和恢复它们.\n并发管理: 通过交错执行多个协程, 事件循环无需多个线程即可实现并发. 在任何时候, 只有一个任务会运行, 但如果一个任务是 I/O 密集型的, 它会切换到另一个任务, 给人一种并行的错觉.\nAsyncio In Action PYTHON Collapse Copy import asyncio import time async def task1(): print(\u0026#34;Task 1 started\u0026#34;) await asyncio.sleep(1) # 将控制权让给事件循环 print(\u0026#34;Task 1 resumed\u0026#34;) await asyncio.sleep(1) # 将控制权让给事件循环 async def task2(): print(\u0026#34;Task 2 started\u0026#34;) await asyncio.sleep(1) # 将控制权让给事件循环 print(\u0026#34;Task 2 resumed\u0026#34;) await asyncio.sleep(1) # 将控制权让给事件循环 async def main(): await asyncio.gather(task1(), task2()) start_time = time.time() asyncio.run(main()) end_time = time.time() print(f\u0026#34;Total time: {end_time - start_time:.2f} seconds\u0026#34;) \u0026#39;\u0026#39;\u0026#39; 任务 1 启动，并使用 await asyncio.sleep(1) 让出控制权。 任务 2 启动，并使用 await asyncio.sleep(1) 让出控制权。 1 秒后，两个任务都恢复。 任务 1 恢复，并使用 await asyncio.sleep(1) 让出控制权。 任务 2 恢复，并使用 await asyncio.sleep(1) 让出控制权。 又过了 1 秒，两个任务都完成。 总耗时为 2 秒。 \u0026#39;\u0026#39;\u0026#39; Click to expand and view more 通过上面的例子, 可以看到如何在进行 I/O 操作时通过切换任务来获得好处. 同样的逻辑如果按顺序执行需要 4 秒, 但使用 asyncio，可以将时间缩短一半. 在提供的代码中, 事件循环就像一个在单个线程上运行的管理器. 它跟踪 task1 和 task2 这样的任务, 确保它们轮流运行. CPU 逐一处理这些任务, 但当一个任务等待某事时(例如使用 await asyncio.sleep 暂停), 它会将控制权交给事件循环. 这使得事件循环可以切换到另一个准备好运行的任务. 这样, 即使所有事情都在一个线程中发生, 任务也能高效且并发地执行, 而无需等待彼此完全完成.\nAsyncio 术语\nasyncio.run(coro)\n运行主协程 coro 并管理事件循环, 创建一个新的事件循环, 运行协程直到完成, 然后关闭循环 被设计用于异步函数外部, 通常在程序的入口点调用 不能在已存在的事件循环内部运行 asyncio.create_task(coro)\n安排协程 core 并发运行, 并返回一个 Task 对象, 这个函数对启动多个协程非常有用 此命令需要一个已存在的事件循环才能执行 用于启动一个应该与其他任务并发运行的协程, 非常适合需要与其他异步操作并行运行的任务 asyncio.gather(*coros)\n并发运行多个协程并等待它们全部完成, 它将它们的结果收集到一个列表中 需要一个活动的事件循环来管理协程 event_loop.run_untill_complete(core)\n使用已存在的事件循环运行协程, 直到完成. 会阻塞直到协程完成并返回结果. 不应该在异步函数内部使用, 它旨在运行协程直到其完成, 应在异步函数外部使用, 通常在同步上下文中 Greenlets 和 Gevent Coroutines 协程 和 greenlets(green threds 绿色线程) 都是管理并发执行的方法, 但它们在实现、控制和使用场景方面有明显的区别.\nGreenlets 是由 Python 的 greenlet 库提供的低级、用户空间协程实现\nPYTHON Collapse Copy from greenlet import greenlet import time def task1(): start_time = time.time() print(\u0026#34;Task 1 started\u0026#34;) time.sleep(1) # 模拟工作 print(\u0026#34;Task 1 yielding\u0026#34;) gr2.switch() # 将控制权让给 task2 print(\u0026#34;Task 1 resumed\u0026#34;) time.sleep(1) # 模拟更多工作 end_time = time.time() print(f\u0026#34;Task 1 completed in {end_time - start_time:.2f} seconds\u0026#34;) def task2(): start_time = time.time() print(\u0026#34;Task 2 started\u0026#34;) time.sleep(1) # 模拟工作 print(\u0026#34;Task 2 yielding\u0026#34;) gr1.switch() # 将控制权让给 task1 print(\u0026#34;Task 2 resumed\u0026#34;) time.sleep(1) # 模拟更多工作 end_time = time.time() print(f\u0026#34;Task 2 completed in {end_time - start_time:.2f} seconds\u0026#34;) # 创建 greenlets gr1 = greenlet(task1) gr2 = greenlet(task2) # 启动 task1 并切换到 task2 start_time = time.time() gr1.switch() gr2.switch() end_time = time.time() print(f\u0026#34;Total execution time: {end_time - start_time:.2f} seconds\u0026#34;) \u0026#39;\u0026#39;\u0026#39; Task 1 started Task 1 yielding Task 2 started Task 2 yielding Task 1 resumed Task 1 completed in 3.01 seconds Task 2 resumed Task 2 completed in 3.01 seconds Total execution time: 4.02 seconds \u0026#39;\u0026#39;\u0026#39; Click to expand and view more Greenlet 在协作式多任务处理方式中为用户提供了完全的灵活性, 可以切换不同的执行上下文, 但它缺乏对异步 I/O 操作的内置支持.\nGevent 是一个构建在 Greenlet 之上的更高级的库, 提供对非阻塞 I/O 的内置支持和更高级的抽象, 适用于 I/O 密集型应用. Gevent 抽象了上下文切换的复杂性, 并提供了对非阻塞 I/O 操作的内置支持.\nPYTHON Collapse Copy import gevent import time def task1(): print(\u0026#34;Task 1 started\u0026#34;) gevent.sleep(1) print(\u0026#34;Task 1 resumed\u0026#34;) gevent.sleep(1) def task2(): print(\u0026#34;Task 2 started\u0026#34;) gevent.sleep(1) print(\u0026#34;Task 2 resumed\u0026#34;) gevent.sleep(1) start_time = time.time() # 创建 greenlets g1 = gevent.spawn(task1) g2 = gevent.spawn(task2) # 启动 greenlets 并等待它们完成 gevent.joinall([g1, g2]) end_time = time.time() print(f\u0026#34;Total time: {end_time - start_time:.2f} seconds\u0026#34;) \u0026#39;\u0026#39;\u0026#39; Task 1 started Task 2 started Task 1 resumed Task 2 resumed Total time: 2.03 seconds \u0026#39;\u0026#39;\u0026#39; Click to expand and view more 下面对比 gevent 和 asyncio :\n事件循环管理\nGevent: 管理自己的事件循环, 并依赖猴子补丁(monkey patching)使标准 I/O 操作变为异步. 这意味着它会修改标准库模块的行为以支持其并发模型 Asyncio: 包含一个内置事件循环, 它是 Python 标准库的一部分. 提供对管理异步操作的原生支持, 无需猴子补丁 猴子补丁\nGevent: 需要显式猴子补丁来将阻塞的 I/O 操作转换为非阻塞的. 这涉及修改标准库模块以与 gevent 的事件循环集成 Asyncio: 不需要猴子补丁, 它使用 Python 原生的 async/await 功能, 该功能与标准库的异步 I/O 操作无缝集成 性能\nGevent: 对于 I/O 密集型任务是高效的, 特别是在已经使用猴子补丁的系统中. 由于需要猴子补丁, 它可能会增加开销, 但在许多场景下仍然有效 Asyncio: 通常通过对异步编程的原生支持提供高性能. 它针对现代应用进行了优化, 并提供高效的 I/O 密集型任务处理, 没有猴子补丁的开销 错误处理\nGevent: 由于使用了猴子补丁的库, 可能需要仔细管理异常. 错误处理需要在 greenlets 内部进行管理 Asyncio: 在协程中利用标准的 Python 错误处理, 原生的语法使得在异步代码中处理异常更容易 使用场景\nGevent: 非常适合将异步行为集成到现有的同步代码库中, 或与兼容 greenlets 的库一起工作, 它适用于需要将现有 I/O 操作打补丁为异步的应用 Asyncio: 最适合采用现代异步编程实践的新应用或代码库, 它非常适合高性能网络应用和 I/O 密集型任务, 这些任务从原生异步支持中受益 Asyncio 通常是新应用的首选, 因为它倾向于现代异步编程实践, 它与 Python 的标准库无缝集成, 非常适合网络应用、实时通信和需要高并发的服务.\nGevent 通常是现有同步代码库的首选, 这些代码库需要进行改造以支持并发, 它能够对标准库模块进行猴子补丁, 使其非常适合需要将阻塞的 I/O 操作转换为非阻塞的应用, 例如在网络服务器、聊天应用和实时系统中.\nExamples 下面是一些使用 asyncio 和 gevent 的例子\nWeb Servers\nFastAPI: 虽然主要基于 Starlette 和 Pydantic 构建, 但 FastAPI 利用 asyncio 来处理异步请求, 使其成为一个用于构建 API 的高性能 Web 框架 Gunicorn with gevent workers: 一个流行的 Python 应用 WSGI HTTP 服务器, 可以使用 gevent workers 来高效地处理大量并发连接 Flask with gevent: 尽管 Flask 本身是同步的, 但将其与 gevent 结合可以并发处理多个请求, 使其适用于实时应用 实时通信\nDiscord.py: 一个 Discord 的 API 封装库, 它使用 asyncio 来高效地处理实时事件和交互 网络工具\nAsyncSSH: 一个用于 SSHv2 协议实现的库, 在 asyncio 之上构建, 为使用 SSH、SFTP 和 SCP 提供了异步 API ZeroMQ with gevent: 对于需要高性能消息传递的应用, gevent 经常与 ZeroMQ 一起使用, 以有效地处理异步通信模式 数据库访问\nGevent with SQLAlchemy: 对于需要异步数据库访问的应用, 将 gevent 与 SQLAlchemy 结合可以处理数据库查询而不会阻塞主线程 Wrapping Up 总而言之, asyncio 和 gevent 都提供了在 Python 中实现并发的强大工具, 但它们满足不同的需求和使用场景. Asyncio 是新应用的绝佳选择, 它利用了 Python 的原生异步能力, 而 gevent 则擅长将异步行为集成到现有的同步代码库中, 尤其是在处理 I/O 密集型任务时. 具体使用哪种还是要根据不同的开发环境判断.\n","title":"Asyncio vs Gevents in Python"},{"link":"/posts/prompt-organization/","text":"这篇文章旨在介绍 Python 中常用的提示词组织方式\nf-string 使用 f 字符串填充变量得到提示词\nPYTHON Collapse Copy def get_prompt(query: str) -\u0026gt; list[dict]: SYSTEM_PROMPT = f\u0026#34;\u0026#34;\u0026#34;... ... 多行提示词, 也可以填充变量 \u0026#34;\u0026#34;\u0026#34; USER_PROMPT = f\u0026#34;\u0026#34;\u0026#34;INPUT: {query} .... \u0026#34;\u0026#34;\u0026#34; return [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: SYSTEM_PROMPT}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: USER_PROMPT}, ] Click to expand and view more 这种方法实现简单, 速度快, 但是:\n多行字符串由于填充变量的需要, 需写在函数内, 导致代码格式混乱 PYTHON Collapse Copy # 实际上, 多行字符串还可以这样实现, 但也不太时候提示词太多的时候, 但这样代码格式会更加优雅 system_prompt = ( f\u0026#34;你是一名{role}负责...\\n\u0026#34; f\u0026#34;具体规则:\\n\u0026#34; f\u0026#34;1. ....\u0026#34; f\u0026#34;2. ....\u0026#34; ) Click to expand and view more 上面这种方法会将多行字符串合并, 注意不要加逗号, 不然就变成元组了 通过代码构造提示词, 任何修改都需要修改代码, 扩展性差 string.Template 使用 Python 元素字符串模板\nPYTHON Collapse Copy SYSTEM_PROMPT = string.Template(\u0026#34;\u0026#34;\u0026#34;你是一名$role 多行提示词... \u0026#34;\u0026#34;\u0026#34;) USER_PROMPT = string.Template(\u0026#34;\u0026#34;\u0026#34;INPUT: $query \u0026#34;\u0026#34;\u0026#34;) def get_prompt(role: str, query: str) -\u0026gt; list[dict]: system_prompt = SYSTEM_PROMPT.subtitute(role=\u0026#34;助手\u0026#34;) user_prompt = USER_PROMPT.subtitute(query=\u0026#34;问题...\u0026#34;) return [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: system_prompt}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_prompt}, ] Click to expand and view more 使用模板字符串, 模板则不必写在函数内, 且模板字符串可以选择替换部分变量, 使用 .safe_substitute()方法传入一个字典, 例如 {\u0026quot;query\u0026quot;: \u0026quot;问题...\u0026quot;}, 对没有传入的变量解析为 $var\n对比 f-string, 模板字符串更加灵活, 且可以只传入部分值\nJinja Jinja 是一个现代的设计者友好的, 仿照 Django 模板的 Python 模板语言. 它速度快, 被广泛使用, 并且提供了可选的沙箱模板执行环境保证安全:\n例如下面这个 .j2 文件内容, 构造了一个用于少样本提示的模板\nJINJA Collapse Copy {% if examples %} {% for example in examples %} INPUT: {{ example.input }} OUPUT: {{ example.output }} {% endfor %} {% endif %} INPUT: {{ user_input }} Click to expand and view more 导入该模板文件代码如下:\nPYTHON Collapse Copy from jinja2 import Environment, PackageLoader # 根据需要不同也可以使用 FileSystemLoader env = Environment( loader=PackageLoader(\u0026#34;app.module.prompt\u0026#34;, \u0026#34;template\u0026#34;), trim_blocks=True, # 移除 {% ... %} 块前后的多余空白 lstrip_blocks=True, # 移除行首 {% ... %} 块前的空白 ) def get_prompt(user_input: str) -\u0026gt; list[dict]: system_template = env.get_template(\u0026#34;system_template.j2\u0026#34;) user_template = env.get_template(\u0026#34;user_template.j2\u0026#34;) system_data = {\u0026#34;var\u0026#34;: val, ...} user_data = { \u0026#34;examples\u0026#34;: [ {\u0026#34;input\u0026#34;: \u0026#34;示例输入1\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;示例输出1\u0026#34;}, # 具体样例也可以通过函数传入 {\u0026#34;input\u0026#34;: \u0026#34;示例输入2\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;示例输出2\u0026#34;}, ], \u0026#34;user_input\u0026#34;: user_input\u0026#34;, } messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: system_template.render(system_data)}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_template.render(user_prompt)}, ] return messages Click to expand and view more 使用 Jinja 模板文件的好处是:\n方便组织提示词文件, 例如这里是将提示词文件放在 ProjectRoot/app/module/prompt 里面, 模板文件放在 prompt/template 里面, 在提示词文件中导入模板文件十分方便, 文件组织清晰, 代码可读性高, 且方便扩展 提示词灵活性更好, 对比 string.Template, Jinja 模板不仅可以填充变量, 还可以在模板中插入循环和条件判断等语法, 使得代码中只需提供一个字典格式的数据即可, 无需在代码里拼凑提示词, 也方便和 RAG 系统结合使用 虽然 Jinja 对比 string.Template 性能上要差一些, 但是 LLM 应用真正花时间的地方是模型的推理部分, 相比之下提示词渲染的时间几乎可以忽略不计. 如果提示词非常多, Jinja 还提供了异步渲染功能, 可以结合异步框架进一步提升性能.\nWrapping Up 上面就是近期使用的一些构造提示词的方法, 分别是 f-string、string.Template 和 Jinja.\n当然也有像 langchain_core.prompts.prompt.PromptTemplate 这样专用框架提供的提示词模板功能, 但是为了支持 LangChain LCEL 语法等原因, 导致其类型设计十分抽象, 且 LangChain 对新模型和新功能的支持比较缓慢, 加上版本不稳定, 接口经常变动, 故没有考虑使用 LangChain 框架提供的功能.(实际上, langchain 也支持使用 Jinja 模板)\n总之, 上面介绍的提示词构造方法各有优劣, 应该根据你项目的复杂度, 自行选择合适的提示词构造方式.\n","title":"Prompt Organization"},{"link":"/posts/from-python-to-go/","text":"From Python to Go: Why We Rewrote Our Ingest Pipeline at Telemetry Harbor\n我们将 Telemetry Harbor 的摄取管道从 Python FastAPI 重写为 Go，原因是遇到了严重的性能瓶颈。迁移后，效率提升了 10 倍，数据完整性因严格类型检查而得到加强，系统也拥有了稳定、可扩展的高并发时间序列数据摄取基础。\n背景：打造一个时间序列数据平台 Telemetry Harbor 源自我们在汽车行业积累的经验。几乎每个项目都要重复搭建相同的基础设施：数据库、后端、数据摄取管道、可视化界面。每次都要花费数周时间，这让我们萌生了打造一个开箱即用平台的想法。\n当时的市场方案并不理想。InfluxDB 的商业化策略让许多关键特性被锁在付费墙后，版本迁移成本高且在大数据负载下表现不佳。TimescaleDB 与 ClickHouse 技术上更强大，但依旧需要用户自行构建后端与摄取管道。我们看到了缺口——需要一个极简、可靠、可直接使用的平台。\nPython FastAPI：原型开发的正确选择 MVP 阶段，我们在开发速度与运行性能之间权衡。最终选择了 Python FastAPI，因为它允许我们：\n快速验证市场假设 迅速收集客户反馈并迭代 在低成本下尝试多种方案 尽快上线以抢占市场 早期架构非常直接：HTTP API（避免防火墙问题）、Redis + RQ 队列、TimescaleDB。测试效果良好，但很快暴露了性能隐患——RQ 的同步处理方式无法支撑高吞吐场景。\n性能瓶颈：Python 无法跟上增长 随着数据量上升，性能问题逐渐浮现：\n空闲 CPU 占用：10% 中等负载：约 40% CPU 高负载：120–300% CPU（峰值 800%），频繁崩溃 问题不仅在于 RQ 的同步限制，而是整个 Python 架构在常规负载下都难以维持稳定。这迫使我们考虑全面重写。\n迁移决策：为什么选择 Go？ 我们评估了 Rust 和 Go：\nRust：性能极致，但学习曲线陡峭，开发周期长。 Go：接近 Rust 的性能，开发简单，迭代快速。 最终选择 Go，以兼顾性能与开发速度。\n重写摄取管道 我们使用 Go Fiber 框架实现新服务，确保与 Python 版本 API 兼容，并通过版本控制平滑过渡（v1 为 Python，v2 为 Go）。\n性能提升显著：\n空闲 CPU：1%（原 10%） 高负载 CPU：约 60%，无崩溃 性能提升 10 倍，系统行为可预测 应用层性能瓶颈彻底消除。\n工程挑战：数据库约束处理 我们必须防止同一设备、货物、时间戳的重复数据。批量写入时，如果一条记录冲突，PostgreSQL 会拒绝整个批次。\n解决方案是两阶段插入：\n将数据写入临时表 由 PostgreSQL 从临时表中选择并插入合法记录 既保证性能，又维持数据完整性。\n新瓶颈：数据库性能 随着应用层变得高效，PostgreSQL 成为主要性能瓶颈。这是好事，数据库扩展手段更多（分片、只读副本、水平分区），可支持更高吞吐。\n意外发现：Pydantic 的类型强制转换\n在 Go 版本中，400 错误率升高。调查发现，Python/Pydantic 会隐式转换类型：\nTrue/False → 1/0 \u0026ldquo;123.45\u0026rdquo;（字符串） → 123.45（浮点） Go 严格拒绝此类数据，暴露了 Python 版本未检测的数据质量问题。我们决定保留 Go 的严格校验，防止潜在数据污染。\n现状与未来 目前两版 API 并行运行，新客户使用 Go v2。下一步将进行数据库分片以支持更大规模。\n经验教训\n快速原型，但要知道何时重写 性能不仅是速度，更是可预测性 类型安全能避免长期数据问题 严格校验比灵活容错更可靠 结论 Python 帮助我们快速验证市场并上线，而 Go 为我们提供了可扩展、稳定、可靠的生产基础。对于面临类似抉择的团队：当现有技术无法支撑下一阶段增长时，不要害怕重写。\n","title":"From Python to Go"},{"link":"/posts/redis-set/","text":"Redis 的集和 set 键允许用户将任意多个不同的元素存储到集和中, 既可以是文本数据, 也可以是二进制数据. 其与列表有以下两个明显的区别:\n列表可以存储重复元素, 而集和只存储非重复元素 列表以有序方式存储元素, 而集和则以无序方式存储元素 下面介绍结合键的各个命令\nSet 集和 SADD: 将元素添加到集和\nPLAINTEXT Collapse Copy SADD set element [element ...] Click to expand and view more 返回成功添加的新元素数量作为返回值, 由于集和不存储相同元素, 所以会自动忽略重复的元素\nSREM: 从集和中移出元素\nPLAINTEXT Collapse Copy SREM set element [element ...] Click to expand and view more 返回被移除的元素数量, 同样的, 不存在的元素会被忽略\nSMOVE: 将元素从一个集和移动到另一个集和\nPLAINTEXT Collapse Copy SMOVE source target element Click to expand and view more 移动操作成功时返回1, 若不存在于源集和, 返回0.\n如果 source 的元素不存在, 则返回0表示失败.\n如果 target 的元素已存在, 则会覆盖该元素. 从结果来看, 并不会导致 target 中元素变化, 但是会导致 source 中的该元素消失.\nSMEMBERS: 获取集和包含的所有元素\nPLAINTEXT Collapse Copy SMEMBERS set Click to expand and view more 由于集和是无序的, 且 SMEMBERS 命令不会进行任何排序操作, 所以根据元素添加的顺序不同, 含相同元素的集和执行该命令结果可能不同.\nSCARD: 获取集和包含的元素数量\nPLAINTEXT Collapse Copy SCARD set Click to expand and view more SISMEMBER: 检查给定元素是否存在于集和\nPLAINTEXT Collapse Copy SISMEMBER set element Click to expand and view more 返回1表示给定的元素存在于集和中, 返回0表示不存在于集和中.\n示例: 唯一计数器 例如, 一个网站想要统计浏览量和用户量\n流览量可以使用是网页被用户访问的次数, 一个用户可以多次访问. 这种类型的数量使用字符串键或者散列键都可以实现 用户数量是访问网站的 IP 地址数量, 这时候就需要构建一个更加严格的计数器, 对每个 IP 地址进行一次次数, 这种计数器就是唯一计数器(unique counter) PLAINTEXT Collapse Copy from redis import Redis class UniqueCounter: def __init__(self, client, key): self.client = client self.key = key def count_in(self, item): return self.client.sadd(self.key, item) def get_result(self): return self.client.scard(self.key) client = Redis(decode_responses=True) counter = UniqueCounter(client, \u0026#34;ip counter\u0026#34;) print(\u0026#34;Add ip\u0026#34;, counter.count_in(\u0026#34;8.8.8.8\u0026#34;)) print(\u0026#34;Add ip\u0026#34;, counter.count_in(\u0026#34;9.9.9.9\u0026#34;)) print(\u0026#34;Add ip\u0026#34;, counter.count_in(\u0026#34;10.10.10.10\u0026#34;)) print(\u0026#34;Numbers of IP:\u0026#34;, counter.get_result()) Click to expand and view more 示例: 点赞 点赞功能可以使用集和来实现, 保证了每个用户对同一个内容只能点1次赞\nPLAINTEXT Collapse Copy from redis import Redis class Like: def __init__(self, client, key): self.client = client self.key = key def cast(self, user): \u0026#34;\u0026#34;\u0026#34;执行点赞 True/False\u0026#34;\u0026#34;\u0026#34; return self.client.sadd(self.key, user) def undo(self, user): \u0026#34;\u0026#34;\u0026#34;取消点赞\u0026#34;\u0026#34;\u0026#34; self.client.srem(self.key, user) def is_liked(self, user): \u0026#34;\u0026#34;\u0026#34;是否已点赞\u0026#34;\u0026#34;\u0026#34; return self.client.sismember(self.key, user) def get_all_liked_users(self): \u0026#34;\u0026#34;\u0026#34;所有点赞用户\u0026#34;\u0026#34;\u0026#34; return self.client.smembers(self.key) def count(self): \u0026#34;\u0026#34;\u0026#34;点赞人数\u0026#34;\u0026#34;\u0026#34; return self.client.scard(self.key) client = Redis(decode_responses=True) like_topic = Like(client, \u0026#34;topic::10086::like\u0026#34;) print(\u0026#34;Peter like:\u0026#34;, like_topic.cast(\u0026#34;peter\u0026#34;)) print(\u0026#34;Mary like:\u0026#34;, like_topic.cast(\u0026#34;mary\u0026#34;)) print(\u0026#34;Liked Users:\u0026#34;, like_topic.get_all_liked_users()) print(\u0026#34;How many likes:\u0026#34;, like_topic.count()) print(\u0026#34;Peter liked:\u0026#34;, like_topic.is_liked(\u0026#34;peter\u0026#34;)) print(\u0026#34;Dan liked:\u0026#34;, like_topic.is_liked(\u0026#34;dan\u0026#34;)) Click to expand and view more 示例: 投票 问答网站、文章推荐网、论坛这类注重内容质量的网站上通常会提供投票功能, 用户可以通过投票来支持一项内容或者反对一项内容:\n支持票越多的文章, 会被网站安排到更显眼的位置, 使得网站的用户快速流览高质量内容. 反对票越多的文章, 则会被放到更不明显的位置, 甚至被当作广告隐藏起来, 使得用户可以忽略这些低质量内容. 例如 Stackoverflow 上面会对回答的答案进行投票, 帮助用户发现高质量的问题和答案.\nPYTHON Collapse Copy from redis import Redis def vote_up_key(vote_target): \u0026#34;\u0026#34;\u0026#34;赞成 vote_target 用户集和 key\u0026#34;\u0026#34;\u0026#34; return vote_target + \u0026#34;::vote_up\u0026#34; def vote_down_key(vote_target): \u0026#34;\u0026#34;\u0026#34;反对 vote_target 用户集和 key\u0026#34;\u0026#34;\u0026#34; return vote_target + \u0026#34;::vote_down\u0026#34; class Vote: def __init__(self, client, vote_target): self.client = client self.vote_up_set = vote_up_key(vote_target) self.vote_down_set = vote_down_key(vote_target) def is_voted(self, user): \u0026#34;\u0026#34;\u0026#34;检查用户是否已投过票\u0026#34;\u0026#34;\u0026#34; return self.client.sismember(self.vote_up_set, user) or self.client.sismember(self.vote_down_set, user) def vote_up(self, user): \u0026#34;\u0026#34;\u0026#34;user 投赞成票\u0026#34;\u0026#34;\u0026#34; if self.is_voted(user): return False self.client.sadd(self.vote_up_set, user) return True def vote_down(self, user): \u0026#34;\u0026#34;\u0026#34;user 投反对票\u0026#34;\u0026#34;\u0026#34; if self.is_voted(user): return False self.client.sadd(self.vote_down_set, user) return True def undo(self, user): \u0026#34;\u0026#34;\u0026#34;取消用户投票\u0026#34;\u0026#34;\u0026#34; self.client.srem(self.vote_up_set, user) self.client.srem(self.vote_down_set, user) def vote_up_count(self): \u0026#34;\u0026#34;\u0026#34;赞成票的数量\u0026#34;\u0026#34;\u0026#34; return self.client.scard(self.vote_up_set) def get_all_vote_up_users(self): \u0026#34;\u0026#34;\u0026#34;所有投赞成票的用户\u0026#34;\u0026#34;\u0026#34; return self.client.smembers(self.vote_up_set) def vote_down_count(self): \u0026#34;\u0026#34;\u0026#34;反对票的数量\u0026#34;\u0026#34;\u0026#34; return self.client.scard(self.vote_down_set) def get_all_vote_down_users(self): \u0026#34;\u0026#34;\u0026#34;所有投反对票的用户\u0026#34;\u0026#34;\u0026#34; return self.client.smembers(self.vote_down_set) client = Redis(decode_responses=True) # 是否将字节数据自动解码额日字符串 question_vote = Vote(client, \u0026#34;question::10\u0026#34;) print(\u0026#34;Peter 投支持票:\u0026#34;, question_vote.vote_up(\u0026#34;peter\u0026#34;)) print(\u0026#34;Jack 投支持票:\u0026#34;, question_vote.vote_up(\u0026#34;jack\u0026#34;)) print(\u0026#34;Tom 投支持票:\u0026#34;, question_vote.vote_up(\u0026#34;tom\u0026#34;)) print(\u0026#34;Mary 投反对票:\u0026#34;, question_vote.vote_down(\u0026#34;mary\u0026#34;)) print(\u0026#34;支持票数量:\u0026#34;, question_vote.vote_up_count()) print(\u0026#34;反对票数量:\u0026#34;, question_vote.vote_down_count()) print(\u0026#34;支持票用户:\u0026#34;, question_vote.get_all_vote_up_users()) print(\u0026#34;反对票用户:\u0026#34;, question_vote.get_all_vote_down_users()) # 取消用户投票(为了多次运行代码) question_vote.undo(\u0026#34;peter\u0026#34;) question_vote.undo(\u0026#34;jack\u0026#34;) question_vote.undo(\u0026#34;tom\u0026#34;) question_vote.undo(\u0026#34;mary\u0026#34;) Click to expand and view more 示例: 社交关系 Twitter 这类社交软件都可以通过关注或者加好友的方式, 构成一种社交关系. 这些网站上的用户都可以关注其他用户, 也可以被其他用户关注. 通过正在关注名单(following list), 用户可以查看自己正在关注的用户及其人数; 通过关注者名单(follower list), 用户可以查看有哪些人正在关注自己.\n下面使用集和来维护这种关系:\n程序为每个用户维护两个集和: 一个集和存储用户的正在关注名单, 另一个集和存储用户的关注者名单. 当 A 关注 B 的时候, 将 A 加入自己的 following list, 并加入 B 的follower list. 当 A 取消对 B 的关注的时候, 将 A 从自己的 following list 移出, 并将 A 从 B 的 follower list 移除. PYTHON Collapse Copy def following_key(user): return user + \u0026#34;::following\u0026#34; def follower_key(user): return user + \u0026#34;::follower\u0026#34; class Relationship: def __init__(self, client, user): self.client = client self.user = user def follow(self, target): \u0026#34;\u0026#34;\u0026#34;关注目标用户\u0026#34;\u0026#34;\u0026#34; user_following_set = following_key(self.user) self.client.sadd(user_following_set, target) target_follower_set = follower_key(target) self.client.sadd(target_follower_set, self.user) def unfollow(self, target): \u0026#34;\u0026#34;\u0026#34;取消关注目标用户\u0026#34;\u0026#34;\u0026#34; user_following_set = following_key(self.user) self.client.srem(user_following_set, target) target_follower_set = follower_key(target) self.client.srem(target_follower_set, self.user) def is_following(self, target): \u0026#34;\u0026#34;\u0026#34;是否关注了目标用户\u0026#34;\u0026#34;\u0026#34; user_following_set = following_key(self.user) return self.client.sismember(user_following_set, target) def get_all_following(self): \u0026#34;\u0026#34;\u0026#34;所有user关注的用户\u0026#34;\u0026#34;\u0026#34; user_following_set = following_key(self.user) return self.client.smembers(user_following_set) def get_all_follower(self): \u0026#34;\u0026#34;\u0026#34;所有关注user的用户\u0026#34;\u0026#34;\u0026#34; user_follower_set = follower_key(self.user) return self.client.smembers(user_follower_set) def count_following(self): \u0026#34;\u0026#34;\u0026#34;user关注的用户数量\u0026#34;\u0026#34;\u0026#34; user_following_set = following_key(self.user) return self.client.scard(user_following_set) def count_follower(self): \u0026#34;\u0026#34;\u0026#34;关注user的用户数量\u0026#34;\u0026#34;\u0026#34; user_follower_set = follower_key(self.user) return self.client.scard(user_follower_set) Click to expand and view more SRANDMEMBER: 随机获取集和中的元素\nPLAINTEXT Collapse Copy SRANDMEMBER set [count] Click to expand and view more 该命令接受一个可选的 count 参数, 用于指定用户想要获取的元素数量. 默认只返回一个元素.\n如果 count 为正数, 将返回 count 个不重复的元素. 当 count 值大于集的元素数量, 将返回集和所有元素.\n如果 count 为负数, 则随机返回 abs(count) 个元素, 并且允许出现重复值.\nSPOP: 随机地从集和中移出指定数量的元素\nPLAINTEXT Collapse Copy SPOP key [count] Click to expand and view more 该命令会返回被移除的元素值作为命令的返回值.\ncount 参数不同于 SRANDMEMBER 命令的参数, 其值只能为正数\n示例: 抽奖 为了推销产品并回馈消费者, 商家经常举办一些抽奖活动, 消费者可以抽奖获取礼品. 下面代码展示了使用集和实现的抽象程序, 这个成会把所有参与抽奖的玩家都添加到一个集和中, 然后通过 SRANDMEMBER 命令随机地选出获奖者.\nPYTHON Collapse Copy class Lottery: def __init__(self, client, key): self.client = client self.key = key def add_player(self, user): \u0026#34;\u0026#34;\u0026#34;添加用户到抽奖名单中\u0026#34;\u0026#34;\u0026#34; self.client.sadd(self.key, user) def get_all_players(self): \u0026#34;\u0026#34;\u0026#34;返回参加抽奖活动的所有用户\u0026#34;\u0026#34;\u0026#34; return self.client.smembers(self.key) def player_count(self): \u0026#34;\u0026#34;\u0026#34;返回抽奖用户数量\u0026#34;\u0026#34;\u0026#34; return self.client.scard(self.key) def draw(self, number): \u0026#34;\u0026#34;\u0026#34;抽取指定数量的获奖者\u0026#34;\u0026#34;\u0026#34; return self.client.srandmember(self.key, number) Click to expand and view more 考虑到完整的抽奖者名单可能会有用, 所以这个抽奖程序使用了随机获取元素的 SRANDMEMBER 命令, 而不是随机移除元素的 SPOP 命令. 如果不需要保留完整的名单, 也可以使用 SPOP 命令实现抽奖程序.\nSINTER、SINTERSTORE: 对集和执行交集计算\nPLAINTEXT Collapse Copy SINTER set [set ...] Click to expand and view more 该命令计算用户给定的所有集和的交集, 返回交集的所有元素.\n此外, 还有 SINTERSTORE 命令, 将集和的交集计算结果存储到指定的键里面.\nPLAINTEXT Collapse Copy SINTERSTORE destination_key set [set ...] Click to expand and view more 如果给定的键已存在, 则 SINTERSTORE 命令结果会覆盖原来的集和键\nSUNION、SUNIONSTORE: 对集和执行并集计算\nPLAINTEXT Collapse Copy SUNION set [set ...] Click to expand and view more 并集计算类似上面的交集计算\nSDIFF、SDIFFSTORE: 对集和执行差集计算\nPLAINTEXT Collapse Copy SDIFF set [set ...] Click to expand and view more SDIFF 命令会安装用户给定集和的顺序, 从左到右依次对给定的集和执行差集计算.\n因为对集合执行交集、并集、差集等集合计算需要耗费大量的资源, 所以用户应该尽量使用SINTERSTORE等命令来存储并重用计算结果, 而不要每次都重复进行计算. 此外, 当集合计算涉及的元素数量非常大时, Redis服务器在进行计算时可能会被阻塞. 这时, 可以考虑使用Redis的复制功能, 通过从服务器来执行集合计算任务, 从而确保主服务器可以继续处理其他客户端发送的命令请求.\n共同关注与推荐关注\n前面使用集和实现了社交网站好友关系的存储, 即关注和被关注列表. 除此之外, 社交网站还通常会提供一些额外功能, 例如共同关注, 推荐关注等.\n要实现共同关注功能, 程序需要计算出两个用户正在关注集和之间的交集.\n推荐关注可以从用户关注集和中, 随机选出指定数量的用户作为种子用户, 然后对这些用户的正在管组集和执行并集计算, 最后从这个并集中随机选出一些推荐关注的对象. 示例: 使用反向索引构建商品筛选器 在访问购物类网站的时候, 通常可以通过一些标签来筛选产品. 这时候, 对每个产品可以建立一个集和, 对每个标签也都建立一个集和, 这样就得到了一份物品到关键字, 以及关键字到物品的映射关系.\nPYTHON Collapse Copy def make_item_key(item): return \u0026#34;InvertedIndex::\u0026#34; + item + \u0026#34;::keyword\u0026#34; def make_keyword_key(keyword): return \u0026#34;InvertedIndex::\u0026#34; + keyword + \u0026#34;::item\u0026#34; class InvertedIndex: def __init__(self, client): self.client = client def add_index(self, item, *keywords): \u0026#34;\u0026#34;\u0026#34;为物品添加关键字\u0026#34;\u0026#34;\u0026#34; # 将给定物品添加到 item_key = make_item_key(item) result = self.client.sadd(item_key, *keywords) # 遍历关键字集和, 将该物品添加进去 for keyword in keywords: keyword_key = make_keyword_key(keyword) self.client.sadd(keyword_key, item) # 返回添加关键字数量作为结果 return result def remove_index(self, item, *keywords): \u0026#34;\u0026#34;\u0026#34;移除物品的关键字\u0026#34;\u0026#34;\u0026#34; item_key = make_item_key(item) result = self.client.srem(item_key, *keywords) for keyword in keywords: keyword_key = make_keyword_key(keyword) self.client.srem(keyword_key, item) return result def get_keywords(self, item): \u0026#34;\u0026#34;\u0026#34;获取物品所有的关键字\u0026#34;\u0026#34;\u0026#34; return self.client.smembers(make_item_key(item)) def get_items(self, *keywords): \u0026#34;\u0026#34;\u0026#34;根据给定的关键字获取物品\u0026#34;\u0026#34;\u0026#34; # 根据给定的关键字计算出与之对应的集合 key keyword_key_list = map(make_keyword_key, keywords) # 将这些集和 key 做并集 return self.client.sinter(*keyword_key_list) Click to expand and view more ","title":"Redis Set"},{"link":"/posts/documenting-rest-apis-with-openapi/","text":"本章介绍如何使用 OpenAPI 来为 API 编写文档. OpenAPI 是描述 RESTful API 最流行的标准, 拥有丰富的生态系统, 可以用于测试、验证和可视化 API. 大多数编程语言都支持 OpenAPI 规范的库.\nOpenAPI 使用 JSON Schema 来描述 API 的结构和模型, 因此首先介绍 JSON Schema 的工作原理. JSON Schema 是一种用于定义 JSON 文档结构的规范, 包括文档中值的类型和格式.\nUsing JSON Schema to model data 使用 JSON Schema 对数据建模\nJSON Schema 是一种规范标准, 用于定义 JSON 文档的结构及其属性的类型和格式. JSON Schema 规范通常定义一个具有特定属性或特性的对象, 由键值对的关联数组表示, 如下面这样:\nJSON Collapse Copy { \u0026#34;status\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } } Click to expand and view more 在 JSON Schema 规范中, 每个属性都以键值对的形式出现, 其中值是该属性的描述符 一个属性最基本的描述符就是 type, 上面例子中, 指定类型为字符串 JSON Schema 支持以下基本数据类型:\nstring: 字符串 number: 整数和十进制数 object: 关联数组 (类似py中的字典) array: 其他数据类型的集合 boolean: 真或假 null: 未初始化的数据 定义一个 object 的例子\nJSON Collapse Copy { \u0026#34;order\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;product\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;size\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;intger\u0026#34; } } } } Click to expand and view more 由于 order 是一个 object, 故 order 属性有 properties. 每个 property 都有自己的类型.\n一个符合规则的 JSON 文档例子如下\nJSON Collapse Copy { \u0026#34;order\u0026#34;: { \u0026#34;product\u0026#34;: \u0026#34;coffee\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;big\u0026#34;, \u0026#34;quantity\u0026#34;: 1, } } Click to expand and view more 属性 property 也可以代表一个项目的数组.\norder 对象代表一个对象的数组, 使用 items 关键字来定义数组中的元素.\nJSON Collapse Copy { \u0026#34;order\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;product\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;size\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; } } } } } Click to expand and view more 在上面例子中, order 属性是一个数组 array. 数组类型需要在模式 schema 中有一个额外的属性, 那就是 items 属性, 其定义了数组中包含的每个元素的类型. 这种情况下, 数组中的每个元素都是一个对象, 代表订单中的一个项目.\n一个对象可以包含任意数量的嵌套对象, 但是, 嵌套太多时, 缩进会变得很大, 导致规范难以阅读.\n为了避免这个问题, JSON Schema 允许单独定义每个对象, 并使用 JSON 指针 (JSON pointers) 来引用它们.\nJSON pointers 是一种特殊语法, 运行向统一分规范中的另一个对象定义.\n如下面代码, 可以将 order 数组中的每个项的定义提取为一个名为 OrderItemSchema 的模型. 然后使用一个 JSON 指针和特殊的 $ref 关键字来引用 OrderItemSchema\nJSON Collapse Copy { \u0026#34;OrderItemSchema\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;product\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;size\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; } } }, \u0026#34;Order\u0026#34;: { \u0026#34;status\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;order\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#39;#/OrderItemSchema\u0026#39; } } } } Click to expand and view more JSON 指针使用特殊关键字 $ref 和 JSONPath 语法来指向 schema 中的另一个定义.\n在 JSONPath 的语法中, 文档的根(root)使用井号 # 表示, 嵌套属性的关系由斜线(slashes) / 表示. 例如, 如果响应创建 #/OrderItemSchema 模型的 size 属性的指针, 我们会使用如下的语法 #/OrderItemSchema/size.\n通过将通用的模式对象提取成壳重用的模型, 并使用 JSON 指针来引用他们, 从而对规范进行重构, 这有助于避免重复, 并报慈整洁和简洁.\n除了指定类型之外, JSON Schema 还允许指定属性的格式(foramt), 可以自定义格式, 也可以使用 JSON Schema 内置的格式.\n例如, 一个代表日期的属性, 可以使用 data 格式, 这是 JSON Schema 支持的内置格式, 代表一个 ISO 日期(如2025-05-21)\nPLAINTEXT Collapse Copy { \u0026#34;created\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;date\u0026#34; } } Click to expand and view more 除了使用 JSON, JSON Schema 实际上还可以使用 YAML 来编写, 这种格式更加常见且更容易理解. OpenAPI 规范也通常以 YAML 格式提供, 后面部分使用 YAML 格式编写.\nAnatomy of an OpenAPI specification 剖析 OpenAPI 规范\nOpenAPI 是一种用于文档化 Restful API 的标准规范格式. 它允许我们详细描述 API 的每一个元素, 包括其端点 endpoints、请求响应和有效载荷(payloads)的格式、安全方案(security schemes)等等. OpenAPI 最初于2010年以 Swagger 的名称创建, 2015年 Linux 基金会和主要公司的联盟共同赞助成立了 OpenAPI Initiative, 是一个旨在改进构建 RESTful API 的协议和标准的项目. 如今, OpenAPI 是迄今为止用于文档化 RESTful API 最流行的规范格式, 它拥有丰富的生态系统工具, 可用于 API 可视化、测试和验证.\nOpenAPI 包含了和 API 交互所需要的一切信息, 一份 OpenAPI 规范由5个部分构成:\nopenapi: 指明版本 info: API 的基本信息, 例如标题和版本 servers: 包含 API 可用的 URL 列表. 可以列出用于不同环境的多个 URL. paths: 描述 API 公开的端点, 包括预期的有效载荷(payloads)、允许的参数以及响应的格式. 这是规范中最重要的部分, 因为它代表了 API 的接口, 也是使用者为了学习如何与 API 集成会查看的部分. components: 定义了在整个规范中被引用的可重复元素. 例如模式(schemas)、参数、安全方案、请求体和响应等. 模式是对请求和响应中预期属性和类型的定义. OpenAPI 模式是使用 JSON Schema 语法定义的. Documenting the API endpoints 文档化 API 端点\nOpenAPI 的 path 部分描述了 API 接口, 它列出了 API 公开的 URL 路径, 以及实现的 HTTP 方法, 预期的请求类型和返回的响应.\n每个路径都是一个对象, 其属性为它支持的 HTTP 方法, 这里将说明 URL 路径和 HTTP 方法的文档化.\n在之前定义了如下端点:\nPOST /orders: 请求订单. 需要订单的细节信息. GET /orders: 返回订单列表. 接受 URL 查询参数, 并允许过滤结果. GET /orders/{order_id}: 返回订单细节信息 PUT /orders/{order_id}: 更新订单细节信息, 由于这是一个 PUT 端点, 要求订单的全面信息. DELETE /orders/{order_id}: 删除订单 POST /orders/{order_id}/pay: 为订单付款 POST /orders/{order_id}/cancel: 取消订单 下面是 API 订单的高层定义, 声明了 URL 和每个 URL 所实现的 HTTP 方法, 并为每个端点添加了一个操作ID(operation ID), 以便在文档其他部分引用:\nYAML Collapse Copy paths: /orders: get: operationId: createOrder /orders/{order_id}: get: operationId: getOrder put: operationId: updateOrder delete: opertaionId: deleteOrder /orders/{order_id}/pay: post: operationId: payOrder /orders/{order_id}/cancel: post: operationId: cancelOrder Click to expand and view more 现在有了端点, 还需要填充其中的细节.\n对于 GET /orders 端点, 需要描述接受它的参数 对于 POST 和 PUT 端点, 需要描述请求的有效载荷 payloads\n此外, 还需要为每个端点描述其响应 Documenting URL query parameters 文档化 URL 查询参数\nURL query parameter 允许我们过滤和排序 GET endpoint 的结果. 在本章中, 将使用 OpenAPI 定义 URL query parameters. GET /orders endpoint 允许我们使用下面的参数过滤订单:\ncancelled: 订单是否被取消, 类型 boolean limit: 表示返回给用户的订单的最大数量 合并起来使用大概下面这样:\nPLAINTEXT Collapse Copy GET /orders?cancelled=true\u0026amp;limit=5 Click to expand and view more 这个请求向服务器请求一个 5条已经取消 的订单的列表.\nPLAINTEXT Collapse Copy paths: /orders: get: parameters: - name: cancelled in: query required: false schema: type: boolean - name: limit in: query required: false schema: type: integer Click to expand and view more 定义一个参数需要一个名称 name, 这个名称就是实际 URL 中用来指引它的值. 还需要指定参数的类型, 在 OpenAPI 3.1 区分了四种类型参数: 路径参数(path parameters)、查询参数(query parameters)、头部参数(header parameters)和Cookie 参数(cookie parameters).\n头部参数是在 HTTP 头部字段中的参数, 而 Cookie 参数则放在 Cookie 有效载荷中. 路径参数是 URL 路径的一部分, 通常用于标识一个资源. 查询参数是可选参数, 允许对端点的结果进行过滤和排序.\n使用 schema 关键字参数来定义参数的类型, 并且在相关时, 也会指定参数的格式. Documenting request payloads 文档化请求载荷\n一个请求代表 client 通过 POST 或 PUT 方法向 server 发送的数据. 这节介绍 API endpoints 的 request payloads.\n例如 POST /orders 方法:\nJSON Collapse Copy { \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;cappuccinio\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;big\u0026#34;, \u0026#34;quantity\u0026#34;: 1 } ] } Click to expand and view more 这个 payload 包含一个 order 属性, 代表了一系列的物品. 每个物品被定义为下面的3个属性和约束:\nproduct: 用户订购的产品类型 size: 产品的大小. 有3种选择: small, medium 和 big quantity: 产品的数量. 可以是任何大于等于1的整数 下面展示如何为这个有效载荷 payload 定义模式\nYAML Collapse Copy paths: /orders: post: operationId: createOrder requestBody: required: true content: application/json: schema: type: object properties: order: type: array items: type: object properties: product: type: string size: type: string enum: - small - medium - big quantity: type: intger required: false default: 1 required: - product - size Click to expand and view more 通过 HTTP 方法的 requestBody 属性下的 content 属性来定义 payload, 并可以指定不同的有效载荷. 有效载荷可以指定为不同的格式, 在本例中, 只允许 JSON 格式数据, 媒体类型为 application/json.\n这里的有效载荷的模式是一个对象, 有一个属性 order, 其类型为数组, 数组中的元素的对象, 包含3个属性: product(类型为字符串), size(类型为字符串) 和 quantity(类型为整数).\n此外, 还为 size 属性定义了一个枚举(enumeration), 将可接受的值限制为 samll、medium 和 big 3种.\n最后, 还为 quantity 属性提供了默认值 1, 因为它是有效载荷中唯一非必须的字段.\nRefactoring schema definitions to avoid repetition 重构 schema 定义从而避免重复\n在本节将介绍重构模式 refactoring schemas 的策略, 以保持 API 规范的整洁和可读性.\n上面的 POST /orders 端点定义很长, 包含多层缩进, 难以阅读, 意味着会变得难以扩展和维护.\n可以将有效载荷 payload 的模式移动到 API 规范的 components 部分. 该部分用于声明在整个规范中被引用的模式, 每个模式都是一个对象, 其中键是模式的名称, 而值是属性的对象.\nYAML Collapse Copy paths: /orders: post: operatoinId: createOrder requestBody: required: true content: application/json: schema: $ref: \u0026#39;#/components/schemas/CreateOrderSchema\u0026#39; ① components: ② schemas: ③ CreateOrderSchema: type: object properties: type: array items: type: object properties: product: type: string size: type: string enum: - samll - medium - big quantity: type: intger required: false default: 1 required: - product - size Click to expand and view more 使用 JSON pointer 指向文档其他位置 schema 定义在 components 下面 每个 schema 都是一个对象, 其中 key(CreateOrderSchema) 是名称, values(CreateOrderSchema下面的所有内容) 是描述属性 properties 将 POST /orders 请求有效载荷的模式移动到 API 的 components 部分, 能使文档更具可读性. 这样得以保持 path 部分的简洁, 并专注于端点的高层细节. 只需要使用一个 JSON 指针来引用 CreateOrderSchema 模式:\nPLAINTEXT Collapse Copy #/components/schemas/CreateOrderSchema Click to expand and view more 这份规范现在已经不错了, 但是可以更好. CreateOrderSchema 有些长, 并且包含了多层嵌套定义. 如果 CreateOrderSchema 的复杂性随着时间增长, 将越来越难以维护. 可以通过下面方式重构数组中订单项的定义, 使其更加具有可读性, 这个策略运行 API 的其他部分重用订单项的模式.\nYAML Collapse Copy components: schemas: OrderItemSchema: ① type: object properties: product: type: string size: type: string enum: - small - medium - big quantity: type: integer default: 1 CreateOrderSchema: type: object properties: order: type: array items: $ref: \u0026#39;#/OrderItemSchema\u0026#39; ② Click to expand and view more OrderItemSchema: 订单中的项 CreateOrderSchema: 使用一个 JSON pointer 指向 OrderItemSchema 现在 schemas 看起来就好多了, 并且可以在 /POST /orders/{order_id} 端点中重用它.\n/orders/{order_id} 代表一个单例资源(singleton resource), 因此 URL 包含一个路径参数, 即订单ID. 在 OpenAPI 中, 路径参数使用大括号{} 表示.\nPLAINTEXT Collapse Copy paths: /orders: get: ... /orders/{order_id}: ① parameters: ② - in: path ③ name: order_id ④ required: true ⑤ schema: type: string format: uuid ⑥ put: ⑦ operationId: updateOrder requestBody: ⑧ required: true content: application/json: schema: $ref: \u0026#39;#/components/schemas/CreateOrderSchema Click to expand and view more 定义订单的资源地址 定义 URL path parameter order_id 参数是 URL 路径的一部分 参数名称 必填参数 具体参数格式(UUID) 为当前 URL 定义 PUT 方法 文档化 request body 的 PUT 端点 Documenting API responses 文档化响应体\nGET /orders/{order_id} 端点的响应类似下面这样:\nJSON Collapse Copy { \u0026#34;id\u0026#34;: \u0026#34;924721eb-a1a1-4f13-b384-37e89c0e0875\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;progress\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;2022-05-01\u0026#34;, \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;cappuccino\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;small\u0026#34;, \u0026#34;quantity\u0026#34;: 1 }, { \u0026#34;product\u0026#34;: \u0026#34;croissant\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 2 } ] } Click to expand and view more 这个有效载荷展示了用户订购的产品, 下单时间以及订单状态. 类似之前 POST 和 PUT 端点定义的请求有效载荷, 因此可以重用之前的模式.\nYAML Collapse Copy components: schemas: OrderItemSchema: ... GetOrderSchema: ① type: object properties: status: type: string enum: ② - created - paid - progress - cancelled - displatched - delivered created: type: string format: date-time ③ order: type: array items: $ref: \u0026#39;#/components/schemas/OrderItemSchema\u0026#39; ④ Click to expand and view more 定义 GetOrderSchema 模式 使用枚举限制状态属性 日期格式的字符串 使用 JSON pointer 引用 OrderItemSchema 在上面的清单中, 使用一个 JSON 指针指向 GetOrderSchema. 另一种重用现有模式的方法是继承.\n在 OpenAPI 中, 可以通过一种称为模式组合(model composition) 的策略来继承和扩展一个模式, 该策略允许将不同模式的属性组合到一个单一的对象定义中. 在这种情况下, 使用特殊关键词 allOf 来表示该对象需要包含列出的所有模式中的属性.\nYAML Collapse Copy components: schemas: OrderItemSchema: ... GetOrderSchema: allOf: ① - $ref: \u0026#39;#/components/schemas/CreateOrderSchema\u0026#39; ② - type: object ③ properties: status: type: string enum: - created - paid - progress - cancelled - dispatched - delivered created: type: string format: date-time Click to expand and view more 使用 allOf 关键字继承其他 schemas 的属性 使用 JSON pointer 引用其他的 schema 使用一个新对象 GetOrderSchema 来包含特有的属性 模型组合(Model composition) 能使规范更简洁、更紧凑, 但它只在模式严格兼容的情况才有效.\n如果决定使用新的属性来扩展 CreateOrderSchema, 那么这个模式可能就不再能用于 GetOrderSchema 模型.\n从这个意义上讲, 有时候更好的做饭是寻找不同模式中的共同元素, 将其定义重构为独立的模式.\n现在有了 GET /orders/{order_id} 端点响应有效载荷的模式, 就可以完善该端点的规范了. 把端点的响应定义为对象, 其中键是响应的状态码, 并描述响应的内容类型及其模式.\nYAML Collapse Copy paths: /orders: get: ... /orders/{order_id}: parameters: - in: path name: order_id required: true schema: type: string format: uuid put: ... get: ① summary: Returns the details of a specific order ② operationId: getOrder responses: ③ \u0026#39;200\u0026#39;: ④ description: OK ⑤ content: ⑥ application/json: schema: $ref: \u0026#39;#/components/schemas/GetOrderSchema\u0026#39; ⑦ Click to expand and view more 定义 GET /order/{order_id} endpoint 为该端点提供一个描述 定义一个端点响应 每个响应都是一个对象, 其中 key 为状态码 响应的简单描述 描述响应的内容类型 使用 JSON pointer 引用 GetOrderSchema 根据上面内容可以看到, 在端点的 responses 部分定义了响应模式(schemas), 在这种情况下, 值提供了 200 (OK) 成功响应的规范, 但也可以为其他状态码编写文档.\nCreating generic responses 创建同样响应\n本节介绍如何为 API 端点添加错误响应. 错误响应更具通用性, 因此可以使用 API 规范的 components 部分来提供这些响应的通用定义, 然后在端点中使用他们.\n这里在 API 的 components 部分的 responses 标头下定义通用响应. 下面展示了一个名为 NotFound 的 404 响应通用定义. 与任何其他响应意义, 也会为其有效载荷编写文档, 本例中有效载荷由 Error 模式定义.\nPLAINTEXT Collapse Copy components: responses: ① NotFound: ② description: The specified resource was not found. ③ content: ④ application/json: schema: $ref: \u0026#39;#/components/schemas/Error\u0026#39; ⑤ schemas: OrderItemSchema: ... Error: ⑥ type: object properties: detail: type: string required: - detail Click to expand and view more 通用响应定义在 components 部分的 responses 下 为这个响应命名 描述这个响应 定义响应内容 引用 Error 模式 定义 Error 有效载荷的模式 上面这份针对 404 响应的规范可以在 /orders/{order_id} URL 路径下的所有端点规范中重复使用, 因为所有这些端点都是专门设计来针对特定资源的.\n在 OpenAPI 的 GitHub 仓库中, 有一个请求是希望允许在 URL 路径下直接包含通用响应, 但目前尚未实现\n下面定义 /orders/{order_id} 的 404 响应模式\nYAML Collapse Copy paths: ... /orders/{order_id}: parameters: - in: path name: order_id required: true schema: type: string \u0026#34;format\u0026#34;: uuid get: summary: Returns the details of a specific order operationId: getOrder responses: \u0026#39;200\u0026#39;: description: OK content: application/json: schema: $ref: \u0026#39;#/components/schemas/GetOrderSchema\u0026#39; \u0026#39;404\u0026#39;: ① $ref: \u0026#39;#/components/responses/NotFound\u0026#39; ② Click to expand and view more 定义一个 404 响应 使用 JSON 指针引用 NotFound 响应 剩下的一个端点是 GET /orders, 它返回一个订单列表, 该端点的有效载荷重用了 GetOrderSchema 来定义订单数组中的项目\nYAML Collapse Copy paths: /orders: get: ① operationId: getOrders responses: \u0026#39;200\u0026#39;: description: A JSON array of orders content: application/json: schema: type: object properties: orders: type: array ② items: $ref: \u0026#39;#/components/schemas/GetOrderSchema\u0026#39; ③ required: - order post: ... /orders/{order_id}: parameters: ... Click to expand and view more 定义 /orders URL 路径的新 GET 方法 orders 是一个数组 数组的每个项目都由 GetOrderSchema 定义 现在, API 的端点已完全文档化. 可以在端点定义中使用更多的元素, 例如 tags 和 externalDocs. 些属性并非绝对必要, 但可以帮助为 API 提供更多结构, 或使其更易于对端点进行分组.\nDefining the authentication scheme of the API 定义 API 的认证模式\n如果 API 受到到保护, API 规范必须描述用户如何进行身份认证和授权请求. API 安全定义位于规范的 components 部分, 在 securitySchema 标头下.\n通过 OpenAPI, 可以描述不同的安全方案, 例如基于 HTTP 的认证、基于密钥的认证、OAuth2 开放授权 和 OpenID Connect.\n下面描述了3种方案: 一种用于 OpenID Connect, 一种用于 OAuth2, 还有一种用于 Bearer 授权.\n这里使用 OpenID Connect 通过前端应用来授权用户访问\n对于 OpenID Connect, 必须在 openIdConnectUrl 属性下提供一个配置 URL, 该 URL 描述了后端客户端如何认证工作 对于直接的 API 集成, 提供 OAuth 的客户端凭证流(client credentials flow)\n对于 OAuth2, 必须描述可用的授权流(authentication flows), 以及客户端必须用于获取其授权令牌的 URL 和可用的作用域(scopes).\nBearer 授权告诉用户, 他们必须在 Authorization 头部中包含一个 JSON Web Token(JWT) 来授权其请求. YAML Collapse Copy components: responses: ... schemas: ... securitySchemes: ① openId: ② type: openIdConnect ③ openIdConnectUrl: https://coffeemesh-dev.eu.auth0.com/.well-known/openid-configuration ④ oauth2: ⑤ type: oauth2 ⑥ flows: ⑦ clientCredentials: ⑧ tokenUrl: https://coffeemesh-dev.eu.auth0.com/oauth/token ⑨ scopes: {} ⑩ bearerAuth: type: http scheme: bearer bearerFormat: JWT ⑪ ... security: - oauth2: - getOrders - createOrder - getOrder - updateOrder - deleteOrder - payOrder - cancelOrder - bearerAuth: - getOrders - createOrder - getOrder - updateOrder - deleteOrder - payOrder - - cancelOrder Click to expand and view more API components 部分的 securitySchemes 标头下的安全方案 为安全方案提供一个名称(可以是任何名称) 安全方案的类型 描述后端 OpenID Connect 配置的 URL 另一个安全方案的名称 该安全方案的类型 该安全方案下可用的授权流 客户端凭证流的描述 用户可以请求授权令牌的 URL 请求授权令牌时可用的作用域 Bearer 令牌的格式是 JSON Web Token (JWT) Wrapping Up JSON Schema 是一个定义 JSON 文档中属性类型和格式的规范, 它有助于以一种独立于编程语言的方式定义数据验证模型. OpenAPI 是一种用于描述 RESTful API 的标准文档格式, 它使用 JSON Schema 来描述 API 的属性. 通过使用 OpenAPI, 你可以利用围绕该标准构建的整个工具和框架生态系统, 从而使 API 集成变得更加容易. JSON pointer 允许使用 $ref 关键字来引用一个模式(schema). 利用 JSON 指针, 可以创建可重用的模式定义, 这些定义可以在 API 规范的不同部分使用, 从而保持 API 规范的整洁和易于理解. ","title":"Documenting REST APIs with OpenAPI"},{"link":"/posts/redis-list/","text":"List 列表 Redis 的列表是一种线性的有序结构, 可以按照元素被推入列表的顺序来存储元素, 这些元素即可以是文字顺序, 也可以是二进制顺序, 且元素可重复出现.\nLPUSH: 将元素推入列表左端\nPLAINTEXT Collapse Copy LPUSH list item [item item ...] Click to expand and view more LPUSH 命令会返回当前元素数量\nRPUSH: 将元素推入列表右端\nPLAINTEXT Collapse Copy RPUSH list item [item item ...] Click to expand and view more LPUSHX, RPUSHX: 只对已存在的列表执行推入操作\n上面两条命令, 在列表不存在的情况下, 会自动创建空列表, 并将元素推入列表中.\n且上面命令每次只能推入一个元素\nLPOP: 弹出列表最左端的元素, 并返回被移出的元素\nPLAINTEXT Collapse Copy POP list Click to expand and view more 空列表 POP 会返回空值 (nil)\nRPOP: 弹出列表最右端的元素\nPLAINTEXT Collapse Copy RPOP list Click to expand and view more RPOPLPUSH: 将列表右端弹出的元素推入列表左端\nPLAINTEXT Collapse Copy RPOPLPUSH source target Click to expand and view more source 和 target 可以是相同列表, 也可以是不同列表. 但不能为空列表, 否则会返回空(nil)\n示例: 先入先出队列 许多电商网站都会在节日时推出一些秒杀活动, 这些活动会放出数量有限的商品供用户抢购, 秒杀系统的一个特点就是短时间内会有大量用户进行相同的购买操作, 如果使用事务或者锁去实现秒杀程序, 那么会因为锁和事务的重试性而导致性能低下, 并且由于重试的存在, 成功购买商品的用户可能并不是最早购买操作的用户, 因此这种秒杀系统并不公平.\n解决方法之一就是把用户的购买操作都放入先进先出队列里面, 然后以队列的方式处理用户购买操作, 这样的程序就可以不使用锁或者事务实现秒杀系统, 且更加公平.\nPYTHON Collapse Copy from redis import Redis class FIFOqueue: def __init__(self, client, key): self.client = client self.key = key def enqueue(self, item): return self.client.rpush(self.key, item) def dequque(self): return self.client.lpop(self.key) client = Redis(decode_responses=True) q = FIFOqueue(client, key=\u0026#34;buy-request\u0026#34;) print(\u0026#34;Enqueue:\u0026#34;, q.enqueue(\u0026#34;peter-buy-milk\u0026#34;), \u0026#34;peter-buy-milk\u0026#34;) print(\u0026#34;Enqueue:\u0026#34;, q.enqueue(\u0026#34;john-buy-rice\u0026#34;), \u0026#34;john-buy-rice\u0026#34;) print(\u0026#34;Enqueue:\u0026#34;, q.enqueue(\u0026#34;david-buy-keyboard\u0026#34;), \u0026#34;david-buy-keyboard\u0026#34;) print(\u0026#34;Dequeue:\u0026#34;, q.dequque()) print(\u0026#34;Dequeue:\u0026#34;, q.dequque()) print(\u0026#34;Dequeeu:\u0026#34;, q.dequque()) Click to expand and view more LLEN: 获取列表长度\nPLAINTEXT Collapse Copy LLEN list Click to expand and view more LINDEX: 获取指定索引上的元素\nPLAINTEXT Collapse Copy LINDEX list index Click to expand and view more 正数索引从左端开始算, 起始为0. 负数索引从右端开始算, 起始为-1. 若索引超出范围则返回(nil).\nLRANGE: 获取给定索引范围上的元素\nPLAINTEXT Collapse Copy LRANGE list start end Click to expand and view more 可以使用 LRANGE list 0 -1 来获取列表的所有元素\n如果 start 和 end 都超出范围, 则返回空列表 nil 如果其中一个超出索引范围, 则超出范围的起始索引会被修正为0, 超出范围的结束索引会被修正为1. 示例: 分页 对于有一定规模的网站来说, 分页程序都是必不可少的; 新闻站点、博客、论坛、搜索引擎等, 都会使用分页程序将数量众多的信息分割为多个页面, 使得用户可以以页面为单位流览网站提供的信息, 并以此来控制网站每次取出的信息数量.\nPYTHON Collapse Copy from redis import Redis class Paging: def __init__(self, client, key): self.client = client self.key = key def add(self, item): self.client.rpush(self.key, item) def get_page(self, page_number, item_per_page): start_index = (page_number - 1) * item_per_page end_index = page_number * item_per_page return self.client.lrange(self.key, start_index, end_index) def size(self): return self.client.llen(self.key) client = Redis(decode_responses=True) topics = Paging(client, \u0026#34;user-topics\u0026#34;) for i in range(1, 20): topics.add(i) print(topics.get_page(1, 5)) print(topics.get_page(2, 5)) print(topics.get_page(1, 10)) print(topics.size()) Click to expand and view more LSET: 为索引设置新元素\nPLAINTEXT Collapse Copy LSET list index new_element Click to expand and view more LSET 命令在成功时返回 OK. 若索引范围错误, 返回一个错误 (error) ERR index out of range\nLINSERT: 将元素插入列表\nPLAINTEXT Collapse Copy LINSERT list BEFORE|AFTER target_element new_element Click to expand and view more 该命令第二个参数可以选用 BEFORE 或 AFTER, 用于指示命令将新元素插入目标元素的前面还是后面, 命令完成后返回列表长度.\n若用户给定的元素不存在 list 中, 则 LINSERT 命令将返回 -1 表示插入失败.\nLTRIM: 修建列表\nPLAINTEXT Collapse Copy LTRIM list start end Click to expand and view more 接受一个列表和一个索引范围, 保留范围内的元素, 删除范围外的所有元素\nLREM: 从列表移除指定元素\nPLAINTEXT Collapse Copy LREM list count element Click to expand and view more count 决定了移除元素的方式:\ncount = 0, 表示移除列表中包含的所有元素 count \u0026gt; 0, 则从左向右开始检查, 并移除最先发现的 count 个指定的元素 count \u0026lt; 0, 则从右向左开始检查, 并移除最先发现的 abs(count) 个指定的元素 示例: 代办事项 使用两个列表分别记录代办事项和已完成事项:\n当用户添加一个新的代办事项时, 程序把这个事项放入代办事项列表中 当用户完成代办事项中某个事项时, 程序把这个事项从代办列表移除, 并放入已完成事项列表中 PYTHON Collapse Copy from redis import Redis def make_todo_list_key(user_id): return user_id + \u0026#34;::todo_list\u0026#34; def make_done_list_key(user_id): return user_id + \u0026#34;::done_list\u0026#34; class TodoList: def __init__(self, client, user_id): self.client = client self.user_id = user_id self.todo_list = make_todo_list_key(self.user_id) self.done_list = make_done_list_key(self.user_id) def add(self, event): self.client.lpush(self.todo_list, event) def remove(self, event): self.client.lrem(self.todo_list, 0, event) # 移除所有元素 def done(self, event): self.remove(event) self.client.lpush(self.done_list, event) def show_todo_list(self): return self.client.lrange(self.todo_list, 0, -1) def show_done_list(self): return self.client.lrange(self.done_list, 0, -1) def clear(self): self.client.delete(make_todo_list_key(self.user_id)) self.client.delete(make_done_list_key(self.user_id)) client = Redis(decode_responses=True) todo = TodoList(client, \u0026#34;peter\u0026#39;s todo list\u0026#34;) todo.add(\u0026#34;go to sleep\u0026#34;) todo.add(\u0026#34;buy some milk\u0026#34;) print(\u0026#34;Todo list:\u0026#34;, todo.show_todo_list()) print() todo.done(\u0026#34;buy some milk\u0026#34;) print(\u0026#34;Todo list:\u0026#34;, todo.show_todo_list()) print(\u0026#34;Done list:\u0026#34;, todo.show_done_list()) todo.clear() Click to expand and view more BLPOP: 阻塞式左端弹出操作\nPLAINTEXT Collapse Copy BLPOP list [list ...] timeout Click to expand and view more BLPOP 命令是带有阻塞功能的左端弹出操作, 接受任意个列表, 以及一个秒级精度的超时时限作为参数.\n该命令会按照从左到右的顺序依次检查用户给定的列表, 并对最先遇到的非空列表执行左端元素弹出操作. 如果没有可以执行弹出操作的列表, 则会阻塞该命令, 知道某个给定列表变为非空, 又或者等待时间超出给定的时限为止.\n若成功执行弹出操作, 则返回一个包含两个元素的列表, 第一个元素记录了执行弹出操作的列表, 即元素来源列表, 第二个参数则是被弹出元素本身.\n解除阻塞状态: 如果客户端被阻塞的过程中, 有另一个客户端向导致阻塞的列表推入了新的元素, 那么该列表就会变为非空, 而被阻塞的客户端也会随着 BLOPOP 命令成功弹出列表元素而重新回到非阻塞状态. 如果在同一时间内, 有多个客户端因为同一个列表而被阻塞, 那么当导致阻塞的列表变为非空时, 服务器将按照\u0026quot;先阻塞先服务\u0026quot;的规则, 依次为被阻塞的多个客户端弹出列表元素 处理空列表: 如果向 BLPOP 命令传入列表都为空列表, 且这些列表在给定时间内都没有变成非空列表, 则会返回一个空值(nil) 列表名的作用: BLPOP 返回来源列表是为了让用户在传入多个列表的情况下, 知道被弹出的元素来源哪个列表 BRPOP: 阻塞式右端弹出操作\nPLAINTEXT Collapse Copy BRPOP list [list ...] timeout Click to expand and view more 该命令和 BLPOP 除了方向不同外, 其他都一样\nBRPOPLPUSH: 阻塞式弹出并推入操作\nPLAINTEXT Collapse Copy BRPOPLPUSH source target timeout Click to expand and view more 若 source 非空, 行为和 RPOPLPUSH 一样, 将 source 的右端弹出, 并推入 target 的左端, 返回弹出的元素\n若 source 为空, 该命令将阻塞客户端, 并等待一定的时间, 类似上面的阻塞操作\n","title":"Redis List"},{"link":"/posts/rust-alternaitve-tools/","text":"常用工具的 rust 替代品.\nIntroduction 在 Unix 生态中, 许多命令行工具都是用 C 编写的, 经过几十年的优化, 性能和稳定性都非常优秀. 然而, 近年来, Rust 以其安全性、内存管理优势和现代化开发体验, 成为系统级工具开发的理想选择.\n首先更新 cargo, 不同系统都可以使用 cargo 安装, 当然也可以使用系统的包管理器安装\nPLAINTEXT Collapse Copy rustup update stable Click to expand and view more 有需要的话修改源, 一般在 ~/.cargo/config.toml, 下面是科大源\nTOML Collapse Copy [source.crates-io] replace-with = \u0026#39;ustc\u0026#39; [source.ustc] registry = \u0026#34;sparse+https://mirrors.ustc.edu.cn/crates.io-index/\u0026#34; [registries.ustc] index = \u0026#34;sparse+https://mirrors.ustc.edu.cn/crates.io-index/\u0026#34; Click to expand and view more Filesystem \u0026amp; Archiving 文件系统与归档 exa 替代 ls: 彩色支持 Git 状态的 ls 替代品\n常用参数: -1: 一行显示一个文件 -l: 显示文件细节信息 -F: 在目录文件名末添加斜杠符号 -T: 树状显示 -R: 递归显示所有文件 --icons: 显示图标 zoxide 替代 cd: 基于访问频率的快速目录跳转工具\n常用参数: z foo # 匹配 foo 的路径 z foo bar # 匹配 foo \u0026amp; bar 的路径 z - # 回到之前目录 zi foo # fzf File \u0026amp; Text Processing 文件与文本处理 bat 替代 cat: 具备语法高亮、行号显示、Git 集成等功能, 让查看文件内容更加美观 ripgrep 替代 grep: 使用 Rust 编写的极速文本搜索工具, 支持递归搜索、正则表达式、忽略规则(.gitignore)等 fd 替代 find: 提供简单直观的语法、更快的搜索性能, 并默认支持彩色输出和忽略 .gitignore 文件 System Monitoring \u0026amp; Management 系统监控与管理 bottom 替代 top / htop: 一个现代化的系统资源监控工具, 支持 CPU、内存、磁盘、网络等多种指标显示, 并提供交互式界面 procs 替代 ps: 更人性化的进程信息显示, 支持彩色输出、树状显示、搜索与过滤 Wrapping up Rust 的安全性和高性能使其成为编写现代 Linux 工具的理想选择. 这些替代品不仅提供了更好的用户体验, 还利用 Rust 的并发优势和零成本抽象提升了性能. 其他一些 rust 工具:\nuv: python 环境管理工具 alacritty: 支持 gpu 加速的终端, 实时刷新 ","title":"Rust Alternaitve Tools"},{"link":"/posts/tokei/","text":"Tokei 介绍 Tokei是一款 Rust 编写的开源工具, 用于统计项目代码行数, 支持上百种语言, 能够扫描整个代码库, 包括:\n语言 文件数量 代码行数 注释行数 空行数 得益于 Rust 的高性能实现, Tokei 即使在超大规模代码库中也能保持极快的统计速度\n(Rust 轮子真不错)\n安装 PLAINTEXT Collapse Copy brew install tokei Click to expand and view more 或者\nPLAINTEXT Collapse Copy cargo install tokei Click to expand and view more 使用 在项目根目录执行\nPLAINTEXT Collapse Copy tokei . Click to expand and view more 输出类似下面这样\nPLAINTEXT Collapse Copy =============================================================================== Language Files Lines Code Comments Blanks =============================================================================== Dockerfile 1 25 9 8 8 Python 52 2914 2372 96 446 TOML 1 65 58 0 7 YAML 2 49 45 0 4 ------------------------------------------------------------------------------- Markdown 1 194 0 158 36 |- BASH 1 13 13 0 0 (Total) 207 13 158 36 =============================================================================== Total 57 3247 2484 262 501 =============================================================================== Click to expand and view more ","title":"Tokei"},{"link":"/posts/redis-hash/","text":"散列 Redis 散列键 hash key 会将一个键和一个散列在数据库里关联起来, 散列中可以存任意多个字段 field. 与字符串一样, 散列字段和值既可以是文本数据, 也可以是二进制数据.\nHSET: 为字段设置值\nPLAINTEXT Collapse Copy HEST hash field value Click to expand and view more 若已给定的字段是否已经存在与散列中, 该设置为一次更新操作, 覆盖旧值后返回0.\n相反, 则为一次创建操作, 命令将在散列里面关联起给定的字段和值, 然后返回1.\nHSETNX: 只在字段不存在的情况下设置值\nPLAINTEXT Collapse Copy HSETNX hash field value Click to expand and view more HSETNX 命令在字段不存在且成功设置值时, 返回1.\n字段已存在并设置值未成功时, 返回0.\nHGET: 获取字段的值\nPLAINTEXT Collapse Copy HGET hash field Click to expand and view more 若查找的不存在的散列或字段, 则会返回空(nil)\n示例: 短网址生成 为了给用户提供更多空间, 并记录用户在网站上的链接点击行为, 大部分社交网站都会将用户输入的网址转换为短网址. 当用户点击段网址时, 后台就会进行数据统计, 并引导用户跳转到原地址.\n创建短网址本质上就是, 要创建出短网址ID与目标网址之间的映射, 并让用户访问短网址时, 根据短网址的ID映射记录中找出与之相对应的目标网址.\n短网址 ID 目标网址 RqRRz8n http://redisdoc.com/geo/index.html RUwtQBx http://item.jd.com/117910607.html HINCRBY: 对字段存储的整数值执行加法或减法操作\nPLAINTEXT Collapse Copy HINCRBY hash field increment Click to expand and view more 与字符串 INCRBY 命令一样, 如果散列字段里面存储着能够被 Redis 解释为整数的数字, 那么用户就可以使用 HINCRBY 命令为该字段的值加上指定的整数增量.\n该命令执行成功后, 将返回字段当前的值为命令的结果. 若要执行减法操作, increment 传入负数即可.\nHINCRBYFLOAT: 对字段存储的数字执行浮点数加法或减法操作\nPLAINTEXT Collapse Copy HINCRBYFLOAT hash field increment Click to expand and view more HINCRBYFLOAT 不仅可以使用整数作为增量, 还可以使用浮点数作为增量. 该命令执行成功后, 返回给定字段的当前值作为结果.\n此外, 不仅存储浮点数的字段可以使用该命令, 整数字段也可以使用该命令; 若计算结果可以表示为整数, 则会使用整数表示.\nHSTRLEN: 获取字段的字节长度\nPLAINTEXT Collapse Copy HSTRLEN hash field Click to expand and view more 如果给定的字段或散列不存在, 将返回0\nHEXISTS: 检查字段是否存在\nPLAINTEXT Collapse Copy HEXISTS hash field Click to expand and view more 如果存在, 返回1, 否则返回0\nHDEL: 删除字段\nPLAINTEXT Collapse Copy HDEL hash field Click to expand and view more HLEN: 获取散列包含的字段数量\nPLAINTEXT Collapse Copy HLEN hash Click to expand and view more 若不存在返回0\nHMSET: 一次为多个字段设置值\nPLAINTEXT Collapse Copy HMSET hash field value [field value ...] Click to expand and view more 该命令成功时返回 OK, 可使用新值覆盖旧值\nHMGET: 一次获取多个字段值\nPLAINTEXT Collapse Copy HMGET hash field [field ...] Click to expand and view more 对于不存在的值, 返回 (nil)\nHKEYS, HVALS, HGETALL: 获取所有字段, 所有值, 所有字段和值\nPLAINTEXT Collapse Copy HEKYS hash HVALS hash HGETALL hash Click to expand and view more 其中, HGETALL 命令返回的结果列表中, 没两个连续的元素代表散列中的一对字段和值, 奇数位置为字段, 偶数位置为字段值.\n若散列不存在, 则返回控列表(empty array)\nRedis 散列底层为无序存储的, 因此HKEYS, HVALS 和 HGETALL 可能会得到不同的结果, 因此不应该对其返回元素顺序做任何假设.\n示例: 存储图数据 图是一直常用的数据结构, 这里使用 field=edge, value=weight 的表示法来存储图结构, 其中 edge 由 start-\u0026gt;edge 构成\nPYTHON Collapse Copy from redis import Redis def make_edge_from_vertexs(start, end): return str(start) + \u0026#34;-\u0026gt;\u0026#34; + str(end) def decompose_vertexs_from_edge_name(name): return name.split(\u0026#34;-\u0026gt;\u0026#34;) class Graph: def __init__(self, client, key): self.client = client self.key = key def add_edge(self, start, end, weight): edge = make_edge_from_vertexs(start, end) self.client.hset(self.key, edge, weight) def remove_edge(self, start, end): edge = make_edge_from_vertexs(start, end) return self.client.hdel(self.key, edge) def get_edge_weight(self, start, end): edge = make_edge_from_vertexs(start, end) return self.client.hget(self.key, edge) def has_edge(self, start, end): edge = make_edge_from_vertexs(start, end) return self.client.hexists(self.key, edge) def add_multi_edges(self, *tuples): nodes_and_weights = {} for start, end, weight in tuples: edge = make_edge_from_vertexs(start, end) nodes_and_weights[edge] = weight self.client.hset(self.key, mapping=nodes_and_weights) # hmset 在 4.0 已抛弃, 使用 .hset(mapping={...}) def get_multi_edge_weights(self, *tuples): edge_list = [] for start, end in tuples: edge = make_edge_from_vertexs(start, end) edge_list.append(edge) return self.client.hmget(self.key, edge_list) def get_all_edges(self): edges = self.client.hkeys(self.key) result = set() for edge in edges: start, end = decompose_vertexs_from_edge_name(edge) result.add((start, end)) return result def get_all_edges_with_weight(self): edges_and_weights = self.client.hgetall(self.key) result = set() for edge, weight in edges_and_weights.items(): start, end = decompose_vertexs_from_edge_name(edge) result.add((start, end, weight)) return result client = Redis(decode_responses=True) graph = Graph(client, \u0026#34;test-graph\u0026#34;) graph.add_edge(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, 30) graph.add_edge(\u0026#34;c\u0026#34;, \u0026#34;b\u0026#34;, 25) graph.add_multi_edges((\u0026#34;b\u0026#34;, \u0026#34;d\u0026#34;, 70), (\u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;, 10)) print(\u0026#34;edge a-\u0026gt; b weight:\u0026#34;, graph.get_edge_weight(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;)) print(\u0026#34;a-\u0026gt;b 是否存在:\u0026#34;, graph.has_edge(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;)) print(\u0026#34;b-\u0026gt;a 是否存在:\u0026#34;, graph.has_edge(\u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;)) print(\u0026#34;所有边:\u0026#34;, graph.get_all_edges()) print(\u0026#34;所有边和权重\u0026#34;, graph.get_all_edges_with_weight()) Click to expand and view more 这里的图数据结构提供了边和权重的功能, 可以快速检查边是否存在, 能够方便的添加和移除边, 适合存储结点较多但是边较少的稀疏图(sparse graph).\n示例: 使用散列键重新实现文章存储程序 PYTHON Collapse Copy from redis import Redis from time import time class Article: def __init__(self, client, article_id): self.client = client self.article_id = str(article_id) self.article_hash = \u0026#34;article::\u0026#34; + self.article_hash def is_exists(self): return self.client.hexists(self.article_hash) def create(self, title, content, author): if self.is_exists(): return False article_data = { \u0026#34;title\u0026#34;: title, \u0026#34;content\u0026#34;: content, \u0026#34;author\u0026#34;: author, \u0026#34;created_at\u0026#34;: time(), } return self.client.hset(self.article_hash, mapping=article_data) def get(self): article_data = self.client.hgetall(self.article_hash) article_data[\u0026#34;id\u0026#34;] = self.article_id # 添加 id 到文章数据, 方便用户操作 return article_data def update(self, title=None, content=None, author=None): if not self.is_exists(): return False article_data = {} if title is not None: article_data[\u0026#34;title\u0026#34;] = title if content is not None: article_data[\u0026#34;content\u0026#34;] = content if author is not None: article_data[\u0026#34;author\u0026#34;] = author return self.client.hset(self.article_hash, mapping=article_data) client = Redis(decode_responses=True) article = Article(client, 10086) article.create(\u0026#34;greeting\u0026#34;, \u0026#34;hello world\u0026#34;, \u0026#34;peter\u0026#34;) Click to expand and view more 字符串有 MSET, MSETNX 命令, 但是并没有为散列提供 HMSET, HMSETNX 命令, 所以创建文章之前要先通过 is_exists() 方法检查文章是否存在, 再考虑是否使用 HMSET 命令进行设置. 在使用散列存储文章数据的时候, 为了避免数据库中出现键名冲突, 需要为每个属性设置一个独一无二的键, 例如 article::10086::title 键存储 id 为10086 文章的标题. Wrapping Up string 和 hash 总结与对比\n资源占用: 字符串键在数量较多的时候, 将占用大量内存和CPU时间. 相反, 将多个数据项存储到一个散列中可以有效减少内存和CPU消耗 支持的操作: 散列键支持的所有命令, 字符串键几乎都支持, 但字符串的 SETRANGE, GETRANGE 等操作散列不支持 过期时间: 字符串键可以为每个键单独设置过期时间, 独立删除某个数据项, 而散列一但到期, 其所包含的所有字段和值都会被删除 ","title":"Redis Hash"},{"link":"/posts/http-methods-status-codes-and-payloads/","text":"本篇文章基于 REST api 介绍HTTP请求方法、HTTP响应码和API数据载荷, 是之前介绍 REST 那篇文章的延伸\nHTTP Status Codes 1xx group: Signals that an operation is in progress 2xx group: Signals that a request was successfully processed 3xx group: Signals that a resource has been moved to a new location 4xx group: Signals that someting was wrong with the request 5xx group: Signals that there was an error while processing the request 在之前文章中, 定义的 HTTP status code 如下:\nPOST /orders: 201 (Created) - 资源成功创建 GET /orders: 200 (OK) - 请求成功处理 GET /orders/{order_id}: 200 (OK) - 请求成功处理 PUT /orders/{order_id}: 200 (OK) - 资源成功更新 DELETE /orders/{order_id}: 204 (No Content) - 请求被成功处理, 但是没有响应内容, 对比其他方法, DELETE 请求不需要 payload 来删除资源 POST /orders/{order_id}/chanel: 200 (OK) - 取消成功, 由于并不创建任何资源, 故返回200 POST /orders/{orders\\id}/pay: 200 (OK) - 支付成功, 同样由于未创建资源, 返回200 上面全是成功的响应, 下面介绍错误响应\n由于用户传入畸形的数据(malformed payload)或者请求一个不存在的 endpoint, 返回4xx响应码 服务器内部产生的错误, 这类错误使用5xx响应码 Client errors in the request 这里将 malformed payload 分为两类:\npayload with invalid syntax: 服务器无法解析或理解的数据, 例如json格式不对, 少了个反括号\u0026quot;}\u0026ldquo;之类的 unprocessable entities: 指却少要求属性的数据. 例如json里面要求name属性, 但是payload没有传这个属性; 又比如传入了一个不存在的资源, 这时返回一个404, 表示找不到相关资源 还有一种常见错误是, 发送了一个不支持的 HTTP 请求, 有两种 status code:\n可以返回一个 501 (Not Implemented) 表示该方法目前还未支持, 但是未来会添加的功能 如果未来也不打算实现该方法, 则可以返回一个 405 (Method Not Allowed) 关于 身份验证(authentication) 和 授权(authorization) 相关的请求错误有以下两个:\n对于未验证的请求, 返回 401 Unauthorized 对于已验证, 但是未授权的访问, 返回 403 Forbidden Server errors in the report 第2种错误是由于服务器代码 bug 或者基础设施限制导致的, 这时返回一个 500 (Internal Server Error)\n另一种相关的错误是, 程序无法处理请求的问题, 通常使用 proxy server 或者 API gateway 来解决这个问题. 由于服务器过载或者下线维护的时候, 我们需要将当前情况告知用户.\n当服务器无法处理新请求的时候, 必须返回 503 (Service Unavailable) 状态码, 表明服务器过载或者下线维护 当服务消耗太长时间返回响应, 应返回一个 504 (Gateway Timeout) 状态码 Designing API Payloads 这部分介绍设计用户友好的 HTTP request / response payloads 的最佳实践.\npayloads 是指 client 和 server 之间传输的数据部分. API 的可用性往往依赖好的 payload 设计, 糟糕的设计会使得 API 的用户使用体验变差.\n一个 HTTP request 包含了 URL, HTTP method 和 一系列的 headers 以及一个可选的 body(payload). HTTP headers 包含了请求的元数据, 例如 encoding format.\n类似的, HTTP response 包含一个 status code, 一协力的 headers 以及一个可选的 payload.\n可以使用不同的序列化方法来表示 payloads, 例如 XML 和 JSON. 在 REST APIs, 数据通常使用 JSON document.\nHTTP 请求规范在 DELETE 和 GET 请求是否可以包含 payload 这一点上故意保持模糊, 其并未禁止使用 payload. 这使得一些 API 可以在 GET 请求中包含负载, 一个著名的例子是 Elasticsearch, 它允许客户端在 GET 请求的请求体中发送查询文档.\n对于 HTTP Response 而言, 根据 status code 的不同, 可能会包含 payload. 根据 HTTP 规范(specification), 1xx, 204(No Content) 和 304(Not Modified) 这些状态码不能包含payload, 而其他的 response 都有.\n在 REST APIs 中, 最重要的就是 4xx 和 5xx 的错误响应, 以及 2xx 的成功响应和204的异常.\nHTTP payload designing patterns 错误的响应应该包含\u0026quot;error\u0026quot;关键字, 以及具体的细节信息, 并解释错误原因.\n例如, 一个 404 Response 返回的信息应该包含下面这些\nJSON Collapse Copy { \u0026#34;error\u0026#34;: \u0026#34;Resource not found\u0026#34; } Click to expand and view more error 是比较常用的关键字, 当然你也可以使用 \u0026ldquo;detail\u0026rdquo; 和 \u0026ldquo;message\u0026rdquo; 这类关键字. 大多数的 Web 框架都有默认的错误模板, 例如 FastAPI 使用\u0026quot;detail\u0026rdquo;.\n对于成功响应的 HTTP Response 而言, 区分为3种类型: 创建资源, 更新资源 和 获取资源.\nResponse Payloads for POST requests\n使用 POST 请求来创建资源. 在 CoffeeMesh 的订单 API 中, 通过 POST /orders 端点来下单. 为了创建一个订单, 需要将购买的商品列表发送给服务器, 服务器负责为该订单分配唯一的 ID, 因此订单的 ID 必须包含在响应数据中返回. 服务器还会设置订单创建的时间以及初始状态. 这里将由服务器设置的属性称为 sever sever-side 或 read-only, 这些属性也必须包含在响应数据中. 最佳实践返回的响应是对 POST 方法的全面表示, 这个 payload 用于验证资源是否被正确创建.\nResponse payloads for PUT and PATCH requests\n要更新资源, 这里使用一个 PUT 或者 PATCH 请求. 对单个资源发送 PUT / PATCH 请求, 例如 CoffeeMesh 订单 API 中的 PUT /orders{order_id} 端点. 在这种情况下, 返回资源的完整表示也是一种良好实践, 客户端可以利用它验证更新是否已被正确处理.\nResponse payloads for GET requests\n使用 GET 方法检索资源. 例如, 在 CoffeeMesh 里面的订单 AIP 一样, 有两个 GET endpoints: GET /orders 和 GET /orders/{orders_id}.\nGET /orders 返回一个列表, 有两种设计策略:\n包含每个订单的完整信息或者包含每个订单的部分信息. 第一种方法在比较大的响应体中, 往往会导致 API 性能下降.第二种方法是包含所有订单的部分信息, 这种实践比较常见, 例如只返回每个订单的 ID 信息, 客户端需要使用 GET /orders/{orders_id} 来获取每个订单的具体信息.一般倾向于返回完整的信息, 尤其是公开发布的 APIs. 然而，如果是在开发一个内部的 API, 并且不需要详细的信息. 那么可以只提供客户端需要的信息. 更小的 payloads 处理起来更快, 能带来更好的用户体验. 但是对于单例 endpoint(GET /orders/{orders_id})应该总是返回完整的信息.\nDesigning URL query parameters 一些 API 接口会返回一个资源列表, 当一个接口返回资源列表时, 最佳实践是允许用户对结果进行筛选和分页. 例如 GET /orders 接口, 可能希望结果为最近的5个订单, 或者只列出已取消的订单. URL 查询参数能让我们实现这些目标, 他应当始终是可选的, 并且在适当的情况下, 服务器可以为其分配默认值.\n定义: URL 查询参数是 URL 中的键值对参数. 查询参数位于问号(?)自后, 通常用于筛选接口的返回结果. 可以用与号(\u0026amp;)来分隔组合多个查询参数.\n调用 GET /orders 接口并按\u0026quot;已取消\u0026quot;来筛选订单结果, 可以这样写\nPLAINTEXT Collapse Copy GET /orders?cancelled=true Click to expand and view more 链接多个参数 向 GET /orders 端点添加一个名为 limit 的查询参数以限制返回结果的数量. 如果要筛选\u0026quot;已取消\u0026quot;订单并将返回结果限制为 5 条, 可以这样请求 API\nPLAINTEXT Collapse Copy GET /orders?cancelled=true\u0026amp;limit=5 Click to expand and view more 分页 允许 API 客户端对结果进行分页也是一种常见的做法. 分页(Pagination)是指将结果切分成不同的集和, 并一次提供一个集和. 可以使用多种策略进行分页, 最常见的方法是使用 page 和 per_page 则两个参数的组合. page 代表数据的某个集和(页码), 而 per_page 则告诉每个集和中想要包含多少个项目. 服务器根据 per_page 的指来确定每一页返回多少条数据.\n在 API 中组合这两个参数, 如下所示:\nPLAINTEXT Collapse Copy GET /orders?page=1\u0026amp;per_page=10 Click to expand and view more ","title":"HTTP Methods, Status Codes and Payloads"},{"link":"/posts/redis-string/","text":"介绍Redis中的字符串键\n字符串 字符串建是 Redis 最基本的键值对类型, 这种类型的键值对会在数据库中把单独的一个值关联起来, 被关联的键和值可以为文本, 也可以是图片, 视屏, 音频等二进制数据.\nSET: 为字符串键设置值 O(1) SET key value\n```Redis SET number \u0026quot;10086\u0026quot; \u0026gt; OK SET book \u0026quot;Redis in action\u0026quot; \u0026gt; OK ``` 对于已经存在的 key, 再次赋值会覆盖原值, 若不想覆盖后面添加参数 NX, 相反, 默认 XX 允许覆盖 ```Redis SET key \u0026quot;10086\u0026quot; NX \u0026gt; (nil) SET key \u0026quot;10086\u0026quot; XX \u0026gt; OK ``` GET: 获取字符串键的值 O(1) GET key\n```Redis GET number \u0026gt; \u0026quot;10086\u0026quot; ``` 对于不存在的值, 返回空 ```Redis GET key_new \u0026gt; (nil) ``` GETSET: 获取旧值并更新值 O(1) GETSET key new_value\n```Redis GETSET key \u0026quot;123456\u0026quot; \u0026gt; \u0026quot;10086\u0026quot; ``` 示例: 缓存 对数据进行缓存是Redis最常见的用法之一, 将数据存储在内存比存储在硬盘要快得多 首先定义缓存\nPYTHON Collapse Copy class Cache: def __init__(self, client): self.client = client def set(self, key, value): self.client.set(key, value) def get(self, key): return self.client.get(key) def update(self, new_value, key): return self.client.getset(key, new_value) # 设置新值, 返回旧值 Click to expand and view more 然后缓存文本数据\nPYTHON Collapse Copy client = Redis(decode_responses=True) # 使用文本编码方式打开客户端 cache = Cache(client) cache.set(\u0026#34;web_page\u0026#34;, \u0026#34;\u0026lt;html\u0026gt;\u0026lt;p\u0026gt;hello world\u0026lt;/p\u0026gt;\u0026lt;/html\u0026gt;\u0026#34;) print(cache.get(\u0026#34;web_page\u0026#34;)) print(cache.update(\u0026#34;web_page\u0026#34;, \u0026#34;\u0026lt;html\u0026gt;\u0026lt;p\u0026gt;update\u0026lt;p\u0026gt;\u0026lt;/html\u0026gt;\u0026#34;)) print(cache.get(\u0026#34;web_page\u0026#34;)) Click to expand and view more 下面是存储一个二进制图片的缓存示例\nPYTHON Collapse Copy client = Redis() # 二进制编码打开客户端 cache = Cache(client) image = open(\u0026#34;DailyBing.jpg\u0026#34;, \u0026#34;rb\u0026#34;) # 二进制只读方式打开图片 data = image.read() # 读取文件内容 image.close() # 关闭文件 cache.set(\u0026#34;daily_bing.jpg\u0026#34;, data) # 将二进制图片缓存到键 daily_bing.jpg 中 print(cache.get(\u0026#34;daily_bing.jpg\u0026#34;)[:20]) # 读取二进制数据的前20字节 Click to expand and view more b\u0026rsquo;\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00'\n示例: 锁 锁是一种同步机制, 用于保证一种资源任何时候只能被一个进程使用. 一个锁的实现通常有获取 (acquire) 和释放 (relase) 这两种操作.\n获取操作用于获取资源的独占使用权, 任何时候只能有一个进程取得锁, 此时, 取得锁的进程称为锁的持有者. 释放操作用于放弃资源的独占使用权, 一般由持有者调用. PYTHON Collapse Copy from redis import Redis VALUE_OF_LOCK = \u0026#34;locking\u0026#34; class Lock: def __init__(self, client, key): self.client = client self.key = key def acquire(self): result = self.client.set(self.key, VALUE_OF_LOCK, nx=True) return result is True def relase(self): return self.client.delete(self.key) == 1 client = Redis(decode_responses=True) lock = Lock(client, \u0026#39;test-lock\u0026#39;) print(\u0026#34;第一次获取锁:\u0026#34;, lock.acquire()) print(\u0026#34;第二次获得锁:\u0026#34;, lock.acquire()) print(\u0026#34;取消锁:\u0026#34;, lock.relase()) print(\u0026#34;第三次获得锁:\u0026#34;, lock.acquire()) Click to expand and view more 第一次获取锁: True 第二次获得锁: False 取消锁: True 第三次获得锁: True\n若要设置锁的时间 SET key value NX EX time 这样是原子性语法, 删除操作对应命令是 DEL key, 返回0表示 key 不存在, 返回1~N表示删除key的数量.\nNX 确保锁只有在没有值时加锁成功, 若有值则返回 None, 通过检查 result 是否为 True 来判断是否获得了锁.\nMSET: 一次为多个字符串键设置值 O(N) MSET key value [key value \u0026hellip;]\n同 SET 命令, MSET 执行成功后返回 OK, 并且会用新值覆盖旧值. 由于执行多条 SET 命令要客户端和服务端之间多次进行网络通讯, 因此 MSET 能减少程序执行操作的时间\nMGET: 一次获取多个字符串键的值 O(N) MGET key [key \u0026hellip;]\nMSETNX: 只在键不存在的情况下, 一次为多个键设置值 MSETNX key value [key value \u0026hellip;]\n若有任意一次键存在值, 则会取消所有操作, 并返回0. 只有所有键都没有值的时候, 执行才成功, 返回1.\n示例: 存储文章信息 在构建应用程序的时候, 经常会需要批量设计和获取多项信息, 以博客为例:\n当用户注册博客时, 程序将用户名字、帐号、密码、注册时间等存储起来, 并在登陆时查取这些信息. 当编写一篇博客文章时, 就要将博客标题、内容、作者、发表时间存储起来, 并在用户阅读的时候取出这些信息. 通过 MSET、MSETNX、MGET 命令, 可以实现上面提到的这些批量设置和批量获取操作\nPYTHON Collapse Copy from redis import Redis from datetime import datetime class Article: def __init__(self, client, article_id): \u0026#34;\u0026#34;\u0026#34;根据id创建文章id\u0026#34;\u0026#34;\u0026#34; self.client = client self.id = str(article_id) self.title_key = \u0026#34;article::\u0026#34; + self.id + \u0026#34;::title\u0026#34; self.content_key = \u0026#34;article::\u0026#34; + self.id + \u0026#34;::content\u0026#34; self.author_key = \u0026#34;article::\u0026#34; + self.id + \u0026#34;author\u0026#34; self.create_at_key = \u0026#34;article::\u0026#34; + self.id + datetime.now() def create(self, title, content, author): \u0026#34;\u0026#34;\u0026#34;创建文章\u0026#34;\u0026#34;\u0026#34; article_data = { self.title_key: title, self.content_key: content, self.author_key: author, self.create_at_key: datetime.now(), } return self.client.msetnx(article_data) def get(self): \u0026#34;\u0026#34;\u0026#34;获取文章信息\u0026#34;\u0026#34;\u0026#34; result = self.client.mget( self.title_key, self.content_key, self.author_key, self.create_at_key, ) return { \u0026#34;id\u0026#34;: self.id, \u0026#34;title\u0026#34;: result[0], \u0026#34;content\u0026#34;: result[1], \u0026#34;author\u0026#34;: result[2], \u0026#34;create_at_key\u0026#34;: result[3], } def update(self, title=None, content=None, author=None): \u0026#34;\u0026#34;\u0026#34;更新文章\u0026#34;\u0026#34;\u0026#34; article_data = {} if title is not None: article_data[self.title_key] = title if content is not None: article_data[self.content_key] = content if author is not None: article_data[self.author_key] = author return self.client.mset(article_data) client = Redis(decode_responses=True) article = Article(client, 10086) # 创建文章 print(article.create(\u0026#34;message\u0026#34;, \u0026#34;hello world\u0026#34;, \u0026#34;sx\u0026#34;)) # 获取文章信息 print(article.get()) # 更新文章作者 print(article.update(author=\u0026#34;join\u0026#34;)) Click to expand and view more 上面程序使用了多个字符串键存储文章信息: article::\u0026lt;id\u0026gt;::\u0026lt;attribute\u0026gt;\nSTRLEN: 获取字符串的字节长度 O(1) STRLEN key\n对于存在的键, 返回字节长度信息. 对于不存在的键, 返回0\nGETRANGE: 获取字符串值指定索引范围上的内容 O(N) GETRANGE key start end\nREDIS Collapse Copy SET message \u0026#34;hello world\u0026#34; GETRANG message 0 4 \u0026gt; hello GETRANGE message -5 -1 \u0026gt; world Click to expand and view more SETRANGE: 修改字符串索引范围的值 O(N) SETRANGE key index subsitute\nREDIS Collapse Copy set message \u0026#34;hello world\u0026#34; SETRANGE message 6 Redis \u0026gt; (integer) 11 GET message \u0026gt; hello Redis Click to expand and view more 当用户给定的新内容比被替换内容长的时候, SETRANGE 会自动扩展被修改的字符串值\nREDIS Collapse Copy SETRANGE message 5 \u0026#34;, this is a message\u0026#34; \u0026gt; (integer) 24 GET message \u0026gt; \u0026#34;hello, this is a message\u0026#34; Click to expand and view more 当用户给出的索引长度超出被替换字符长度时, 字符串末尾到 index-1 之间部分将使用空字符串填充为0\nREDIS Collapse Copy SET greeting \u0026#34;hello\u0026#34; SETRANGE greeting 10 \u0026#34;hello\u0026#34; \u0026gt; (integer) 15 GET greeting \u0026gt; \u0026#34;hello\\x00\\x00\\x00\\x00\\x00world\u0026#34; Click to expand and view more 示例: 给文章存储程序加上文章长度计数功能和文章御览功能给 文章长度计数功能: 显示文章长度, 用于估计阅读时长 文章预览功能: 显示文章开头一部分内容, 帮助读者快速了解文章 PYTHON Collapse Copy class Article: ... def get_content_len(self): return self.client.strlen(self.content_key) def get_content_perview(self, preview_len): start_index = 0 end_index = preview_len - 1 return self.client.getrange(self.content, start_index, end_index) Click to expand and view more APPEND: 追加新内容到值的末尾 APPEND key suffix\n若用户给定的 key 不存在, 则相当于 SET key suffix\n示例: 存储日志 很多程序运行的时候会产生日志, 日志记录了程序的运行状态以及执行过的重要操作. 若每条日志存储一个键值对, 则会消耗很多资源, 且分散在数据库中, 需要额外的时间查找日志, 这里将不同日志拼接在同一个值里面.\nPYTHON Collapse Copy from redis import Redis LOG_SEPERATOR = \u0026#34;\\n\u0026#34; class Log: def __init__(self, client, key): self.client = client self.key = key def add(self, new_log): new_log += LOG_SEPERATOR self.client.append(self.key, new_log) def get_all(self): all_logs = self.client.get(self.key) if all_logs is not None: log_list = all_logs.split(LOG_SEPERATOR) log_list.remove(\u0026#34;\u0026#34;) # 删除默认多余的空字符串 return log_list else: return [] Click to expand and view more 数字值 下面介绍使用字符串键存储数字值:\n每当存储一个值到字符串键里面的时候, 有下面两种情况\nC 语言 long long int 类型的整数, 取值范围为 -2^63 ~ 2^63-1 (超出范围会被当成字符串) C 语言 long double 类型的浮点数 为了方便地处理字符串键的值, Redis 提供了一系列加法和减法操作命令, 下面介绍这些命令\nINCRBY, DECRBY: 对整数执行加法和减法操作 O(1) INCRBY key increment DECRBY key increment\n如果类型为浮点数, 使用上面方法会报错 (key的值 和 increment 都必须为整数) 当该命令遇到**不存在的键**时, 会将键的值初始化为0, 然后再执行操作 INCR, DECR: 对整数执行加1和减1操作 O(1) INCR key DECR key\nINCRBYFLOAT: 对数字值执行浮点数加减法操作 INCRBYFLOAT key increment\nINCRBYFLOAT 命令即执行加法操作, 也可以执行加法操作, 并且操作对象和 increment 都既可以为整数也可以为浮点数 虽然 Redis 没有限制字符串键存储浮点数的小数位数, 但是 INCRBYFLOAT 最多只会保留小数点后的17位数字, 超出部分将被截断 示例: ID 生成器 identifier 标识符, 经常在程序中使用, 通常以数字形式出现, 并通过递增的方法创建新的ID.\nPYTHON Collapse Copy from redis import Redis class IdGenerator: def __init__(self, client, key): self.client = client self.key = key def produce(self): \u0026#34;\u0026#34;\u0026#34;生成下一个id\u0026#34;\u0026#34;\u0026#34; return self.client.incr(self.key) def reserve(self, n): \u0026#34;\u0026#34;\u0026#34;初始化\u0026#34;\u0026#34;\u0026#34; result = self.client.set(self.key, n, nx=1) # key 不存在才行 return result is True client = Redis(decode_responses=True) id_generator = IdGenerator(client, \u0026#34;user::id\u0026#34;) print(id_generator.reserve(1000000)) # 保留100万个ID -\u0026gt; True print(id_generator.produce()) # 生成ID, 均大于100万 print(id_generator.reserve(1000)) # 已存在 -\u0026gt; False Click to expand and view more 示例: 计数器 除了ID生成器, 计数器也是常用的组件之一, 例如点赞回复数量, 播放量等.\nPYTHON Collapse Copy from redis import Redis class Counter: def __init__(self, client, key): self.client = client self.key = key def increase(self, n=1): return self.client.incr(self.key, n) def decrease(self, n=1): return self.client.decr(self.key, n) def get(self): value = self.client.get(self.key) if value in None: return 0 else: return int(value) def reset(self): old_value = self.client.getset(self.key) if old_value is None: return 0 else: return(old_value) client = Redis(decode_responses=True) counter = Counter(client, \u0026#34;counter::page_viewed\u0026#34;) print(counter.increase()) # +1 print(counter.increase()) print(counter.increase(10)) # +10 print(counter.decrease()) # -1 print(counter.decrease(5)) # -5 print(counter.reset()) # 重置计数器 print(counter.get()) # 返回计数器当前值 Click to expand and view more 注: 在 redis-py 中 INCR 和 INCRBY 都使用 .incr() 方法\n示例: 限速器 为了保障系统的安全性和性能, 并保证重要资源不被滥用, 应用程序需要对用户的行为进行限制\n防止网络爬虫: 限制每个IP地址在固定时间段内访问的页面数量 防止爆力破解: 当用户多次输入错误的密码, 会帐号进行冻结 上面机制的实现可以使用限速器, 下面是一个限速器示例代码, 该程序将操作最大可执行次数存储在一个字符串里面, 每次用户进行该操作后就将其减1\nPYTHON Collapse Copy from redis import Redis class Limter: def __init__(self, client, key): self.client = client self.key = key def set_max_execute_times(self, max_execut_time): self.client.set(self.key, max_execut_time) def still_valid_to_execute(self): num = self.client.decr(self.key) return (num \u0026gt;= 0) def remaining_execute_times(self): num = int(self.client.get(self.key)) if num \u0026lt; 0: return 0 else: return num client = Redis(decode_responses=True) limter = Limter(client, \u0026#34;wrong_password_limter\u0026#34;) print(limter.set_max_execute_times(5)) # 最多5次输入错误密码 print(limter.still_valid_to_execute()) # 前5次 True, 之后 False Click to expand and view more ","title":"Redis String"},{"link":"/posts/ieee-754-introduce/","text":"IEEE 754 标准数值类型及分类\n整数 Integer 整数是没有小数部分的值, 在计算机内通常有两种表示方式:\n有符号整数: 可以表示正数和负数, 最常用的是二补码表示. 例如 8 位二进制的范围为[-2^7, 2^7-1] 无符号整数: 仅表示非负数, 8 位二进制的范围为 [0, 2^8-1] 其中补码(Two\u0026rsquo;s Complement)用于表示负数\n正数补码与原码相同 负数的补码 = 该数绝对值的二进制取反 + 1 通过补码, 可以使得加减运算统一, 溢出检测更加简单\n浮点数 Floating-point 浮点数用于表示带小数的实数, 尤其适合科学计算和近似表示很大或很小的数值. IEEE 754 定义了浮点数的标准格式, 类似科学计数法:\nPLAINTEXT Collapse Copy value = (-1)^(sign) x mantissa x 2^(exponent) Click to expand and view more 浮点数由三部分组成:\n符号位 sign: 0/1代表正负 阶码 exponent: 通常使用偏移表示法 尾数 fraction/mantissa: 小数部分 常见浮点数类型:\n单精度 float32: 1 位符号 + 8 位阶码 + 23 位尾数 双精度 float64: 1 位符号 + 11 位阶码 + 52 位尾数 浮点数的分类 Categories 以 64 精度为例\n部分 位数 描述 符号位（sign） 1 0 表示正数，1 表示负数 阶码（exponent） 11 偏移量（bias）为 1023，表示数值的量级 尾数（fraction / mantissa） 52 有效数字，不包括隐藏位 浮点数的表示公式:\nPLAINTEXT Collapse Copy value = (-1)^sign x (1 + fraction) x 2^(exponent - bias) Click to expand and view more 正常数 Normalized numbers\n阶码 exponent: 不全为0, 也不全为1, [1, 2^11-2] 尾数 fraction: 隐含1, [0, 1 - 2^-52], (52位全1 位 1 - 2^-52) PLAINTEXT Collapse Copy value = (-1)^sign x (1 + fraction) x 2^(exponent - 1023) Click to expand and view more 其中, bias = 2^(exponent - 1) - 1, 这里为 1023\n最大正常数: 阶码最大为 1024*2-2 = 2046, 尾数全为1 1-2^-52, 即 ( 1 + (1 - 2^-52) ) x 2^(2026-1023) 最小正常数: 阶码最小位 1, 尾数全为0, 即 ( 1 + 0 ) x 2^(1-1023) 非正规数 Subnormal numbers / Denormalized numbers\n阶码 exponent: 全0 尾数 fraction: [0, 1-2^-52], 没有隐藏位1 PLAINTEXT Collapse Copy value = (-1)^sign x (fraction) x 2^(1 - bias) Click to expand and view more 非正规数指数紧接最小正常数, 使非正规数数值连续接近零\n注意: 非正规数的指数并不是阶码减 bias 的直接结果(0−1023 = −1023), 而是约定使用最小正常数指数 E_min = −1022. 这样可以让非正规数顺接正常数, 形成连续的可表示范围, 并支持渐进下溢.\n最大非正规数: 阶码为0, 尾数全为1, 即 ( 1 - 2^-52 ) x 2^(-1022) 最小非正规数: 阶码位0, 尾数最低位为1, 其他为0, 即 ( 2^-52 x 2^(-1022) ) 零 0\n符号 sign: 0/1 正负零 阶码 exponent: 0 尾数 fraction: 0 无穷 infinity\n符号sign: 0/1 正负无穷 阶码 exponent: 2047 (全1) 尾数 fraction: 0 非数值 NaN\n阶码 exponent: 2047 (全1) 尾数 fraction != 0 表示未定义或非法运算, 如 0/0\n类别 (categories) 符号位 (sign) 阶码 (exponent) 尾数 (fraction / mantissa) 描述 正常数 0 或 1 [1, 2046] 1.f 范围: [1.0, 2-ε) 阶码非全0且非全1, 尾数隐含最高位1 非正规数 0 或 1 全 0 0.f 范围: (0, 1.0-ε] 阶码全0, 尾数非全0, 无隐藏位1, 接近0 ±0 0 或 1 全 0 全 0 阶码全0, 尾数全0 ±∞ 0 或 1 全 1 [2047] 全 0 阶码全1, 尾数全0 NaN (qNaN / sNaN) 0 或 1 全 1 [2047] 非全 0 阶码全1, 尾数非全0, 表示无效或未定义运算 注意: 非正规数的阶码虽然为全0, 但是计算时约定为 1-bias = 1-1023 = -1022, 而不是像正规数那样 exponent - bias\n","title":"IEEE-754 Introduce"},{"link":"/posts/designing-and-building-rest-apis/","text":"这篇文章延续之前微服务的内容, 将介绍关于 REST API 的以下几个方面:\nREST API 的设计原则 Richardson maturity model (RMM) 如何帮助理解 REST 的优势和设计原则 REST API 中资源(resource)和端点(endpoints)设计的概念 表达性状态转移 representational state transfer (REST) 描述了一种通过网络进行通信的应用程序架构风格. 最初, REST 的概念包含了一组用于设计分布式、可扩展 Web 应用的约束条件. 随着时间推移, 出现了更为细致的协议和规范, 为 REST API 的设计提供了明确的指导方针. 如今, REST 已经成为构建 Web API 的最流行选择.\n下面将继续在 CoffeeMesh 项目上, 设计相关订单 API.\nWhat is REST? REST 由 Roy Fielding 在他的博士论文 \u0026ldquo;Architectural Styles and the Design of Network-based Software Atchitecture\u0026rdquo; (PhD diss. University of California,Irvine,2000,p. 109) 中创造.\n定义: REST 是一个松耦合和高伸缩的 API 架构风格. REST APIs 以资源为核心来组织, 这些资源是可以通过 API 操作的实体.\n资源 resource 是可以通过唯一的 URL 来标识的实体, 有两种类型: 集和 collections 和 单体 singletons. 单体标识一个单独的实体, 而集和标识一组实体.\n例如, 在 CoffeeMesh 的订单服务负责管理订单, 通过 /orders/{order_id} 访问特定订单, 是一个单体端点(singleton endpoint); 而所有订单通过 /orders 获取, 是一个集和端点 (collection endpoint).\n某些资源还可以嵌套进其他资源中, 例如一个订单的 payload 中, 可能包含一个嵌套数组列出该订单的多个商品 , 例如下面这样:\nJSON Collapse Copy { \u0026#34;id\u0026#34;: \u0026#34;924721eb-a1a1-4f13-b384-37e89c0e0875\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;progress\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;2023-09-01\u0026#34;, \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;cappuccino\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;small\u0026#34;, \u0026#34;quantity\u0026#34;: 1 }, { \u0026#34;product\u0026#34;: \u0026#34;croissant\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 2 } ] } Click to expand and view more 可以创建一个嵌套端点来表示嵌套资源, 例如通过 GET /orders/{order_id}/status 端点查询订单的状态和细节信息. 当资源对应的负载 payload 较大时, 使用嵌套端点是一种常见的优化策略, 例如只想知道状态信息, 就不需要查询大量的详细数据了, status 端点返回信息如下:\nJSON Collapse Copy { \u0026#34;status\u0026#34;: \u0026#34;processing\u0026#34; } Click to expand and view more Architectural constraints of REST applications 这里解释 REST 应用的架构约束, 这些约束由 Fielding 列出, 用于规定服务器应如何处理并响应客户端请求. 下面是每个约束的简单描述:\nClient-server architecture 客户端-服务器架构: 用户界面必须与后端解耦 decoupled Statelessness 无状态性: 服务器不能在请求之间维护状态 Cacheability 可缓存性: 返回相同内容的请求, 应支持缓存 Layered system 分层系统: API 按层架构, 但要向用户隐藏复杂性 Code on demand 按需代码: 服务器可以按需将代码注入到用户界面 Uniform interferace 统一接口: API 必须提供一致的接口来访问和操作资源 Separation of concers: The client-server architecture principle 关注点分离: 客户端-服务器架构原则\nREST 依赖于关注点分离原则, 因此要求用户界面(UI)必须于数据存储和服务器逻辑解耦. 这样一来, 服务器组件就可以独立于 UI 元素进行开发. 一种常见的实现方法是: 将 UI 构建为一个独立应用, 例如单页应用(SPA)\nMake it scalable: The statelessness principle 可扩展性: 无状态原则\n在 REST 中, 每一次对服务器的请求都必须包含处理该请求的全部信息. 特别是, 服务器不能在请求之间保持状态. 将状态管理从服务器组件中移除, 可以更容易地对后端进行水平扩展, 这使得我们能够部署多个服务器示例, 并且由于这些实例都不管理 API 客户端的状态, 客户端就可以于任意一个实例进行通信.\nOptimize for performance: The cacheability principle 性能优化: 可缓存原则\n在适用的情况下, 服务器必须是可缓存的. 缓存提升 API 的性能, 这意味着不必一次又一次地执行生成响应所需要的计算. GET 请求适合缓存, 因为他们返回的是服务器中已保存的数据. 通过缓存 GET 请求, 可以避免在用户每次请求相同信息时都从数据源重新获取数据, 生成 GET 请求响应所需要的时间越长, 缓存所带来的收益就越大.\nMake it simple for the client: The layered system principle 让客户端更简单: 分层系统原则\n在 REST 架构中, 客户端必须通过一个唯一的入口访问 API, 而且不应该知道自己是直接连接到最终服务器, 还是连接到某个中间层(例如负载均衡器). 可以把服务端的应用的不同组件部署在不同的服务器上, 或者把相同的组件部署在多个服务器上, 以实现冗余和壳扩展性. 但这些复杂性必须对用户隐藏, 只暴露一个统一的入口来封装服务访问.\nExtendable interferaces: The code-on-demand principle 可扩展接口: 按需代码原则\n服务器可以通过直接从后端发送可执行代码, 来扩展客户端应用的功能. 这个约束是可选的, 只适用于后端提供客户端界面的应用.\nKeep it consistent: The uniform interface principle 保持统一性: 统一接口原则\nREST 应用必须向其使用者提供统一且一直的接口, 接口必须有文档说明, 服务器和客户端必须严格遵循 API 规范. 每个资源通过统一资源标识符(URI)来标识, 每个 URI 必须唯一, 并且始终返回相同的资源. 资源必须使用某种序列化方法表示, 并且这种方法在整个 API 中应保持一致. 如今, REST API 通常使用 JSON 作为序列化格式, 但也可以使用其他格式, 例如 XML.\nHypermedia as the engine of application state 超媒介作为应用状态引擎 (HATEOAS)\n在 2008 年发表的一篇题为REST APIs Must Be Hypertext-Driven的文章中, Fielding 提出:\nREST API 的响应必须包含相关链接, 以便客户端可以通过这些链接导航 API\nHATEOAS 是 REST API 设计中的一种范式(paradigm), 它强调可发现性. 每当客户端向服务器请求某个资源时, 响应必须包含指向该资源的相关链接列表. 例如, 客户端请求订单详情时, 响应必须包含取消订单和支付订单的相关链接.\n例如下面这样\nJSON Collapse Copy { \u0026#34;id\u0026#34;: 8, \u0026#34;status\u0026#34;: \u0026#34;progress\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;2025-8-16\u0026#34;, \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;cappuccino\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;small\u0026#34;, \u0026#34;quantity\u0026#34;: 1 }, { \u0026#34;product\u0026#34;: \u0026#34;croissant\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 2 } ], \u0026#34;links\u0026#34;: [ { \u0026#34;href\u0026#34;: \u0026#34;/orders/8/cancel\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Cancels the order\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;POST\u0026#34; }, { \u0026#34;href\u0026#34;: \u0026#34;/orders/8/pay\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Pays for the order\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;POST\u0026#34; } ] } Click to expand and view more 提供关联链接可以使 API 具有可导航性, 更易于使用, 因为每个资源都会附带与之交互所需的所有 URL. 然而在实际中, 许多 API 并没有这样实现, 原因包括:\n超链接提供的信息在 API 文档中已经可用 实际上, OpenAPI 规范中包含的信息比单独为特定资源提供的相关链接列表要丰富和结构化得多 不总是清楚应该返回哪些链接 不同用户拥有不同的权限和角色, 可以执行不同操作和访问不同资源 例如，CoffeeMesh API 的外部用户可以使用 POST /orders 下单, 也可以使用 GET /orders/{order_id} 查询订单详情, 但不能使用 DELETE /orders/{order_id} 删除订单, 因为该接口仅限内部用户 如果 HATEOAS 的目标是让 API 可以从单一入口导航, 那么向外部用户返回他们无法使用的 DELETE 链接显然没有意义 因此, 需要根据用户权限返回不同的相关链接列表, 但这会增加 API 设计和实现的复杂性, 并将授权层与 API 层耦合 资源状态可能限制某些操作 例如, POST /orders/1234/cancel 只能在活跃订单上调用, 而无法对已取消订单调用 这种不确定性会增加遵循 HATEOAS 原则的接口设计和实现难度 响应负载可能过大 在一些 API 中, 相关链接列表可能非常庞大, 使响应体变大, 从而影响 API 性能, 以及对网络连接较差的小设备的可靠性 在设计自己的 API 时, 可以根据实际情况决定是否遵循 HATEOAS 原则, 在某些情况下是有用的, 例如:\n在 Wiki 应用中, 响应中的 \u0026ldquo;linked resources\u0026rdquo; 部分可以列出\n与某篇文章相关的内容 该文章的多语言版本链接 可以对文章执行的操作链接 总体来说, 需要在 API 文档已经清晰详细提供信息 与 通过响应辅助客户端交互 之间找到平衡\n面向公众的 API: 客户端会从关联链接中受益 小型内部 API: 通常不需要提供关联链接 Analyzing the matruity of an API with the Richardson maturity model 使用 Richardson 成熟度模型分析 API 的成熟度\n这是由 Leonard Richardson 提出的一种思维模型, 用于帮助评估一个 API 在多大程度上遵循了 REST 原则, Richardson 成熟度模型将 API 的\u0026quot;成熟度\u0026quot;划分为四个等级: 0. Level 0: RPC over HTTP\nLevel 1: Resources Level 2: HTTP methods and status codes Level 3: Hypermedia controls (HATEOAS) Glory of REST! Level 0: Web APIs à la RPC 类似 PRC 的 Web API\n在0级中, HTTP 本质上只作为一种传输系统, 用于承载与服务器的交互. 在这种情况下, API 的概念更接近 远程过程调用(remote procedure call, RPC). 所有服务器的请求都在同一个端点发起, 并使用相同的 HTTP 方法, 客户端请求的具体细节通过 HTTP 的 payload 传递.\n例如, 在 CoffeeMesh 网站下单时, 客户端可能会向通用 /api 端点发送如下 POST 请求:\nJSON Collapse Copy { \u0026#34;action\u0026#34;: \u0026#34;placeOrder\u0026#34;, \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;mocha\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 2 } ] } Click to expand and view more 服务器通常会返回200状态码, 并附带一个 payload, 告诉请求处理结果.\n类似地, 要获取某个订单的详情, 客户端也可能向通用 /api 端点发送如下 POST 请求:\nJSON Collapse Copy { \u0026#34;action\u0026#34;: \u0026#34;getOrder\u0026#34;, \u0026#34;order\u0026#34;: [ { \u0026#34;id\u0026#34;: 8 } ] } Click to expand and view more Level 1: Intorducing the concept of resource 第1级引入了资源 URL 的概念, 服务器不再使用通用的 /api 端点, 而是暴露表示资源的 URL. 例如:\n/orders 表示订单集和 /order/{order_id} 表示单个订单 要下单时, 客户端向 /orders 端点发送 POST 请求, payload 与 0 级类似\nJSON Collapse Copy { \u0026#34;action\u0026#34;: \u0026#34;placeOrder\u0026#34;, \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;mocha\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 2 } ] } Click to expand and view more 在这一层, API 还没有使用不同的 HTTP 方法来区分不同操作\nLevel 2: Using HTTP methods and status codes 第2级引入了 HTTP 请求方法verbs 和 状态码status 的概念, 这一层, HTTP verbs 用于表示具体操作. 例如, 要下订单, 客户端向 /orders 端点发送一个 POST 请求, 内容如下:\nPYTHON Collapse Copy { \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;mocha\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 2 } ] } Click to expand and view more 在这个例子中, HTTP 方法 POST 表示要执行的操作, 而请求体仅包含想要下的订单的具体信息\n类似地, 如果要获取某个订单的详细信息, 我们会向该订单的 URI 发送 GET 请求: /orders/{order_id}. 这里使用 GET 告诉服务器, 希望获取 URI 指定资源的详细信息\n前几个级别的响应通常都使用相同的状态码(通常为 200), 而第二级引入了 HTTP 状态码的语义化使用, 用来报告客户端请求处理的结果. 例如:\n使用 POST 创建资源时, 服务器会返回 201 Created 状态码 请求不存在的资源时, 会返回 404 Not Found 状态码 Level 3: API discoverability 第3级引入了可发现性的概念, 通过 HATEOAS 原则, 并在响应中添加表示可对资源执行操作的链接来实现.\n例如, 对 /orders/{order_id} 端点发送 GET 请求, 会返回该订单的表示(representation), 并包含一系列相关链接\nPYTHON Collapse Copy { \u0026#34;id\u0026#34;: 8, \u0026#34;status\u0026#34;: \u0026#34;progress\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;2023-09-01\u0026#34;, \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;cappuccino\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;small\u0026#34;, \u0026#34;quantity\u0026#34;: 1 }, { \u0026#34;product\u0026#34;: \u0026#34;croissant\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 2 } ], \u0026#34;links\u0026#34;: [ { \u0026#34;href\u0026#34;: \u0026#34;/orders/8/cancel\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Cancels the order\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;POST\u0026#34; }, { \u0026#34;href\u0026#34;: \u0026#34;/orders/8/pay\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Pays for the order\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;GET\u0026#34; } ] } Click to expand and view more 在 Richardson 成熟度模型中, 第三级代表了他所称的 \u0026ldquo;REST 的荣耀(Glory of REST)\u0026rdquo; 的最后一步\n该模型为我们提供了一个框架, 用来思考 API 设计在 REST 原则体系中的位置. 它的目的不是衡量 API 在多大程度上\u0026quot;符合\u0026quot;REST 原则, 也不是评估 API 设计的质量; 而是帮助我们思考如何充分利用 HTTP 协议, 创建表达力强、易理解、易使用的 API.\n","title":"Designing and Building REST APIs"},{"link":"/posts/intorduce-uuid/","text":"UUID(Universally Unique Identifier, 通用唯一标识符) 是一种标准化的128位标识符, 用于在分布式系统中生成几乎不会重复的唯一 ID. 最早于 IETF 制定为 RFC 4122 标准, 保证在不同机器、不同时间生成的 ID 也能保持全局唯一.\nUUID 通常以16进制表示, 采用5段结构, 用连字符 - 分隔, 例如:\nPLAINTEXT Collapse Copy 550e8400-e29b-41d4-a716-446655440000 Click to expand and view more 有如下特点:\n全局唯一 无中心依赖 不可预测 跨平台通用 UUID 有以下不同版本:\n版本 生成 特点 v1 基于时间戳 + MAC 地址 按时间排序，含生成设备信息 v3 基于命名空间的 MD5 哈希 输入相同则输出相同(MD5 已不再安全) v4 基于操作系统的随机数生成 完全随机, 最常用 v5 基于命名空间的 SHA-1 哈希 与 v3 类似, 但使用 SHA-1 v6~v8 现代版本(草案) 提高排序性能和隐私保护 其中, 对于需要时间有序的使用 v1, 大多数通用场景使用 v4\nUUID 的应用场景\n数据库主键(分布式环境避免冲突) 会话标识(Session ID、Token) 文件命名(防止重名) 分布式系统节点 ID 追踪请求链路(Trace ID) 示例代码\nPYTHON Collapse Copy import uuid # 生成 UUID v1 u1 = uuid.uuid1() print(\u0026#34;UUID v1:\u0026#34;, u1) # 生成 UUID v4（随机） u4 = uuid.uuid4() print(\u0026#34;UUID v4:\u0026#34;, u4) # 生成 UUID v3（命名空间 + MD5） u3 = uuid.uuid3(uuid.NAMESPACE_DNS, \u0026#34;example.com\u0026#34;) print(\u0026#34;UUID v3:\u0026#34;, u3) # 生成 UUID v5（命名空间 + SHA-1） u5 = uuid.uuid5(uuid.NAMESPACE_DNS, \u0026#34;example.com\u0026#34;) print(\u0026#34;UUID v5:\u0026#34;, u5) Click to expand and view more UUID v1: 9f7a1f7e-9e87-11ee-b15d-0242ac120002\nUUID v4: 5f9b44e4-62af-4d13-bd4c-52de5f028f33\nUUID v3: 9073926b-929f-31c2-abc9-fad77ae3e8eb\nUUID v5: 2ed6657d-e927-568b-95e1-2665a8aea6a2\n","title":"Intorduce UUID"},{"link":"/posts/microservice-with-fastapi/","text":"What are microservices ? 什么是微服务? 微服务可以有多种不同的定义方式, 具体取决于希望强调微服务架构的哪个方面, 不同作者会给出略有不同但相关的定义\nSam Newman, 微服务领域最有影响力的作者之一, 给出了一个极简的定义:\n“Microservices are small, autonomous services that work together.”\n这个定义强调了这样一个事实: 微服务是彼此独立运行的应用程序, 但它们可以协作完成任务. 该定义还强调微服务是 “small (小的)”, 这里的 small 并不是指微服务代码量的大小, 而是指微服务具有狭窄且定义清晰的职责范围, 符合单一职责原则(Single Responsibility Principle) —— 即“只做一件事，并把它做好”.\nJames Lewis 和 Martin Fowler 撰写的一篇开创性文章提供了一个更详细的定义, 他们将微服务定义为一种架构风格(architectural style)\n“an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API”\n这个定义强调了服务的自主性(autonomy), 指出它们运行在各自独立的进程中. Lewis 和 Fowler 同样强调了微服务职责的狭窄性(narrow scope of responsibilities), 称其为“small”, 并明确指出微服务之间通过轻量协议(如HTTP)进行通信\n定义\n微服务是一种架构风格，其中系统的各个组件被设计为可独立部署的服务(independently deployable services). 微服务围绕明确的业务子领域(business subdomains)进行设计，并通过如 HTTP 等轻量协议(lightweight protocols)相互通信 从以上定义中我们可以看到, 微服务可以被定义为一种架构风格, 其中服务作为组件执行一组小而明确的相关功能. 这意味着微服务是围绕特定的业务子领域来设计和构建的, 例如处理支付、发送邮件或处理客户订单等.\n微服务作为独立的进程进行部署, 通常运行在独立的环境中, 并通过定义清晰的接口暴露其能力\nA basic API implementation 这里通过一个 CoffeeMesh 项目的 orders service (订单服务) api 介绍微服务\n首先给出 OpenAPI 格式的 API 定义文档 oas.yaml, 可以通过 Swagger UI 来查看该文档内容 (OAS 代表 OpenAPI specification/规范, 是一种标准的 REST API 文档)\n具体 API 如下\n/orders: 检索订单(GET) 和 创建订单(POST) /orders/{order_id}: 检索某个订单的细节(GET), 更新订单(PUT) 和 删除订单(DELETE) /orders/{order_id}/cancel: 删除某个订单 /orders/{order_id}/pay: 支付订单 除了 API endpoints, 还有 data models (在 OpenAPI 中被称为 schemas). Schemas 告诉客户端需要什么样的数据载荷(payload)以及什么是类型.\n例如,OrderItemSchema 指定了 product 和 size 是必填的, 而 quantity 属性是可选的, 当这个属性消失的时候, 默认值为 1\nYAML Collapse Copy # file: oas.yaml OrderItemSchema: type: object required: - product - size properties: product: type: string size: type: string enum: - small - medium - big quantity: type: integer default: 1 minimum: 1 Click to expand and view more 请求处理流大概下面这样: HTTP request -\u0026gt; Uvicorn -\u0026gt; FastAPI(Starlette routing -\u0026gt; data -\u0026gt; api endpoints) -\u0026gt; Pydantic\n下面是一个 orders API 的最小实现\nPYTHON Collapse Copy from datetime import datetime from uuid import UUID from starlette.responses import Response from starlette import status from orders.app import app order = { \u0026#34;id\u0026#34;: \u0026#34;ff0f1355-e821-4178-9567-550dec27a373\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;delivered\u0026#34;, \u0026#34;created\u0026#34;: datetime.utcnow(), \u0026#34;order\u0026#34;: [ { \u0026#34;product\u0026#34;: \u0026#34;cappuccino\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;quantity\u0026#34;: 1, } ] } @app.get(\u0026#34;/orders\u0026#34;) def get_orders(): return {\u0026#34;orders\u0026#34;: [orders]} @app.post(\u0026#34;/orders\u0026#34;, status_code=status.HTTP_201_CREATED) def create_order(): return order @app.get(\u0026#34;/orders/{order_id}\u0026#34;) def get_order(order_id: UUID): return order @app.get(\u0026#34;/orders/{order_id}\u0026#34;) def update_order(order_id: UUID): return order @app.delete(\u0026#34;/orders/{order_id}\u0026#34;, status_code=status.HTTP_204_NO_CONTENT) def delete_order(order: UUID): return Response(status_code=HTTPStatus.NO_CONTENT.value) @app.post(\u0026#34;/orders/{order_id}/cancel\u0026#34;) def cancel_order(order_id: UUID): return order @app.post(\u0026#34;/orders/{order_id}/pay\u0026#34;) def pay_order(order_id: UUID): return order Click to expand and view more 现在有了 API 的基本骨架, 后面将继续实现 incoming payload 和 outgoing response 的验证\nImplementing data validation models with pydantic 这里介绍 data validation 和 marshalling\n\u0026ldquo;Marshalling\u0026rdquo; 指的是将一个内存中的数据结构转换成一种适合存储或通过网络传输的格式. 在 Web API 的上下文中, Marshalling 特指将一个对象转换为一个数据结构(比如 JSON 或 XML). 以便将其序列化为所选的内容类型, 同时明确指定对象属性的映射关系\n点单系统包含了3个shcemas: CreateOrderSchema, GetOrderSchema 和 OrderItemSchema, 可以在oas.yaml查看\n下面使用 Pydantic 实现对应 schema, 可以在 schema.py找到\nPYTHON Collapse Copy from enum import Enum class Size(Enum): small = \u0026#34;small\u0026#34; medium = \u0026#34;medium\u0026#34; big = \u0026#34;big\u0026#34; class StatusEnum(Enum): created = \u0026#34;created\u0026#34; paid = \u0026#34;paid\u0026#34; progress = \u0026#34;progress\u0026#34; cancelled = \u0026#34;cancelled\u0026#34; dispatched = \u0026#34;dispatched\u0026#34; delivered = \u0026#34;delivered\u0026#34; Click to expand and view more 对于只能从特定值中选择的类型, 定义枚举类型 Size 和 StatusEnum\nPYTHON Collapse Copy class OrderItemSchema(BaseModel): product: str size: Size quantity: conint(ge=1, strict=True) | None = 1 Click to expand and view more 将 OrderItemSchema 的属性设置为 conint, 这将强制使用整数值, 并且规定数值要大于等于1, 以及默认值1\nPYTHON Collapse Copy class CreateOrderSchema(BaseModel): order: conlist(OrderItemSchema, min_items=1) class GetOrderSchema(CreateOrderSchema): id: UUID created: datetime status: StatusEnum class GetOrdersSchema(BaseModel): orders: List[GetOrderSchema] Click to expand and view more 使用 pydantic 的 conlist 类型定义了 CreateOrderSchema 的 order 属性, 要求列表至少有一个元素\nValidating request payloads with pydantic 上面实现了模型定义, 现在通过将其声明为视图函数的一个参数来拦截请求负载, 并通过将其类型设置为相关的 Pydantic 模型进行验证\n代码可以在api.py里找到\nPYTHON Collapse Copy from uuid import UUID from starlette.response import Response from starlette import status from orders.app import app from orders.api.schemas import CreateOrderSchema # 导入数据模型 @app.post(\u0026#34;/orders\u0026#34;, status_code=status.HTTP_201_CREATED) def create_order(order_details: CreateOrderSchema): return order @app.get(\u0026#34;/orders/{order_id}\u0026#34;) def get_order(order_id: UUID): return order @app.put(\u0026#34;/orders/{order_id}\u0026#34;) def update_order(order_id: UUID, order_details: CreateOrderSchema): return order Click to expand and view more 如果发送一个有问题的数据(例如移除 product 字段), FastAPI 将会生成一份错误消息.\nJSON Collapse Copy { \u0026#34;detail\u0026#34;: [ { \u0026#34;loc\u0026#34;: [ \u0026#34;body\u0026#34;, \u0026#34;order\u0026#34;, 0, \u0026#34;product\u0026#34; ], \u0026#34;msg\u0026#34;: \u0026#34;field required\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;value_error.missing\u0026#34; } ] } Click to expand and view more 该错误消息使用 JSON Pointer 来指示问题所在, JSON Pointer 是一种语法, 用来表示 JSON 文档中特定值的路径\n例如, loc: /body/order/0/product 大概等同于 Pytohn 中的以下表示法 loc['body']['order'][0]['product']\nbody 指的是请求的主体部分 order 指的是主体中的 order 键 0 指的是 order 列表中的第一个元素 product 指的是这个元素中的 product 键 有时候参数可能是可选的, 但是并不能为 null. 这里使用 Pydantic 的 validator() 装饰器来添加额外的规则\nPYTHON Collapse Copy from pydantic import BaseModel, conint, validator ... class OrderItemSchema(BaseModel): product: int size: Size quantity: conint(ge=1, strict=True) | None = 1 @validator(\u0026#39;quantity\u0026#39;) def quantity_non_nullable(): assert value is not None, \u0026#34;quantity may not be None\u0026#34; return value Click to expand and view more Marshalling and validating response payloads with pydantic 这里定义一下返回类型 api.py\nPYTHON Collapse Copy from starlette.responses import Response from starlette import status from orders.api.schemas import ( GetOrderSchema, CreateOrderSchema, GetOrdersSchema, ) @app.get(\u0026#34;/orders\u0026#34;, response_model=GetOrdersSchema) def get_orders(): return [ order ] @app.post( \u0026#34;/orders\u0026#34;, status_code=status.HTTP_201_CREATED, response_model=GetOrderSchema ) def create_order(order_details: CreateOrderSchema): return order Click to expand and view more 现在, 如果 response payload 中缺少了返回类型需要的属性, FastAPI 则会报错, 如果有多的属性, 则会被去除\nAdding an in-memory list of orders to the API 现在通过一个简单的内存列表来管理订单状态\nPYTHON Collapse Copy import time import uuid from datetime import datetime from uuid import UUID from fastapi import HTTPException from starlette.responses import Response from starlette import status from orders.app import app from orders.api.schemas import GetOrderSchema, CreateOrderSchema ORDERS = [] # in memory list # 获取订单列表 @app.get(\u0026#34;/orders\u0026#34;, respones_model=GetOrderSchema) def get_orders(): return ORDERS # return order list # 创建订单 @app.post( \u0026#34;/orders\u0026#34;, status_code=status.HTTP_201_CREATED, response_model=GetOrderSchema, ) def create_order(order_details: CreateOrderSchema): # convert Pydantic model -\u0026gt; dict: v1 use .dict(); v2 use .model_dump() order = order_details.model_dump() order[\u0026#34;id\u0026#34;] = uuid.uuid4() # 获取订单 @app.get(\u0026#34;/orders/{order_id}\u0026#34;, response_model=GetOrderSchema) def get_order(order_id: UUID): for order in ORDERS: if order[\u0026#34;id\u0026#34;] == order_id: return order raise HTTPException( status_code=404, detail=f\u0026#34;Order with ID {order_id} not found\u0026#34;, ) # 更新订单 @app.put(\u0026#34;/orders/{order_id}\u0026#34;, response_model=GetOrderSchema) def update_order(order_id: UUID, order_details: CreateOrderSchema): for order in ORDERS: if order[\u0026#34;id\u0026#34;] == order_id: order.update(order_details.model_dump()) return order raise HTTPException( status_code=404, detail=f\u0026#34;Order with ID {order_id} not found\u0026#34;, ) # 删除订单 @app.delete( \u0026#34;/orders/{order_id}\u0026#34;, status_code=status.HTTP_204_NO_CONTENT, response_class=Response ) def delete_order(order_id: UUID): for index, order in enumerate(ORDERS): if order[\u0026#34;id\u0026#34;] == order_id: ORDERS.pop(index) return Response(status_code=HTTPStatus.NO_CONTENT.value) raise HTTPException( status_code=404, detail=f\u0026#34;Order with ID {order_id} not found\u0026#34;, ) # 取消订单 @app.post(\u0026#34;/orders/{order_id}/cancel\u0026#34;, response_model=GetOrderSchema) def cancel_order(order_id: UUID): for order in ORDERS: if order[\u0026#34;id\u0026#34;] == order_id: order[\u0026#34;status\u0026#34;] = \u0026#34;cancelled\u0026#34; return order raise HTTPException( status_code=404, detail=f\u0026#34;Order with ID {order_id} not found\u0026#34;, ) # 支付订单 @app.get(\u0026#34;/orders/{order_id}/pay\u0026#34;, response_model=GetOrderSchema) def pay_order(order_id: UUID): for order in ORDERS: if order[\u0026#34;id\u0026#34;] == order_id: order[\u0026#34;status\u0026#34;] = \u0026#34;progress\u0026#34; return order raise HTTPException( status_code=404, detail=f\u0026#34;Order with ID {order_id} not found\u0026#34;\u0026lt;\u0026gt; ) Click to expand and view more Microservice Principles 微服务设计原则: 如何将系统拆分为微服务 service decomposition, 以及如何估计其质量 下面是三个设计原则:\nDatabase-per-service principle 服务独立数据库原则 Loose coupling principle 松耦合原则 Single Responsibility Principle (SRP) 单一职责原则 遵循这些原则将帮助你避免构建一个\u0026quot;分布式单体应用\u0026quot;(distributed monolith)的风险\nData-per-service principle 服务独立数据库原则是指, 每个微服务拥有一系列具体的数据, 并且其他微服务只能通过 API 访问.\n这并不意味着每个微服务都要连接到不同的数据库中, 可以是关系数据库中的不同 tables, 或者非关系数据库中的 collections, 关键是数据被某个服务拥有, 不能被其他服务直接访问.\n例如, 为了计算价格, orders service 从 Production database 中获取每个物品的价格, 它也需要知道用户是否有折扣优惠, 这个需要从 User database 获取. 然而, 不能直接诶访问这两个数据库, order service 需要从 products service 和 users service 获取数据.\nLoose coupling principle 松耦合原则要求在设计服务的时候, 必须清晰的关注分离点, 松耦合的服务不依赖另一个服务的实现细节, 这项原则有两个实际的应用:\n每个服务都可以独立于其他服务工作: 如果一个服务在不调用另一个服务的情况下无法完成一个简单的请求, 那么这两个服务之间没有清晰的关注点分离, 他们应被视为一个整体 每个服务都可以在不影响其他服务工作的情况下进行更新: 如果一个服务的更新需要其他服务, 那么这些服务之间存在紧密耦合, 需要重新设计 例如, 一个基于历史数据计算销售预测的服务(Sales Forecast Service), 以及一个拥有历史销售数据的服务(Historical Data Service), 为了计算预测, 销售服务会调用历史数据服务的API来获取历史数据. 在这种情况下, 销售预测服务在不调用历史数据服务的情况下无法响应任何请求, 因此两个服务之间存在紧密耦合.\n解决方案是重新设计这两个服务, 使它们不相互依赖, 或者将它们合并成一个单一的服务.\nSingle responsibility principle 单一职责原则(SRP)指出, 我们要设计职责少、理想情况下只有一个职责的组件. 当应用于微服务设计架构时, 这意味着我们应努力围绕单一的业务能力或子域来设计服务.\nDecomposing micorservices by business capabilities 下面将 CoffeeMesh 系统根据业务内容分成以下部分\n产品团队对应产品服务 原料团队对应原料服务 销售团队对应销售服务 金融团队对应金融服务 厨房团队对应厨房服务 配送团队对应配送服务 在上面的微服务架构中, 将不同的业务定义为一个微服务, 这样是为了方便, 但并不一定要这样实现\n如上的设计规则, 满足了 SRP 原则, 每个模块都处理自己的数据, 但是这种设计并不满足松耦合原则(loose couping principle), 产品服务需要确定每款产品的库存,由于库存数据在原料服务中, 这就需要依赖原料服务, 而为每个产品都设计一个面向原料服务的 API 显然不太合理.\n因此, 这两个服务应该耦合在一起, 最终的服务结构如下:\nProducts service: Products and Ingredients team Sales service: Sales team Kitchen service: Kitchen team Finance service: Finance team Delivery service: Delivery service Service decomposition by subdomains 通过子领域分解是一种从 领域驱动设计(domain-driven desgin, DDD) 中汲取灵感的方法. 领域驱动设计是一种软件开发方法, 它专注于使用业务用户相同的语言来对业务流程和流向进行建模, 当应用于微服务设计时, DDD 能够帮助定义每个服务的核心职责和边界\n对于 CoffeeMesh 项目, 我们希望根据下单的过程, 以及配送给客户的过程来建模, 将其分解为以下8步:\n当用户登陆网站后, 像用户展示产品列表. 每个产品都表示是否有库存. 用户可以根据是否有库存和价格来排序 用户选择产品后下单 用户为订单付费 一但用户付费, 就将订单细节传递给 kitchen 服务 kitchen 服务根据订单制作咖啡 用户可以查询订单进度 一但订单制作完成, 就安排配送 用户可以追踪无人机的配送进度, 直到配送到用户手中 根据上面步骤, 将模块划分为以下几个子领域 (subdomains)\nProduction Subdomain 产品子领域\n第一个服务用于 CoffeeMesh 产品目录的子域, 这个子域告诉用户哪些产品可用, 哪些不可用. 为此, 产品子域会追踪每种产品和原料的库存\nOrders Subdomain 订单子域\n第二步代表一个允许用户选择产品的子域, 这个子域用于管理订单的声明周期. 该子域拥有用户订单的数据, 并提供一个接口来管理订单和检查其状态. 订单领域还负责第四步的第二部分: 在成功处理付款后, 将订单传递给厨房. 同时也满足了第六步的要求: 允许用户检查其订单状态. 作为订单管理者, 订单子域还会与配送子域协作来安排配送.\nPayments Subdomain 支付子域\n第三步代表一个处理用户支付的子域. 该子域包括用户支付处理的专门逻辑, 包括银行卡验证, 与第三方支付提供商集成, 处理不同支付方式等. 支付子领域拥有与用户支付相关的数据.\nKitchen Subdomain 厨房子域\n第五步代表一个与厨房协作来管理客户订单生产的子域. 厨房的生产系统是全自动的, 厨房子域与厨房系统进行接口交互, 以安排客户订单的生产并追踪其进度.一旦订单生产完成, 厨房子域会通知订单子域, 后者随后安排配送. 厨房子域拥有与客户订单生产相关的数据, 并公开一个接口, 允许我们向厨房发送订单并跟踪其进度. 订单子域通过与厨房子域的接口交互, 来更新订单状态, 以满足第六步的需求.\nDelivery Subdomain 配送子域\n第七步代表一个与自动化配送系统进行接口交互的子域. 该子域包含专门的逻辑, 用于解析客户的地理位置并计算到达他们的最佳路线. 它管理着配送无人机机队并优化配送, 同时拥有与所有配送相关的数据. 订单子域通过与配送子域的接口交互, 来更新客户订单的行程, 以满足第八步的需求.\n通过以上分析, 将 CoffeeMesh 分解为5个子领域, 这些子领域可以被映射为微服务, 每个子领域都封装了定义明确, 职责清晰且拥有自己的逻辑区域. 领域驱动设计的微服务也满足了之前的微服务设计原则: 所有这些子域都可以在不依赖其他微服务的情况下执行其核心任务, 因此是松耦合的; 每个服务都拥有自己的数据, 因此符合服务独立数据库原则; 最后, 每个服务都在一个定义狭窄的子域内执行任务, 这符合单一职责原则.\nWrapping Up 上面介绍了微服务的概念, 并通过一个 CoffeeMesh 的项目解释了如何将其分解(decompose)为微服务架构, 分别通过业务分解和通过子领域分解, 以及设计微服务的3条原则:\nDatabase-per-service principle 数据库独享原则 Loose coupling principle 松耦合原则 Single responsibility principle 单一责任原则 ","title":"Microservice with FastAPI"},{"link":"/posts/python-generics/","text":"本篇文件介绍 Python 中的 泛型(Generics)\nIntro 在没有泛型的情况下, 会遇上以下几个问题:\n难以表达意图\n假设你编写了一个函数, 它接受一个列表, 并返回列表中的第一个元素. 在不使用类型提示的情况下, 这个函数可以处理任何类型的列表, 但我们无法在函数签名中表达\u0026quot;返回的元素的类型与列表中的元素类型相同\u0026quot;这个意图\nPYTHON Collapse Copy def get_first_element(items): return items[0] Click to expand and view more 丧失类型信息\n如果使用类型提示, 可能会像下面这样写, 但这样会丢失类型信息. list[Any] 表示可以接收任何类型的列表, 但 -\u0026gt; Any 意味着不知道返回的元素类型是什么, 这使得 mypy 等静态类型检测工具无法追踪类型, 降低了代码的可读性和安全性\nPYTHON Collapse Copy from typing import Any def get_first_element(items: list[Any]) -\u0026gt; Any: return items[0] # 调用时, 类型检查工具无法得知 first_str 的类型 first_str = get_first_element([\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;]) Click to expand and view more 代码重复\n如果为每种可能的类型都编写一个单独的函数, 则会导致代码重复\nPYTHON Collapse Copy def get_first_int(items: list[int]) -\u0026gt; int: return items[0] def get_first_str(items: list[str]) -\u0026gt; str: return items[0] Click to expand and view more 通过引入 类型变量 (TypeVar) 来解决问题, 类型变量就像一个占位符, 代表在未来某时刻会被具体指定的类型\nPYTHON Collapse Copy from typing import TypeVar T = TypeVar(\u0026#34;T\u0026#34;) def get_first_element(items: list[T]) -\u0026gt; T: return items[0] # 现在, 类型检查工具可以正确推断出类型 first_str: str = get_first_element([\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;]) first_int: int = get_first_element([1, 2, 3]) Click to expand and view more T = TypeVar('T') 定义了一个名为 T 的类型变量, 这里 T 只是一个约定俗成的名字, 也可以使用其他字母 items: list[T] 表示 items 是一个列表, 其内部元素类型是 T -\u0026gt; T: 返回类型也是 T 当使用 [\u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;] 调用函数时, 静态类型检查器会推断出 T 是 str, 返回类型为 str 当使用 [1, 2, 3] 调用函数时, T 被推断为 int 注意: 这个函数假设列表非空, 如果传入空列表会抛出 IndexError\nGeneric Class 除了函数, 泛型也常用于定义泛型类\nPYTHON Collapse Copy from typing import TypeVar, Generic T = TypeVar(\u0026#34;T\u0026#34;) class Box(Generic[T]): def __init__(self, items: list[T]): self._items = items def get(self) -\u0026gt; T: return self._items[0] def add(self, item: T) -\u0026gt; None: self._items.append(item) # 创建一个存储字符串的 Box string_box = Box([\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;]) item_str = string_box.get() # str string_box.add(\u0026#34;cherry\u0026#34;) # 创建一个存储整数的 Box int_box = Box([10, 20]) item_int = int_box.get() # int int_box.add(30) Click to expand and view more TypeVar 定义类型变量: 相当于一个占位符, 将来由使用者指定具体类型 Generic 定义泛型类或泛型接口: 使这个类在类型检查器眼中变成一个模板 Advanced Usage 简单介绍一下泛型的一些进阶用法\n多类型参数\nPYTHON Collapse Copy from typing import TypeVar, Generic K = TypeVar(\u0026#34;K\u0026#34;) V = TypeVar(\u0026#34;V\u0026#34;) class Pair(Generic[K, V]): def __init__(self, key: K, value: V): self.key = key self.value = value def get_key(self) -\u0026gt; K: return self.key def get_value(self) -\u0026gt; V: return self.value # 使用示例 pair = Pair(\u0026#34;name\u0026#34;, 25) # Pair[str, int] Click to expand and view more 支持多个类型变量, 类似 dict[K, V] 的结构\n类型约束 (Constraints)\n有时候可能希望泛型只能是某些特定类型\nPYTHON Collapse Copy from typing import TypeVar Number = TypeVar(\u0026#39;Number\u0026#39;, int, float) def add(a: Number, b: Number) -\u0026gt; Number: return a + b # 正确使用 result1 = add(1, 2) # int result2 = add(1.5, 2.3) # float # 错误使用: mypy 会报错 # result3 = add(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;) # str 不被允许 Click to expand and view more Number 只能为 int 或 float, 传入其他类型, 类型检查工具会报错\n协变与逆变 (Covariance/Contravariance)\n在泛型类型中, 可以控制类型变量的变型关系\nPYTHON Collapse Copy from typing import Generic, TypeVar T_co = TypeVar(\u0026#34;T_co\u0026#34;, covariant=True) # 协变 T_contra = TypeVar(\u0026#34;T_contra\u0026#34;, contravariant=True) # 逆变 class Producer(Generic[T_co]): \u0026#34;\u0026#34;\u0026#34;只产出 T_co 类型的数据 (协变)\u0026#34;\u0026#34;\u0026#34; def __init__(self, value: T_co): self._value = value def get(self) -\u0026gt; T_co: return self._value class Consumer(Generic[T_contra]): \u0026#34;\u0026#34;\u0026#34;只消费 T_contra 类型的数据 (逆变)\u0026#34;\u0026#34;\u0026#34; def __init__(self): pass def consume(self, value: T_contra) -\u0026gt; None: print(f\u0026#34;Consuming: {value}\u0026#34;) Click to expand and view more 协变 (covariant): 如果 A 是 B 的子类型, 那么 Generic[A] 也是 Generic[B] 的子类型. 适用于只产出数据的场景 逆变 (contravariant): 如果 A 是 B 的子类型, 那么 Generic[B] 是 Generic[A] 的子类型. 适用于只消费数据的场景 这主要用于接口设计中的读/写分离 泛型与 Protocol\nProtocol 允许定义泛型接口 (duck typing)\nPYTHON Collapse Copy from typing import Protocol, TypeVar T = TypeVar(\u0026#39;T\u0026#39;) class SupportsLen(Protocol): def __len__(self) -\u0026gt; int: ... def total_length(items: list[SupportsLen]) -\u0026gt; int: return sum(len(x) for x in items) # 使用示例 result = total_length([\u0026#34;hello\u0026#34;, [1, 2, 3], {\u0026#34;a\u0026#34;: 1}]) # 可以接受任何有 __len__ 方法的对象 Click to expand and view more 任何实现了__len__方法的对象都能被接受, 比继承更加灵活\n泛型在标准库中的使用\n集合类: list[T], dict[K, V], set[T] 迭代器: Iterator[T], Iterable[T] 函数工具: Callable[[T1, T2], R] 上下文管理器: ContextManager[T] PYTHON Collapse Copy from typing import Callable def operate(a: int, b: int, func: Callable[[int, int], int]) -\u0026gt; int: return func(a, b) # 使用示例 def add(x: int, y: int) -\u0026gt; int: return x + y def multiply(x: int, y: int) -\u0026gt; int: return x * y result1 = operate(5, 3, add) # 8 result2 = operate(5, 3, multiply) # 15 Click to expand and view more Wrapping Up 泛型是 Python 类型提示系统中一个非常强大的工具, 它通过类型变量帮助我们编写更加灵活、安全且可维护的代码.\n它虽然不会影响程序的运行时行为 (类型信息在运行时会被擦除), 但它为静态类型分析提供了必要的信息, 使得代码意图更加清晰, 并且能在早期发现类型错误.\nPython 的泛型是类型提示系统的一部分, 和 C++/Java 的编译期泛型不同, 它的作用主要是:\n帮助 IDE 和类型检查工具发现类型错误 提升代码可读性和可维护性 提供更精确的 API 类型签名 支持更好的代码重用和抽象 ","title":"Python Generics"},{"link":"/posts/python-strings/","text":"这篇文章总结一下 Python 中字符串的类型\nUnicode String 字符串 u 在 Python3 中是多余的, 因为所有的普通字符串默认都是 Unicode, 但在 Python2 中, u 用来显示的表示 Unicode 字符串, 现在保留这个是为了向后兼容\nFromatted String 格式化字符串 f 前缀用于创建格式化字符串, 这是最常见的字符串格式方法, 运行在字符串中嵌入表达式, 在求值时转换为普通的 str\nPYTHON Collapse Copy name = \u0026#34;World\u0026#34; greeting = f\u0026#34;Hello, {name}!\u0026#34; # 结果: \u0026#34;Hello, World!\u0026#34; Click to expand and view more Raw String 原始字符串 r 前缀用于创建原始字符串, 会忽略反斜杠 \\ 的转义功能, 在编写文件路径或正则表达式的时候非常有用, 可以避免大量的反斜杠转义\nPYTHON Collapse Copy path = r\u0026#34;C:\\Users\\Documents\u0026#34; # 单个反斜杠 \u0026#39; regex = r\u0026#34;\\bword\\b\u0026#34; # \\b 不会被转义 Click to expand and view more Bytes String 字节串 b 前缀用于创建字节串字面量, 表示一个不可变的字节序列, 而不是 Unicode 文本, 字节串主要用于二进制数据, 例如图像文件、网络数据或压缩文件等\nPYTHON Collapse Copy binary_data = b\u0026#34;Hello\u0026#34; # 存储的是 ASCII 编码的字节 Click to expand and view more Template String 模板字符串 t 前缀用于创建模板字符串, 这是 Python 3.14 引入的新功能, 由 PEP 750 通过.\n不同于 f-string, t-string 不会立即求值为 str, 而是求值为一个 Template 对象, 这为开发者提供了将在将字符串和插值组合之前进行处理(和安全转义)的能力\nPYTHON Collapse Copy from string.templatelib import Template template = t\u0026#34;Hello, {name}\u0026#34; # template 是一个 Template 对象 Click to expand and view more 组合使用 前缀 含义 用途 f 格式化 嵌入变量和表达式 r 原始 忽略反斜杠转义 b 字节 处理二进制数据 t 模板 在组合前处理插值 u Unicode Python 3 中默认开启 fr / rf 格式化+原始 在正则表达式中嵌入变量 br / rb 字节+原始 忽略二进制数据中的转义 tr / rb 模板+原始 模板中处理原始文本 ","title":"Python Strings"},{"link":"/posts/fastapi-response-model/","text":"本篇文章介绍 FastAPI 的返回类型 response model\n可以在返回函数的类型注解中声明该接口的响应数据类型\n类型注解的用法和输入数据参数一样, 可以使用:\nPydantic 模型 list 列表 dict 字典 scalar 标量值 (int, bool \u0026hellip;) PYTHON Collapse Copy @app.post(\u0026#34;/items/\u0026#34;) async def create_item(item: Item) -\u0026gt; Item: ... @app.get(\u0026#34;/items/\u0026#34;) async def read_items() -\u0026gt; list[Item]: ... Click to expand and view more FastAPI 会使用返回类型完成一下事情:\n验证返回类型 如果返回的数据无效, 说明业务代码有问题, FastAPI 会返回服务器错误, 而不是把数据发给客户端\n在 OpenAPI 中为响应添加 JSON Schema 用于自动生成接口文档, 自动生成客户端代码\n最重要的是 它会限制并过滤出数据, 只保留返回类型中定义的字段\nresponse_model Parameter 有时候可能需要返回的数据和类型注解不完全一致, 例如:\n可能想返回字典或数据库对象, 但声明的响应类型为 Pydantic 模型 这样 Pydantic 会做数据文档、验证等工作, 即使返回的是字典或 ORM 对象 如果直接用返回类型注解, 编辑器会提示类型不匹配的错误\n这种情况下, 可以用路径装饰器的 response_model 参数来声明响应类型, 而不是用返回类型注解\nPYTHON Collapse Copy class Item(BaseModel): name: str description: str | None = None price: float tax: float | None = None tags: list[str] = [] @app.post(\u0026#34;/items/\u0026#34;, response_model=Item) async def create_item(item: Item) -\u0026gt; Any: return item @app.get(\u0026#34;/items/\u0026#34;, response_model=list[Item]) async def read_items() -\u0026gt; Any: return [ {\u0026#34;name\u0026#34;: \u0026#34;Portal Gun\u0026#34;, \u0026#34;price\u0026#34;: 42.0}, {\u0026#34;name\u0026#34;: \u0026#34;Plumbus\u0026#34;, \u0026#34;price\u0026#34;: 32.0}, ] Click to expand and view more 注意:\nresponse_model 是装饰器(get、post 等方法)的参数, 不是函数的参数 接收的类型和 Pydantic 字段定义一样, 可以是单个模型, 也可以是模型列表等 FastAPI 用其做数据库验证、文档生成、以及过滤输出数据 如果使用 mypy 之类做 static type check, 可以声明函数返回类型为 Any\nresponse_model 优先级 如果同时声明了 response_model 和返回类型, 则 response_model 会优先生效\n如果想要禁用响应模型, 可以设置 response_model=None (用于一些非 Pydantic 类型的返回值) Return the Same Input Data 返回相同数据数据 很多情况下, 希望模型返回与输入模型相同的数据\n这式, 可以在路径函数中直接声明 response_model=YourModel, FastAPI 会自动处理\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel, EmailStr app = FastAPI() class UserIn(BaseModel): username: str password: str email: EmailStr full_name: str | None = None # Don\u0026#39;t do this in production! @app.post(\u0026#34;/user/\u0026#34;) async def create_user(user: UserIn) -\u0026gt; UserIn: return user Click to expand and view more 不要在生产环境中以明文形式存储用户密码, 也不要像这样直接返回密码\nAdd an Output Model 添加输出模型 我们可以改成: 输入模型包含明文密码, 输出模型不含\nPYTHON Collapse Copy from typing import Any from fastapi import FastAPI from pydantic import BaseModel, EmailStr app = FastAPI() # Input model class UserIn(BaseModel): username: str password: str email: EmailStr full_name: str | None = None # Output model class UserOut(BaseModel): username: str email: EmailStr full_name: str | None = None @app.post(\u0026#34;/user/\u0026#34;, response_model=UserOut) # output async def create_user(user: UserIn) -\u0026gt; Any: return user # like input Click to expand and view more 这样, 即使路径操作函数返回的对象中包含该字段, FastAPI 也会按照 response_model=UserOut 来过滤密码\nReturn Type and Data Filtering 返回类型与数据过滤 延续上面的例子, 希望函数的类型注解和实际返回值不同:\n函数返回的对象可能包含更多数据, 但响应中只保留输出模型声明的字段\n之前由于类不同, 只能用 response_model, 这样就失去了编辑器和类型检查对返回值的检查\n大多数情况下, 我们只是想去掉或过滤掉部分数据, 这时可以用 类继承(classes and inheritance) 来兼顾类型注解和数据过滤\nPYTHON Collapse Copy class BaseUser(BaseModel): username: str email: EmailStr full_name: str | None = None class UserIn(BaseUser): password: str @app.post(\u0026#34;/user/\u0026#34;) async def create_user(user: UserIn) -\u0026gt; BaseUser: return user Click to expand and view more 通过这种方式:\nType Annotations and Testing 编辑器和类型检查工具支持: UserIn 是 BaseUser 的子类, 返回 UserIn 实例完全符合 BaseUser 类型要求 FastAPI Data Filtering 数据过滤: 响应中会自动去掉 password 字段, 只保留 BaseUser 中声明的字段 Other Return Type Annotations 其他类型注解 有些时候, 返回的内容不是有效的 Pydantic 字段, 但在函数中添加了注解, 为了获取工具支持\nReturn a response directly 直接返回响应 最常见的就是直接返回一个 Resposne\nPYTHON Collapse Copy from fastapi import FastAPI, Response from fastapi.resposnes import JSONResponse, RedirectResponse app = FastAPI() @app.get(\u0026#34;/portal\u0026#34;) async def get_protal(teleport: bool = False) -\u0026gt; Response: if teleport: return RedirectResponse(url=\u0026#34;https://www.youtube.com/watch?v=dQw4w9WgXcQ\u0026#34;) return JSONResponse(content={\u0026#34;message\u0026#34;: \u0026#34;Here\u0026#39;s your interdimensional portal.\u0026#34;}) Click to expand and view more 这种简单情况由 FastAPI 自动处理, 因为返回类型注解是 Response 类\n开发工具也能正常工作, 因为 RedirectResponse 和 JSONResponse 都是 Response 的子类, 所以类型注解是正确的\nInvalid return type annotations 无效的类型注解 但是, 当返回一些其他任意对象(不是有效的 Pydantic 类型, 例如数据库对象)并在函数中这样注解时, FastAPI 会尝试从该类型注解创建一个 Pydantic 响应模型, 然后会失败\n如果使用了联合模型, 其中有一个或多个不是有效的 Pydantic 类型, 同样会失败\nPYTHON Collapse Copy from fastapi import FastAPI, Response from fastapi.responses import RedirectResponse app = FastAPI() @app.get(\u0026#34;/portal\u0026#34;) async def get_portal(teleport: bool = False) -\u0026gt; Response | dict: if teleport: return RedirectResponse(url=\u0026#34;https://www.youtube.com/watch?v=dQw4w9WgXcQ\u0026#34;) return {\u0026#34;message\u0026#34;: \u0026#34;Here\u0026#39;s your interdimensional portal.\u0026#34;} Click to expand and view more 这会失败是因为类型注解不是单一的 Pydantic 类型, 也不是单一的 Response 类或子类, 而是 Response 和 dict 之间的联合类型\nDisable response Model 禁用响应类型 如果不希望 FastAPI 执行默认的数据验证、文档生成、过滤等操作, 但是又想在函数中保留返回类型注解, 以获得编辑器和类型检查工具的支持, 这种情况下设置 response_model=None 来禁用响应生成\nPYTHON Collapse Copy from fastapi import FastAPI, Response from fastapi.response import RedirectResponse app = FastAPI() @app.get(\u0026#34;/portal\u0026#34;, response_model=None) async def get_protal(teleport: bool = False) -\u0026gt; Response | dict: if teleport: return RedirectResponse(url=\u0026#34;https://www.youtube.com/watch?v=dQw4w9WgXcQ\u0026#34;) return JSONResponse(content={\u0026#34;message\u0026#34;: \u0026#34;Here\u0026#39;s your interdimensional portal.\u0026#34;}) Click to expand and view more Response Model Encoding Parameters 响应模型编码参数 响应模型可能有默认值\nPYTHON Collapse Copy class Item(BaseModel): name: str description: str | None = None price: float tax: float = 10.5 tags: list[str] = [] Click to expand and view more 例如, 在 NoSQL 数据库中哟许多可选属性的模型, 但不想发送默认值的很长的 JSON 响应\n可以使用 path operation operator 的 response_model_exclude_mode 参数来去除默认值\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;, response_model=Item, response_model_exclude_unset=True) async def read_item(item_id: str): return items[item_id] Click to expand and view more description: str | None = None 默认值为 None tax: float = 10.5 的默认值为 10.5 tags: List[str] = [] 的默认值是空列表 [] 此时, 如果向该路径发送 ID 为 foo 的项目请求\nYAML Collapse Copy \u0026#34;foo\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;price\u0026#34;: 50.2} Click to expand and view more 响应将是\nYAML Collapse Copy { \u0026#34;name\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;price\u0026#34;: 50.2, } Click to expand and view more response_model_include 和 response_model_exclude 也可以使用 path operation parameter 中的 response_model_include 和 response_model_exclude, 他们接受一个包含属性名称字符串的 set, 用于包含(省略其余部分)或排除(包含其余部分)\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str description: str | None = None price: float tax: float = 10.5 items = { \u0026#34;foo\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;price\u0026#34;: 50.2}, \u0026#34;bar\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;Bar\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The Bar fighters\u0026#34;, \u0026#34;price\u0026#34;: 62, \u0026#34;tax\u0026#34;: 20.2}, \u0026#34;baz\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Baz\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;There goes my baz\u0026#34;, \u0026#34;price\u0026#34;: 50.2, \u0026#34;tax\u0026#34;: 10.5, }, } @app.get( \u0026#34;/items/{item_id}/name\u0026#34;, response_model=Item, response_model_include={\u0026#34;name\u0026#34;, \u0026#34;description\u0026#34;}, # 包含 ) async def read_item_name(item_id: str): return items[item_id] @app.get( \u0026#34;/items/{item_id}/public\u0026#34;, response_model=Item, response_model_exclude={\u0026#34;tax\u0026#34;}, # 排除 ) async def read_item_public_data(item_id: str): return items[item_id] Click to expand and view more 虽然可以通过上述方法自定义返回参数包含哪些, 但还是建议使用多个类来实现该功能, 而不这些参数\n这是因为, 即使使用 response_model_include 或 response_model_exclude 来省略某些属性, 在应用程序的 OpenAPI 中生成的 JSON Schema 仍将是完整模型的 Schema\n这对于 response_model_by_alias 也是一样的\nUsing list instead of sets 如果忘记使用集和而使用元组或列表, FastAPI 仍会将其转换为集和, 确保正常工作\nPYTHON Collapse Copy @app.get( \u0026#34;/items/{item_id}/name\u0026#34;, response_model=Item, response_model_include=[\u0026#34;name\u0026#34;, \u0026#34;description\u0026#34;], # 使用列表 ) async def read_item_name(item_id: str): return items[item_id] @app.get( \u0026#34;/items/{item_id}/public\u0026#34;, response_model=Item, response_model_exclude=[\u0026#34;tax\u0026#34;], # 使用列表 ) async def read_item_public_data(item_id: str): return items[item_id] Click to expand and view more Response Status Code 响应状态码 就像可以指定响应模型一样, 也可以在任何路径操作中使用 status_code 参数声明用于响应:\n@app.get() @app.post() @app.put() @app.delete() PYTHON Collapse Copy from fastapi import FastAPI app = FastAPI() @app.post(\u0026#34;/items/\u0026#34;, status_code=201) async def create_item(name: str): return {\u0026#34;name\u0026#34;: name} Click to expand and view more status_code 是\u0026quot;装饰器\u0026quot;方法的一个参数, 而不是你的路径操作函数 path operation function 的参数\nstatus_code 参数接收一个表示 HTTP 状态码的数字, 也可以接收一个 IntEnum, 比如 Python 中的 http.HTTPStatus\n将在响应中返回该状态码 并在 OpenAPI 模式中也如此记录 About HTTP status codes 在 HTTP 协议中, 会在响应中发送一个3位数的数字状态码\n这些状态码又一个相关联的名称便于识别, 但重要的是数字本身\n100~199: 用于\u0026quot;信息\u0026quot;, 很少会直接使用它们, 这些状态码的响应不能有响应体 200~299: 用于\u0026quot;成功\u0026quot;的响应, 这些是最常用的 200 的默认的\u0026quot;成功\u0026quot;响应, 表示一切 OK 201 表示已创建, 通常在数据库中创建新记录后使用 204 表示无内容, 当没有内容返回给客户端时使用此响应, 因此不能有响应体 300~399: 用于\u0026quot;重定向\u0026quot;, 这些状态码的响应可能有也可能没有响应体. 但 304 (未修改) 除外, 它必须没有响应体 400~499: 用于\u0026quot;客户端错误\u0026quot;响应, 404 用于\u0026quot;未找到\u0026quot;的响应 400 客户端通用错误 500~599: 用于服务器错误, 几乎从不直接使用它们. 当的应用代码或服务器的某个部分出错时, 它会自动返回这些状态码之一 要了解更多关于每个状态码的信息以及哪个代码用于什么目的，请查阅 MDN 关于 HTTP 状态码的文档\nShortcut to remember the names 除了直接使用数字外, 还可以使用 fastapi.status 中的便捷变量\nPYTHON Collapse Copy from fastapi import FastAPI, status app = FastAPI() @app.post(\u0026#34;/items/\u0026#34;, status_code=status.HTTP_201_CREATED) async def create_item(name: str): return {\u0026#34;name\u0026#34;: name} Click to expand and view more 这只是一直便利, 都是一样的树枝, 但这样可以使用编辑器的自动补全功能\n也可以使用 from starlette import status\n","title":"FastAPI Response Model"},{"link":"/posts/fastapi-cookie-and-header-parameters/","text":"这篇文章介绍 Fastapi 的 Cookie 和 Header 参数\nCookie Parameters 通过定义 Query 和 Path 参数一样定义 Cookie 参数\nPYTHON Collapse Copy from typing Annotated from fastapi import Cookie, FastAPI app = FastAPI() @app.get(\u0026#34;/items/\u0026#34;) async def read_items(ads_id: Annotated[str | None, Cookie()] = None): return {\u0026#34;ads_id\u0026#34;: ads_id} Click to expand and view more Cookie Parameters Models 如果有一组相关的 cookies, 可以使用 Pydantic model 来声明.\n这样可以在多个部分复用这个模型, 同时还能一次性为所有参数声明验证规则和元数据.\n下面使用 Pydantic 模型定义 Cookies, 然后将参数声明为 Cookie\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Cookie from pydantic import BaseModel app = FastAPI() class Cookie(BaseModel): session_id: str fatebook_tracker: str | None = None googall_tracker: str | None = None @app.get(\u0026#34;/items/\u0026#34;) async def read_items(cookies: Annotated[Cookies, Cookie()]): return cookies Click to expand and view more Forbid Extra Cookies 禁止额外的Cookie 在某些场景下(虽然并不常见), 可能希望限制 API 只能接收特定的 Cookie. 这样, API 就可以\u0026quot;自己\u0026quot;管理 Cookie 同意策略了.\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Cookie from pydantic import BaseModel app = FastAPI() class Cookies(BaseModel): model_config = {\u0026#34;extra\u0026#34;: \u0026#34;forbid\u0026#34;} # forbid extra cookies session_id: str fatebook_tracker: str | None = None googall_tracker: str | None = None @app.get(\u0026#34;/items/\u0026#34;) async def read_items(cookies: Annotated[Cookies, Cookie()]): return cookies Click to expand and view more 这样, 如果客户端发送额外的 cookies, 则会收到一个错误响应. 例如, 客户端发送了 santa_tracker 这个额外 Cookie\nPYTHON Collapse Copy santa_tracker = good-list-please Click to expand and view more 将会收到如下错误响应\nJSON Collapse Copy { \u0026#34;detail\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;extra_forbidden\u0026#34;, \u0026#34;loc\u0026#34;: [\u0026#34;cookie\u0026#34;, \u0026#34;santa_tracker\u0026#34;], \u0026#34;msg\u0026#34;: \u0026#34;Extra inputs are not permitted\u0026#34;, \u0026#34;input\u0026#34;: \u0026#34;good-list-please\u0026#34;, } ] } Click to expand and view more Header Parameters 同样的, 通过定义 Query 和 Path 参数一样定义 Header 参数\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Header app = FastAPI() @app.get(\u0026#34;/items/\u0026#34;) async def read_items(user_agent: Annotated[str | None, Header()] = None): return {\u0026#34;User-Agent\u0026#34;: user_agent} Click to expand and view more Automatic conversoin 自动转换 Header 拥有一些在 Path, Query 和 Cookie 上的额外功能\n大多数标准的 header 都通过一个连字符(hyphen character), 也称为减号(minus symbol)分开, 但是变量 user-agent 这样在 Python 中是不合法的. 所以, 默认情况下 Header 会将参数名中的 hypen(-) 使用下划线 undersocre(_) 替换.\n同样的, HTTP headers 是不区分大小写的, 所以可以使用标准的 Python 风格 (snake_case). 因此可以使用 user_agent 在 Python 代码中, 而不需要首字母大写成 User_Agent.\n如果想要禁止这种自动转换, 需要将 Header 的参数 convert_undersocres 设置为 False\nPYTHON Collapse Copy from typing import Typing from fastapi import FastAPI, Header app = FastAPI() @app.get(\u0026#34;/items/\u0026#34;) async def read_items( strange_header: Annotated[str | None, Header(convert_undersocres=False)] = None ): return {\u0026#34;strange_header\u0026#34;: strange_header} Click to expand and view more Duplicate headers 重复请求头 一个请求中可能会收到重复的 headers, 也就是同一个 header 有多个值.\n可以在类型声明中使用 list 来处理这种情况, 这样会得到一个 Python 列表.\n例如要声明一个可能多次出现的 X-Token 头部, 可以这样写:\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Header app = FastAPI() @app.get(\u0026#34;/items/\u0026#34;) async def read_items(x_token: Annotated[list[str] | None, Header()] = None): return {\u0026#34;X-Token values\u0026#34;: x_token} Click to expand and view more 如果向该接口发送两个这样的 HTTP headers\nPLAINTEXT Collapse Copy X-Token: foo X-Token: bar Click to expand and view more 返回类似这样\nJSON Collapse Copy { \u0026#34;X-Token values\u0026#34;: [ \u0026#34;bar\u0026#34;, \u0026#34;foo\u0026#34; ] } Click to expand and view more Header parameters models 请求头参数模型 同样可以使用 Pydantic model 定义 Header Parameters, 这样可以在多个地方复用模型, 还能一次性为所有参数声明规则和元数据\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Header from pydantic import BaseModel app = FastAPI() class CommonHeaders(BaseModel): host: str save_data: str if_modified_since: str | None = None traceparent: str | None = None x_tag: list[str] = [] @app.get(\u0026#34;/items\u0026#34;) async def read_items(headers: Annotated[CommonHeaders, Header()]): return headers Click to expand and view more Forbid extra headers 禁止额外请求头 同样也可以禁止额外的 headers\nPYTHON Collapse Copy class CommonHeaders(BaseModel): model_config = {\u0026#34;extra\u0026#34;: \u0026#34;forbid\u0026#34;} # 禁止额外字段 ... Click to expand and view more 如果客户端尝试发送额外的 Header，将会收到错误响应. 例如, 客户端发送了 tool 这个额外 Header\nPLAINTEXT Collapse Copy tool: plumbus Click to expand and view more 将会收到如下错误响应\nJSON Collapse Copy { \u0026#34;detail\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;extra_forbidden\u0026#34;, \u0026#34;loc\u0026#34;: [\u0026#34;header\u0026#34;, \u0026#34;tool\u0026#34;], \u0026#34;msg\u0026#34;: \u0026#34;Extra inputs are not permitted\u0026#34;, \u0026#34;input\u0026#34;: \u0026#34;plumbus\u0026#34; } ] } Click to expand and view more Disable convert undersocres 禁止转换下划线 同样可以禁用自动下换线转换\n与普通的 Header 参数一样, 如果参数名中包含下划线 undersocre (_), FastAPI 会自动将其转换为连字符 hypens (-)\nPYTHON Collapse Copy async def read_items( headers: Annotated[CommonHeaders, Header(convert_underscores=False)], ): ... Click to expand and view more 在将 convert_underscores 设置为 False 前, 注意有些 HTTP 代理和服务器不允许带下划线的头部字段\n","title":"Fastapi Cookie and Header Parameters"},{"link":"/posts/python-function-parameters/","text":"今天是周日, 简单写点吧, 简单总结一下 Python 中函数参数\nPython Function Parameters Python 函数参数机制非常灵活丰富, 理解各种参数类型及其用法对于写出优雅、易维护的代码非常重要. 本文将介绍 Python 中函数参数的种类与用法, 并详细讲解 Python 3.8 引入的参数分隔符 / 和 *, 帮助你更好地设计函数接口.\n1. Postional Arguments 位置参数 函数定义中最常见的参数, 调用时按顺序传入值\nPYTHON Collapse Copy def greet(name, age): print(f\u0026#34;Hello, {name}. You are {age} years old.\u0026#34;) greet(\u0026#34;Alice\u0026#34;, 30) # Hello, Alice. You are 30 years old. Click to expand and view more 2. Keyword Arguments 关键字参数 调用时以 key=value 形式传入, 顺序可变\nPYTHON Collapse Copy greet(age=30, name=\u0026#34;Alice\u0026#34;) Click to expand and view more 3. Default Arguments 默认参数 定义函数时给参数赋默认值, 调用时可省略\nPYTHON Collapse Copy def greet(name, age=20): print(f\u0026#34;Hello, {name}. You are {age} years old.\u0026#34;) greet(\u0026#34;Bob\u0026#34;) # 使用默认年龄20 greet(\u0026#34;Bob\u0026#34;, 25) # 指定年龄 Click to expand and view more 注意: 使用默认参数尽量不要使用可变类型(mutable), 例如列表, 因为默认参数是存储在函数中的, 而非函数实例中, 多次调用会改变默认值的内容. PYTHON Collapse Copy def greet(names: list[str] = [\u0026#34;Alice\u0026#34;, \u0026#34;Bob\u0026#34;]): ... Click to expand and view more 若希望使用默认值, 建议使用下面这种方法\nPYTHON Collapse Copy def greet(names: list[str] | None = None): if not names: names = [\u0026#34;Alice\u0026#34;, \u0026#34;Bob\u0026#34;] ... Click to expand and view more 同样的, 默认值参数如果为一个表达式, 则是在定义时求值, 而非运行改函数时才求值\n4. *args 可变位置参数 用于接收任意数量的位置参数, 形成元组\nPYTHON Collapse Copy def sum_all(*args): return sum(args) sum_all(1, 2, 3) # 6 sum_all() # 0 Click to expand and view more 5. **kwargs 可变关键字参数 用于接收任意数量的关键字参数, 形成字典\nPYTHON Collapse Copy def print_info(**kwargs): for k, v in kwargs.items(): print(f\u0026#34;{k} = {v}\u0026#34;) print_info(name=\u0026#34;Alice\u0026#34;, age=30) Click to expand and view more / 和 * 的用法 Python 3.8 引入了两种新的函数参数分隔符: 斜杠 /(forward slash) 和 星号 *(asterisk) 符号, 用于更精细地控制参数的调用方式\nPostional-only parameters (/) 斜杠前的参数必须通过位置传递, 不能用关键字传递\nPYTHON Collapse Copy def func(a, b, /, c, d): print(a, b, c, d) Click to expand and view more 调用时\nPYTHON Collapse Copy func(1, 2, c=3, d=4) # 正确 func(1, 2, 3, 4) # 也正确 func(a=1, b=2, c=3, d=4) # 错误，a 和 b 不能用关键字传递 Click to expand and view more 用途:\n保护函数接口的参数顺序, 避免调用者用关键字修改参数值 兼容一些C语言扩展模块的调用约定 明确哪些参数是\u0026quot;位置专用\u0026quot;的 Keyword-only parameters (*) 星号后的参数必须用关键字传递, 不能用位置传递\nPYTHON Collapse Copy def func(a, b, *, c, d): print(a, b, c, d) Click to expand and view more 调用时\nPYTHON Collapse Copy func(1, 2, c=3, d=4) # 正确 func(1, 2, 3, 4) # 错误，c 和 d 只能用关键字传递 Click to expand and view more 用途:\n强制调用者明确指定关键字参数, 提高代码可读性 避免参数顺序引起的混淆 Use both / and * / 和 * 也可以同时使用\nPYTHON Collapse Copy def func(a, b, /, c, d, *, e, f): print(a, b, c, d, e, f) Click to expand and view more 调用时\na 和 b 只能用位置参数传递 c 和 d 都可以 e 和 f 只能用关键字参数传递 ","title":"Python Function Parameters"},{"link":"/posts/fastapi-body-advanced-uses/","text":"本篇文章介绍 FastAPI Request Body 的进阶用法\nBody - Multiple Parameters 首先, 可以将Path, Query 和 request body 参数声明自由的写在一起\n对于 request body 参数可以是可选的, 并且可设置为默认的 None\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Path from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str description: str | None = None price: float tax: float | None = None @app.put(\u0026#34;/items/{item_id}\u0026#34;) async def update_item( item_id: Annotated[int, Path(title=\u0026#34;The ID of the item to get\u0026#34;, ge=0, le=1000)], # Path q: str | None = None, # Query item: Item | None = None, # body ): results = {\u0026#34;item_id\u0026#34;: item_id} if q: results.update({\u0026#34;q\u0026#34;: q}) if item: results.update({\u0026#34;item\u0026#34;: item}) return results Click to expand and view more Multiple body parameters 多参数请求体 在上面例子中, FastAPI 期望一个包含 Item 属性的 JSON body, 例如\nJSON Collapse Copy { \u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The pretender\u0026#34;, \u0026#34;price\u0026#34;: 42.0, \u0026#34;tax\u0026#34;: 3.2 } Click to expand and view more 但也可以声明多个body parameters, 例如 item 和 user\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str description: str | None = None price: float tax: float | None = None class User(BaseModel): username: str full_name: str | None = None @app.put(\u0026#34;/items/{item_id}\u0026#34;) async def update_item(item_id: int, item: Item, user: User): results = {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;item\u0026#34;: item, \u0026#34;user\u0026#34;: user} return results Click to expand and view more 在这种情况下, FastAPI 会检测到函数有一个 body parameter, 这时会使用中的参数名作为请求体的 key(field names), 并期望如下结构:\nJSON Collapse Copy { \u0026#34;item\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The pretender\u0026#34;, \u0026#34;price\u0026#34;: 42.0, \u0026#34;tax\u0026#34;: 3.2 }, \u0026#34;user\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;dave\u0026#34;, \u0026#34;full_name\u0026#34;: \u0026#34;Dave Grohl\u0026#34; } } Click to expand and view more FastAPI 会自动进行请求解析、类型转换、验证, 并在 OpenAPI 文档中反映出这种结构\nSingular values in body 请求体中的单个参数 和 Query 、Path 可以添加额外信息一样, FastAPI 也提供了 Body 来对请求参数添加额外信息\n例如, 除了 item 和 user 外, 还想在请求体中添加一个 importance 字段, 如果直接写 importance: int 则会被当作查询参数\n可以通过 Body() 明确告诉 FastAPI 把它当作一个 body parameter\nPYTHON Collapse Copy @app.put(\u0026#34;/items/{item_id}\u0026#34;) async def update_item( item_id: int, item: Item, user: User, importance: Annotated[int, Body()] ): ... Click to expand and view more 这种情况下, FastAPI 会期待如下的请求体:\nJSON Collapse Copy { \u0026#34;item\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The pretender\u0026#34;, \u0026#34;price\u0026#34;: 42.0, \u0026#34;tax\u0026#34;: 3.2 }, \u0026#34;user\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;dave\u0026#34;, \u0026#34;full_name\u0026#34;: \u0026#34;Dave Grohl\u0026#34; }, \u0026#34;importance\u0026#34;: 5 } Click to expand and view more 它同样会自动转换数据类型、校验并生成文档\nMultiple body params and query 多个请求体参数和查询参数 也可以在多请求体参数的基础上, 添加查询参数\nPYTHON Collapse Copy @app.put(\u0026#34;/items/{item_id}\u0026#34;) async def update_item( *, # 强制 key=value item_id: int, item: Item, user: User, importance: Annotated[int, Body(gt=0)], q: str | None = None, # 查询参数 ): ... Click to expand and view more Embed a single body parameter 嵌入单个请求体参数 假设只有一个请求体参数 item: Item, 默认情况下 FastAPI 期望请求体就是一个 Item 对应的结构\nJSON Collapse Copy { \u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The pretender\u0026#34;, \u0026#34;price\u0026#34;: 42.0, \u0026#34;tax\u0026#34;: 3.2 } Click to expand and view more 但若希望如下带有 itemkey 的结构\nJSON Collapse Copy { \u0026#34;item\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The pretender\u0026#34;, \u0026#34;price\u0026#34;: 42.0, \u0026#34;tax\u0026#34;: 3.2 } } Click to expand and view more 那么可以使用 Body(embed=True)\nPYTHON Collapse Copy @app.put(\u0026#34;/items/{item_id}\u0026#34;) async def update_item( item_id: int, item: Annotated[ Item, Body(embed=True), # embed a single param ] ): ... Click to expand and view more 这将使 FastAPI 将请求体视为嵌套结构, key 为 item\nBody - Fields 除了可以在 path operation (路径操作)函数参数中使用 Query、Path和Body来声明额外的验证和数据, 还可以在 Pydantic 模型内部的 Field 的字段验证规则和元数据\nDeclare model attributes 声明模型字段属性 首先要导入 Filed\nPYTHON Collapse Copy from pydantic import BaseModel, Field # import Filed Click to expand and view more 可以在模型字段上使用 Filed 来添加验证规则和信息\nPYTHON Collapse Copy class Item(BaseModel): name: str description: str | None = Field( default=None, title=\u0026#34;项目的描述\u0026#34;, max_length=300 ) price: float = Field(gt=0, description=\u0026#34;价格必须大于 0\u0026#34;) tax: float | None = None Click to expand and view more 实际上, Query、Path 和其他类, 都继承自一个公共的 Param 类, 而 Param 是 Pydantic 的 FieldInfo 类的子类, pydantic.Field() 返回的就是一个 FieldInfo 实例\nBody - Nested Models 在 FastAPI 中, 可以定义、校验、文档化并使用任意深度嵌套的模型\nList fields 列表字段 可以将字段定义为某种子类型, 例如 Python 的 list\nPYTHON Collapse Copy class Item(BaseModel): name: str description: str | None = None price: float tax: float | None = None tags: list = [] # list Click to expand and view more List fields with type parameter 带类型参数的列表字段 Python 提供一种\u0026quot;类型参数\u0026quot;的方法, 来指定列表类型\nPYTHON Collapse Copy # Python 3.10+ tags: list[str] = [] Click to expand and view more 对于py3.10之前的版本, 需要使用 typing 模块\nPYTHON Collapse Copy tags: List[str] = [] Click to expand and view more Set types 集和类型 如果不希望 tages 重复, 则使用 set 更加合适\nPYTHON Collapse Copy class Item(BaseModel): ... tags: set[str] = set() Click to expand and view more 这样即使客户端传来重复元素, FastAPI 也会自动去重并返回一个唯一元素集合\nNested Models 嵌套模型 Pydantic 的每个字段都可以是另一模型, 从而形成嵌套结构\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class Image(BaseModel): url: str name: str class Item(BaseModel): ... image: Image | None = None @app.put(\u0026#34;/items/{item_id}\u0026#34;) async def update_item(item_id: int, item: Item): return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;item\u0026#34;: item} Click to expand and view more 此时的 FastAPI 会期望请求体为如下结构:\nJSON Collapse Copy { \u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The pretender\u0026#34;, \u0026#34;price\u0026#34;: 42.0, \u0026#34;tax\u0026#34;: 3.2, \u0026#34;tags\u0026#34;: [\u0026#34;rock\u0026#34;, \u0026#34;metal\u0026#34;, \u0026#34;bar\u0026#34;], \u0026#34;image\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://example.com/baz.jpg\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;The Foo live\u0026#34; } } Click to expand and view more 这样使用 FastAPI 会获得:\n编辑器自动补全 类型转换 数据校验 自动生成文档 Special types and validation 特殊类型与验证 除了像 str, int, float 这类 singular types, 还可以使用更加负责的继承于 str 的 singular types, 全部类型可以在 Pydantic\u0026rsquo;s Type Overview 查看\n下面是 HttpUrl 的例子\nPYTHON Collapse Copy from pydantic import HttpUrl class Image(BaseModel): url: HttpUrl name: str Click to expand and view more 这样会检查 JSON schema 中的 url 是否合法, 并在 OpenAPI 文档中显示\nAttributes with lists of submodels 带有子模型属性的列表 PYTHON Collapse Copy class Image(BaseModel): url: HttpUrl name: str class Item(BaseModel): name: str description: str | None = None price: float tax: float | None = None tags: set[str] = set() images: list[Image] | None = None # lists of submodels Click to expand and view more 此时 FastAPI 会期望请求体有一个 images 字段, 为 Image 对象的列表\nJSON Collapse Copy { \u0026#34;name\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The pretender\u0026#34;, \u0026#34;price\u0026#34;: 42.0, \u0026#34;tax\u0026#34;: 3.2, \u0026#34;tags\u0026#34;: [ \u0026#34;rock\u0026#34;, \u0026#34;metal\u0026#34;, \u0026#34;bar\u0026#34; ], \u0026#34;images\u0026#34;: [ { \u0026#34;url\u0026#34;: \u0026#34;http://example.com/baz.jpg\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;The Foo live\u0026#34; }, { \u0026#34;url\u0026#34;: \u0026#34;http://example.com/dave.jpg\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;The Baz\u0026#34; } ] } Click to expand and view more Deeply nested models 深度嵌套模型 可以定义任意深度的嵌套模型\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel, HttpUrl app = FastAPI() class Image(BaseModel): url: HttpUrl name: str class Item(BaseModel): name: str description: str | None = None price: float tax: float | None = None tags: set[str] = set() images: list[Image] | None = None class Offer(BaseModel): name: str description: str | None = None price: float items: list[Item] @app.post(\u0026#34;/offers/\u0026#34;) async def create_offer(offer: Offer): return offer Click to expand and view more Bodies of pure lists 纯列表请求体 如果请求体的顶层是一个数组(例如上传多个图片), 可以直接将参数类型声明为列表:\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel, HttpUrl app = FastAPI() class Image(BaseModel): url: HttpUrl name: str @app.post(\u0026#34;/images/multiple/\u0026#34;) async def create_multiple_images(images: list[Image]): return images Click to expand and view more Bodies of arbitrary dictS 任意字典作为请求体 可以声明请求体为一个字典 (键和值都可指定类型)\nPYTHON Collapse Copy @app.post(\u0026#34;/index-weights/\u0026#34;) async def create_index_weights(weights: dict[int, float]): return weights Click to expand and view more 虽然 JSON 标准只支持字符串作为 key, 但 Pydantic 会自动将字符串形式的数字转换为 int 因此, 如果客户端发送 { \u0026quot;1\u0026quot;: 0.1, \u0026quot;2\u0026quot;: 0.2 }, 接收到的将是 {1: 0.1, 2: 0.2} ","title":"FastAPI Body Advanced Uses"},{"link":"/posts/git-whitelist/","text":"有时你开启了一个新的项目, 运行了 cargo init、uv init 和 go mod init\n这些命令创建了工作所需要的必要文件, 同时也在 .gitignore 文件中添加了以下内容\nPLAINTEXT Collapse Copy target __pycache__ bin Click to expand and view more 一切都很顺利, 你继续开发新功能, 等到时机成熟时就将项目发布到了 Git 托管平台上\n人们开始对你的项目感兴趣, 甚至有人决定为你实现一个新功能, 这简直是免费劳动力!\n当你查看代码, 发现了一个格格不入的文件 .DS_Store, 你问那个人这是什么, 他说他根本不知道\n然后你只是将该文件从分支里面删除, 并把文件名加入了仓库的 .gitignore\nPLAINTEXT Collapse Copy target __pycache__ bin .DS_Store Click to expand and view more 现在代码合并到了 main, 仓库里只包含有用的内容\n接着, 另一人使用基于 Web 技术的 IDE 提交了另一个合并请求, 一看发现有一个完全无关的目录也被提交了, 于是 .gitignore 里又增加了一条内容\nPLAINTEXT Collapse Copy target __pycache__ bin .DS_Store .vscode Click to expand and view more 接下来, 有人使用 IntelliJ IDEA 提交了五百个 XML 文件和 .idea 目录, 这时又不得不将其加入 .gitignore\nPLAINTEXT Collapse Copy target __pycache__ bin .DS_Store .vscode .idea Click to expand and view more 多年后, .gitignore 已经有了上百行, 但是仍然时不时有各种奇怪的文件, 例如 testscripts、foo、a、qux、data.tar.gz、start.sh、cat \u0026hellip;\u0026hellip;\n你就像西西弗斯一样, 因欺骗死亡和冥界而受到永无止境的惩罚\n西西弗斯推着一块写着 .DS_Store 的巨石艰难上山\n如何改变偷偷溜进来的文件循环呢? 去教育每一个提交合并请求的人肯定不行, 得通过自动化工具解决, 而不是主观沟通\n幸运的是, 可以将这个黑名单变成白名单, 可以通过默认忽略所有文件, 然后只手动“取消忽略”明确允许的文件\nPLAINTEXT Collapse Copy * !.gitignore # 白名单：任意位置下的 src 目录及其子文件夹 !src/ !src/**/ !src/**/*.rs !Cargo.{toml,lock} # 白名单：项目根目录下的 pysrc 目录 !/pysrc/ !/pysrc/*.py !pyproject.toml !uv.lock !/cmd/ !/cmd/*.go !main.go !go.{mod,sum} !/docs/ !/docs/*.md Click to expand and view more 现在, 没人再能不小心提交不该提交的文件了. Git 会自动忽略所有文件, 只允许那些明确列入白名单的文件.\n这种做法也具备一定的“面向未来”的能力——当然, 前提是以后不会有某个 IDE 把 src/ide.rs 当成保存项目配置的理想文件路径, 但愿那一天永远不会到来\u0026hellip;\n","title":"Git Whitelist"},{"link":"/posts/fastapi-parameters-and-validations/","text":"这篇文章介绍 FastAPI 中的参数验证功能\nQuery Parameters and String Validations FastAPI 允许为参数声明额外的信息和验证规则\nPYTHON Collapse Copy from fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/items/\u0026#34;) async def read_items(q: str | None = None): results = {\u0026#34;items\u0026#34;: [{\u0026#34;item_id\u0026#34;: \u0026#34;Foo\u0026#34;}, {\u0026#34;item_id\u0026#34;: \u0026#34;Bar\u0026#34;}]} if q: results.update({\u0026#34;q\u0026#34;: q}) return results Click to expand and view more q 是类型为 str | None 的查询参数, 这意味着它可以是字符串, 也可以是 None. 其默认值是 None, 因此 FastAPI 会识别它为“可选参数”\nFastAPI 通过 = None 的默认值知道该参数是非必填的\n使用 str | None 还能帮助编辑器提供更好的类型提示和错误检测\nAdditional validation 额外验证 即使 q 是可选的, 但仍然可以设置条件: 如果提供了 q, 则长度不能超过50个字符\n使用 Query 和 Annotated 来实现\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Query app = FastAPI() @app.get(\u0026#34;/items/\u0026#34;) async def read_items(q: Annotated[str | None, Query(max_length=50)] = None): results = {\u0026#34;items\u0026#34;: [{\u0026#34;item_id\u0026#34;: \u0026#34;Foo\u0026#34;}, {\u0026#34;item_id\u0026#34;: \u0026#34;Bar\u0026#34;}]} if q: results.update({\u0026#34;q\u0026#34;: q}) return results Click to expand and view more 使用 Annotated 包装后, 就可以传递额外的元数据(Query(max_length=5)), 用于校验或者文档\n注意: 使用 Annotated 的时候，不能在 Query() 中再次使用 default\n❌ 错误写法 PYTHON Collapse Copy q: Annotated[str, Query(default=\u0026#34;rick\u0026#34;)] = \u0026#34;morty\u0026#34; Click to expand and view more ✅ 正确写法 PYTHON Collapse Copy q: Annotated[str, Query()] = \u0026#34;rick\u0026#34; Click to expand and view more 使用 Annotated 有以下优点\n默认值直接写在函数参数上，更符合 Python 风格 该函数在非 FastAPI 环境中调用时也能正常工作 类型检查器能更准确提示 可复用于如 Typer 等其它框架 Annotated 可附加多个元数据 More Validations 更多验证 也可以添加参数 min_length\nPYTHON Collapse Copy @app.get(\u0026#34;/items/\u0026#34;) async def read_items( q: Annotated[str | None, Query(min_length=3, max_length=50)] = None, ): ... Click to expand and view more regular expressions 正则表达式\nPYTHON Collapse Copy @app.get(\u0026#34;/items/\u0026#34;) async def read_items( q: Annotated[ str | None, Query(min_length=3, max_length=50, pattern=\u0026#34;^fixedquery$\u0026#34;) ] = None, ): ... Click to expand and view more ^: 以后面字符串开始, 之前没有其他字符串\nfixedquery: 完全匹配的单词\n$: 在此结束, 之后没有更多字符\ndefault values 默认值\n除了 None, 也可以设置其他默认值\nPYTHON Collapse Copy q: Annotated[str, Query(min_length=3)] = \u0026#34;fixedquery\u0026#34; Click to expand and view more reuqired parameters 必填参数\n如果想让参数 q 是必填的, 不设置默认值即可\nPYTHON Collapse Copy q: Annotated[str, Query(min_length=3)] Click to expand and view more 即使参数可以为 None, 但仍强制要求传值\nPYTHON Collapse Copy q: Annotated[str | None, Query(min_length=3)] Click to expand and view more query parameter list / multiple values 参数列表/多个值\n可以接收多个值的查询参数\nPYTHON Collapse Copy @app.get(\u0026#34;/items/\u0026#34;) async def read_items(q: Annotated[list[str] | None, Query()] = None): query_items = {\u0026#34;q\u0026#34;: q} return query_items Click to expand and view more 访问如下 URL\nPLAINTEXT Collapse Copy http://localhost:8000/items/?q=foo\u0026amp;q=bar Click to expand and view more 将得到多个 q 查询参数值, URL response 将如下\nJSON Collapse Copy { \u0026#34;q\u0026#34;: [\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;] } Click to expand and view more 若不使用 Query(), FastAPI 会把 list[str] 当成 request body (请求体)\nDeclare more metadata 添加更多元信息 这些信息会出现在 OpenAPI 文档中\nPYTHON Collapse Copy q: Annotated[str | None, Query( title=\u0026#34;查询字符串\u0026#34;, description=\u0026#34;用于数据库中模糊搜索匹配的查询字符串\u0026#34;, min_length=3 )] = None Click to expand and view more Alias parameters 参数别名 有时想使用一个在 Python 中非法的别名, 例如 item-query\nPLAINTEXT Collapse Copy http://127.0.0.1:8000/items/?item-query=foobaritems Click to expand and view more 最接近的变量名为 item_query, 但是 item-query 不能为变量名\n此时, 可以使用别名 alias\nPYTHON Collapse Copy q: Annotated[str | None, Query(alias=\u0026#34;item-query\u0026#34;)] = None Click to expand and view more Deprecating parameters 弃用参数 想标记某个参数已被弃用, 可以加上\nPYTHON Collapse Copy Query(..., deprecated=True) Click to expand and view more Exclude parameters from OpenAPI 从OpenAPI中隐藏参数 可以设置参数不出现在自动生成的文章中\nPYTHON Collapse Copy hidden_query: Annotated[str | None, Query(include_in_schema=False)] = None Click to expand and view more Custom validation 自定义校验 若内建参数不够用, 可以使用 Pydantic v2 的 AfterValidator\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import AfterValidator from typing import Annotated def check_valid_id(id: str): if not id.startswith((\u0026#34;isbn-\u0026#34;, \u0026#34;imdb-\u0026#34;)): raise ValueError(\u0026#34;Invalid ID format, 必须以 \u0026#39;isbn-\u0026#39; 或 \u0026#39;imdb-\u0026#39; 开头\u0026#34;) return id @app.get(\u0026#34;/items/\u0026#34;) async def read_items( id: Annotated[str | None, AfterValidator(check_valid_id)] = None, ): if id: team = data.get(id) else: id, item = random.choice(list(data.items())) return {\u0026#34;id\u0026#34;: id, \u0026#34;name\u0026#34;: item} Click to expand and view more value.startswith((\u0026quot;isbn-\u0026quot;, \u0026quot;imdb-\u0026quot;)) 可以一次检查多个前缀 random.choice(list(data.items())) 取出随机的键值对 Path Parameters and Numberic Validations 和使用 Query 查询参数声明更多验证规则和元数据一样, 也可以使用 Path 为路径参数声明相同类型的规则验证和元数据\nImport Path 导入路径 首先, 从 fastapi 中导入 Path, 并导入 Annotated\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Path, Query app = FastAPI() @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_items( item_id: Annotated[int, Path(title=\u0026#34;要获取的物品 ID\u0026#34;)], q: Annotated[str | None, Query(alias=\u0026#34;item-query\u0026#34;)] = None, ): results = {\u0026#34;item_id\u0026#34;: item_id} if q: results.update({\u0026#34;q\u0026#34;: q}) return results Click to expand and view more Declare metadata 声明元数据 可以像在 Query 中一样声明所有的参数\nPYTHON Collapse Copy item_id: Annotated[int, Path(title=\u0026#34;要获取的物品 ID\u0026#34;)] Click to expand and view more ⚠️ 路径参数总是必填的, 它必须作为路径的一部分存在. 即使将它设为 None 或指定默认值, 也不会生效, 它仍然是必须的\nOrder the parameters 自由排序参数 如果希望 query parameter 声明为必填的 str, 并且不需要声明任何其他事情, 那么不需要用 Query() 包裹\n但是对于 path parameter item_id 仍然需要使用 Path, 并且出于一些原因并不像使用 Annotated\n如果将有 defalult 默认值的参数, 放到没有默认值参数前面, 那么 Python 会报错, 所以要这样声明函数\nPYTHON Collapse Copy from fastapi import FastAPI, Path app = FastAPI() @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_items(q: str, item_id: int = Path(title=\u0026#34;要获取的物品 ID\u0026#34;)): results = {\u0026#34;item_id\u0026#34;: item_id} if q: results.update({\u0026#34;q\u0026#34;: q}) return results Click to expand and view more 但是, 如果使用 Annotated 就不会有这个顺序的问题, 因为默认值并不写在函数参数中\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_items( q: str, item_id: Annotated[int, Path(title=\u0026#34;要获取的物品 ID\u0026#34;)] ): ... Click to expand and view more Order the parameters tricks 参数顺序技巧 如果不想使用 Annotated, 但是又想:\n为查询参数 q 不使用 Query, 也不设置默认值 为路径参数 item_id 使用 Path 两个参数顺序任意 不想用 Annotated 那可以使用一个小技巧: 在函数参数前面加一个星号 *\n作用是: 告诉 Python, 后面所有参数必须作为关键字参数传入 (即使用key=value的方法, 不能省略参数名)\nPYTHON Collapse Copy async def read_items(*, item_id: int = Path(title=\u0026#34;The ID of the item to get\u0026#34;), q: str): ... Click to expand and view more Better with Annotated 推荐使用Annotated 如果使用 Annotated, 由于不是用参数默认值来传递 Path()、Query(), 就不需要使用*这种语法\nPYTHON Collapse Copy # Python 3.9+ async def read_items( item_id: Annotated[int, Path(title=\u0026#34;The ID of the item to get\u0026#34;)], q: str ): ... Click to expand and view more Number Validations 数字验证 在 FastAPI 中, 可以通过 Path()、Query() (以及其他参数类) 为数值类型参数添加约数条件, 有以下四种:\ngt: greater than (大于) ge: greater than or equal (大于等于) lt: less than (小于) le: less than or equal (小于等于) 这些验证适用于路径参数(path parameter)和查询参数(query parameter), 并且支持 int 和 float 类型\n整数验证示例 (Path 参数)\n使用 ge=1 表示 item_id 必须是一个大于等于1的整数\nPYTHON Collapse Copy from typing import Annotated from fastapi import FastAPI, Path app = FastAPI() @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_items( item_id: Annotated[int, Path(title=\u0026#34;要获取的项目 ID\u0026#34;, ge=1)], q: str ): return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;q\u0026#34;: q} Click to expand and view more 也可以通过 ge 和 le 同时限制一个整数的区间范围\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_items( item_id: Annotated[int, Path(title=\u0026#34;要获取的项目 ID\u0026#34;, gt=0, le=1000)], q: str ): return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;q\u0026#34;: q} Click to expand and view more 浮点数验证示例 (Query 参数)\n浮点类型的校验同样适用. 例如, 使用 gt 可以确保值 严格大于 0\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_items( *, item_id: Annotated[int, Path(title=\u0026#34;项目 ID\u0026#34;, ge=0, le=1000)], q: str, size: Annotated[float, Query(gt=0, lt=10.5)], ): return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;q\u0026#34;: q, \u0026#34;size\u0026#34;: size} Click to expand and view more item_id 必须在 [0, 1000] 区间内 size 必须在 (0, 10.5) 区间内 ","title":"FastAPI Parameters and Validations"},{"link":"/posts/fastapi-parameters/","text":"FastAPI 是一个现代、快速（高性能）的 Python Web 框架, 它自动处理参数的解析、验证和文档生成\n本文将介绍 FastAPI 中三类最常用的参数: 路径参数 (Path Parameters)、查询参数 (Query Parameters) 和 请求体(Request Body) 的用法与原理\n1. Path Parameters 路径参数 路径参数是 URL 路径中的动态部分, 使用 {} 包裹表示\nPYTHON Collapse Copy from fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_item(item_id: str): return {\u0026#34;item_id\u0026#34;: item_id} Click to expand and view more 访问 /items/foo 返回:\nPYTHON Collapse Copy {\u0026#34;item_id\u0026#34;: \u0026#34;foo\u0026#34;} Click to expand and view more Data conversion \u0026amp; validation 类型声明与自动转换 可以为路径参数声明类型, FastAPI 会自动解析并验证:\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_item(item_id: int): return {\u0026#34;item_id\u0026#34;: item_id} Click to expand and view more 访问 /items/3, item_id 会被转换为 int 类型\nRouting orders 路由匹配顺序 路径匹配按声明顺序执行, 例如\nPYTHON Collapse Copy @app.get(\u0026#34;/users/me\u0026#34;) async def read_user_me(): return {\u0026#34;user_id\u0026#34;: \u0026#34;current_user\u0026#34;} @app.get(\u0026#34;/users/{user_id}\u0026#34;) async def read_user(user_id: str): return {\u0026#34;user_id\u0026#34;: user_id} Click to expand and view more 必须先声明 /users/me, 否则会被 /users/{user_id} 捕获\nPredefined enum values 预定义枚举值 使用 Python 的 Enum 定义一组可选的路径参数值\nPYTHON Collapse Copy from enum import Enum class ModelName(str, Enum): alexnet = \u0026#34;alexnet\u0026#34; resnet = \u0026#34;resnet\u0026#34; lenet = \u0026#34;lenet\u0026#34; @app.get(\u0026#34;/models/{model_name}\u0026#34;) async def get_model(model_name: ModelName): return {\u0026#34;model_name\u0026#34;: model_name} Click to expand and view more Swagger 文档会自动显示可选值\nPath parameters containing paths 路径型参数 默认路径参数不能包含斜杠 /, 但可以用 :path 声明允许匹配完整路径\nPYTHON Collapse Copy @app.get(\u0026#34;/files/{file_path:path}\u0026#34;) async def read_file(file_path: str): return {\u0026#34;file_path\u0026#34;: file_path} Click to expand and view more 访问 /files/home/user/file.txt, file_path 会是 \u0026quot;home/user/file.txt\u0026quot;\n2. Query Parameters 查询参数 查询参数是 URL ? 后的键值对, 不属于路径部分\nPYTHON Collapse Copy fake_items_db = [{\u0026#34;item_name\u0026#34;: \u0026#34;Foo\u0026#34;}, {\u0026#34;item_name\u0026#34;: \u0026#34;Bar\u0026#34;}] @app.get(\u0026#34;/items/\u0026#34;) async def read_items(skip: int = 0, limit: int = 10): return fake_items_db[skip : skip + limit] Click to expand and view more 访问 /items/?skip=0\u0026amp;limit=10 时, 会自动把查询参数 skip 和 limit 转成 int\nOptional parameters 可选参数默认值 给查询参数赋默认值即为可选\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_item(item_id: str, q: str | None = None): if q: return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;q\u0026#34;: q} return {\u0026#34;item_id\u0026#34;: item_id} Click to expand and view more q 是可选查询参数, 默认为 None\nQuery parameter type conversion 查询参数类型转换 PYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_item(item_id: str, q: str | None = None, short: bool = False): ... Click to expand and view more 支持自动把字符串转换成布尔值, 以下都会被识别为 True\nPLAINTEXT Collapse Copy http://127.0.0.1:8000/items/foo?short=1 Click to expand and view more 或者\n?short=true ?short=on ?short=yes Multiple path and query parameters 多路径查询参数组合 路径参数和查询参数可混合使用, 无需声明顺\nPYTHON Collapse Copy @app.get(\u0026#34;/users/{user_id}/items/{item_id}\u0026#34;) async def read_user_item(user_id: int, item_id: str, q: str | None = None, short: bool = False): ... Click to expand and view more Required query parameters 必填查询参数 未设置默认值的查询参数为必填参数\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_item(item_id: str, needy: str): ... Click to expand and view more 上面的 needy 就是一个必填的 str 类型\n当然也可以定义一些必填参数, 以及有默认值的可选参数\nPYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_user_item( item_id: str, needy: str, skip: int = 0, limit: int | None = None ): ... Click to expand and view more needy \u0026amp; item_id, 必填 str 类型 skip, 默认值为 0 的类型 limit, 一个可选的类型 [注]\n路径参数永远是必填的, 因为它们来自 URL 本身 PYTHON Collapse Copy @app.get(\u0026#34;/items/{item_id}\u0026#34;) def read(item_id: str = \u0026#34;123\u0026#34;): # 这里写默认值是无效的 ... Click to expand and view more 类型为 Optional[...] 或 type | None 不等于可选参数, 仍然要配合默认值 = None 才是可选 PYTHON Collapse Copy def func(x: int | None): # 必填 def func(x: int | None = None): # 可选 Click to expand and view more 3. Request Body 当通过 API 传送数据的时候, 通常通过 request body 发送\nrequest body 是 client 客户端发送给 API 的数据, 而 response body 是 API 发送给 client 的数据\nPydantic\u0026rsquo;s BaseModel 使用 Pydantic 定义数据模型\nPYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel class Item(BaseModel): name: str description: str | None = None price: float tax: float | None = None app = FastAPI() @app.post(\u0026#34;/items/\u0026#34;) async def create_item(item: Item): return item Click to expand and view more Declare it as a parameter 在路由中声明请求体\nPYTHON Collapse Copy @app.post(\u0026#34;/items/\u0026#34;) async def create_item(item: Item): return item Click to expand and view more FastAPI 会:\n读取 request body, 并转换为 JSON 校验字段和类型 返回类型错误时给出详细反馈, 包括数据那里以及导致了什么错误 提供编辑器类型提示 生成模型的 JSON Schema 定义, 也可以在项目中任何位置使用 根据 schema 自动生成文档 Request body + path + query parameters 路径参数、查询参数与请求体同时使用 PYTHON Collapse Copy @app.put(\u0026#34;/items/{item_id}\u0026#34;) async def update_item(item_id: int, item: Item, q: str | None = None): result = {\u0026#34;item_id\u0026#34;: item_id, **item.dict()} if q: result.update({\u0026#34;q\u0026#34;: q}) return result Click to expand and view more 这个函数参数会被以下方式识别:\n如果参数同时在 path 中声明, 被当成 path parameter 如果参数为单一类型, 如 int, float, str 或 bool 等, 将会被解释为 query parameter 如果参数声明为一个 Pydantic Model, 将被解释为 request body ","title":"FastAPI Parameters"},{"link":"/posts/python-tricks/","text":"1. The Self-Replicating Trick 将一个含有空列表的列表乘5, 得到有5个空列表的列表\nPYTHON Collapse Copy x = [[]] * 5 x Click to expand and view more [[], [], [], [], []]\n当使用.append(\u0026quot;x\u0026quot;)方法时, 所有列表都被修改\nPYTHON Collapse Copy x[0].append(\u0026#34;x\u0026#34;) x Click to expand and view more [[\u0026ldquo;x\u0026rdquo;], [\u0026ldquo;x\u0026rdquo;], [\u0026ldquo;x\u0026rdquo;], [\u0026ldquo;x\u0026rdquo;], [\u0026ldquo;x\u0026rdquo;]]\n打印其 id 可以看到, id 都相同\nPYTHON Collapse Copy for item in x: print(id(item)) Click to expand and view more 4417579584\n4417579584\n4417579584\n4417579584\n4417579584\n或者使用set()发现 id 唯一\nPYTHON Collapse Copy set(id(item) for item in x) Click to expand and view more {4417579584}\n也就是说, 当使用乘法的时候, 创建了5个内部列表的引用副本\n使用反汇编发现, 只创建了两个列表, 并执行乘5\nPYTHON Collapse Copy dis.dis(\u0026#34;[[]] * 5\u0026#34;) 0 0 RESUME 0 # 用于支持解释器恢复 (py3.11) 1 2 BUILD_LIST 0 # 构造一个空列表[], 压栈 4 BUILD_LIST 1 # 从栈顶取一个对象, 构造列表[[]] 6 LOAD_CONST 0 (5) # 加载常量 5 8 BINARY_OP 5 (*) # 对栈顶两个元素执行乘法 12 RETURN_VALUE # 返回栈顶结果 Click to expand and view more The alternative 如果要构造独立列表, 应改用列表推导式\nPYTHON Collapse Copy x = [[] for _ in range(5)] x Click to expand and view more [[], [], [], [], []]\nPYTHON Collapse Copy for item in x: print(id(item)) Click to expand and view more 4587832384\n4587818752\n4587831168\n4587839168\n4587809152\nPYTHON Collapse Copy set(id(item) for item in x) Click to expand and view more {4587809152, 4587818752, 4587831168, 4587832384, 4587839168}\n2. The Teleportation Trick PYTHON Collapse Copy def add_to_shopping_list(item, shopping_list=[]): shopping_list.append(item) return shopping_list Click to expand and view more 上面函数为一个空列表中添加一个 item, 期望每次创建一个新的空列表, 并添加一个item\nPYTHON Collapse Copy groceries = add_to_shopping_list(\u0026#34;Bread\u0026#34;) groceries Click to expand and view more [\u0026lsquo;Bread\u0026rsquo;]\nPYTHON Collapse Copy books = add_to_shopping_list(\u0026#34;A Brief History of Time\u0026#34;) books Click to expand and view more [\u0026lsquo;Bread\u0026rsquo;, \u0026lsquo;A Brief History of Time\u0026rsquo;]\n然而, \u0026lsquo;Bread\u0026rsquo; 被传送到 books 里面去了\n下面不使用默认参数, 测试一下函数\nPYTHON Collapse Copy cakes = [] cakes = add_to_shopping_list(\u0026#34;Chorolate Cake\u0026#34;, cakes) cakes Click to expand and view more [\u0026lsquo;Chorolate Cake\u0026rsquo;]\nPYTHON Collapse Copy tools = [] tools = add_to_shopping_list(\u0026#34;Snapper\u0026#34;, tools) tools Click to expand and view more [\u0026lsquo;Snapper\u0026rsquo;]\n当传入一个存在的列表时, 没有发生传送行为\n回到函数定义: 默认参数的列表, 在函数定义的时候已经被创建了, 因此每次使用该函数而不传入列表参数的时候, 默认列表shopping_list就会被使用, 且 list 是一个可变类型, 因此每次会修改这个列表\n使用下面方法, 每次打印出使用列表的 id, 会发现不传入列表参数时的 id 都相同\nPYTHON Collapse Copy def add_to_shopping_list(item, shopping_list=[]): print(id(shopping_list)) shopping_list.append(item) return shopping_list Click to expand and view more The alternative 这个 bug 在使用可变类型(mutable)作为默认参数的时候都会发生, 应该避免可变数据类型作为默认参数\n如果想要默认值参数, 可以考虑使用 None 作为参数默认值\nPYTHON Collapse Copy def add_to_shopping_list(item, shopping_list=None): if shopping_list is None: shopping_list = [] shopping_list.append(item) return shopping_list Click to expand and view more The Vanishing Trick 下面是最后一个 trick\nPYTHON Collapse Copy doubles = (number * 2 for number in range(10)) 4 in doubles # True 4 in doubles # False Click to expand and view more 上面结果看起来很矛盾, 4 怎么一会儿在 doubles 中, 一会儿又不再 doubles 中?\n再来看一个例子\nPYTHON Collapse Copy another_doubles = [number * 2 for number in range(10)] 4 in another_doubles # True 4 in another_doubles # True Click to expand and view more 上面这个例子中, 就都是 True\n问题出在, 当使用括号()创建 doubles 的时候, 并不是创建了元组 tuple, 而是一个生成器 generator\nPYTHON Collapse Copy doubles = (number ** 2 for number in range(10)) doubles Click to expand and view more \u0026lt;generator object at 0x111718e10\u0026gt;\n生成器并不会包含所有的值, 而是在使用的时候生成每个值\n例如, 调用 next() 会返回下一个值\nPYTHON Collapse Copy next(doubles) # 0 next(doubles) # 1 next(doubles) # 2 next(doubles) # 4 ... next(doubles) # 18 next(doubles) Click to expand and view more StopIteration Traceback (most recent call last)\n生成器是一次型的数据结构, 当生成下一个数据的时候, 之前的数据不会被保存, 也就是只能遍历数据一次\n一但遍历完成, 就会报StopIteration的错误, 所以当运行4 in doubles的时候, 先得到0, 为 False, 生成器会继续遍历下一个, 直到得到4, 当再次调用的时候, 下一个返回6, 直到遍历结束也无法得到到4\n同样的行为在迭代器 iterator 上也一样\nPYTHON Collapse Copy numbers = [2, 4, 6, 8] numbers_rev = reversed(numbers) numbers_rev # \u0026lt;list_reverseiterator object at 0x......\u0026gt; 4 in numbers_rev # True 4 in numbers_rev # False Click to expand and view more The alternative 如果使用生成器, 要知道只能遍历每个元素一次, 如果要获得一个有所有元素的数据结构, 应该使用元素 tuple 或列表 list\nPYTHON Collapse Copy doubles = (number * 2 for number in range(10)) # generator more_doubles = tuple(number * 2 for number in range(10)) # tuple 4 in more_doubles # True 4 in more_doubles # True Click to expand and view more ","title":"Python Tricks"},{"link":"/posts/executing-arbitrary-python-code-from-a-comment/","text":"通过注释执行任意Python代码\n问题描述 Q: 只能控制一行的.py代码中注释的内容(\\n\\r均会被替换为空字符), 如何执行任意代码?\nA: 在注释#中, 构造一个.zip 文件, python 会将该内容当成一个zip包执行, 触发任意代码执行\n解决方案 从 Python 3.5 起, 可以直接执行一个 .zip 文件\nPYTHON3 Collapse Copy python myapp.zip Click to expand and view more 前提是ZIP 包中包含一个顶层的__main__.py文件, Python 会把它当作 zipapp, 自动解压并运行__main__.py\nPython 会从末尾找到 ZIP 的目录结构, 而不是依赖文件头, 所以前面的“垃圾”字节会被忽略\nPython 源码中的任何行, 只要以 # 开头, 解释器都会忽略后面内容, 因此可以:\n把 ZIP 文件的数据藏在 Python 源码中的注释中（开头加 #） 把 ZIP 数据直接拼接在 Python 文件的后面, 只保证文件头部分是合法 Python ZIP 不关心前缀, Python 只要最前面是有效源码, 也不会管后面 难点 ZIP 文件头包含二进制字段，比如\n偏移量（文件数据相对于 ZIP 开头的位置） 长度（文件名长度、注释长度等） 这些值写死在 header 里, 是十六进制整数 如果这些字节中出现了像 \\x00、\\xFF 等非 ASCII 内容, Python 就不能把它当注释 解决方法: 暴力穷举合法组合\n想办法 调整偏移值和结构位置，使得最终写出来的 ZIP 文件\n所有的字段值都转化为 可打印字符（ASCII 范围内） 所有 binary 字段看起来都像合法的注释字符串 于是用 itertools.product(range(256), repeat=2) 暴力尝试偏移组合，只要碰巧生成的 ZIP 包所有关键字节都在可打印范围内（ASCII 32~126），就认为成功。 下面是generate_polygloy_zip.py代码, 会生成一个符合要求的polygloy.py代码, 最后运行该代码, 可以执行Body里面的内容BODY = b\u0026quot;print('FROM MAIN.py FILE!!!')#\u0026quot;\nPYTHON3 Collapse Copy # struct: 按字节结构打包数据，方便构造 ZIP 文件二进制头 # itertools: 用来暴力枚举 CRC 校验和后缀（确保安全ASCII） # zlib: 计算 CRC32 校验和 import struct, itertools, zlib # 文件开头代码 # encode(): Unicode 字符串 -\u0026gt; bytes 字节串 JUNK_HEAD = \u0026#34;\u0026#34;\u0026#34;print(\u0026#34;Hello World!\u0026#34;) # This is a comment. Here\u0026#39;s another: # \u0026#34;\u0026#34;\u0026#34;.encode() # 文件结尾代码 JUNK_TAIL = \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Thanks for playing!\u0026#34;)\u0026#34;\u0026#34;\u0026#34; # zip 文件核心代码 # b: 字节串 FILENAME = b\u0026#34;__main__.py\u0026#34; BODY = b\u0026#34;print(\u0026#39;FROM MAIN.py FILE!!!\u0026#39;)#\u0026#34; # 校验 CRC 是否为 ASCII-safe def ascii_safe(x: int) -\u0026gt; bool: return all(((x \u0026gt;\u0026gt; (8*i)) \u0026amp; 0x80) == 0 for i in range(4)) # 检查 32 位整数的四个字节，每个字节最高位（0x80）是否为 0，即是否为 ASCII 范围内的字节 def find_suffix(core: bytes, length: int = 4) -\u0026gt; tuple[bytes, int]: \u0026#34;\u0026#34;\u0026#34; - ZIP 文件 CRC32 计算结果必须 ASCII-safe（低于 0x80） - 这里用暴力方法，给 payload 后面加4字节后缀，找到合适的后缀让 CRC32 满足 ASCII-safe 条件 \u0026#34;\u0026#34;\u0026#34; printable = range(0x20, 0x7f) for tail in itertools.product(printable, repeat=length): payload = core + bytes(tail) crc = zlib.crc32(payload) \u0026amp; 0xFFFFFFFF if ascii_safe(crc): return bytes(tail), crc raise RuntimeError(\u0026#34;No ASCII-safe CRC found.\u0026#34;) # 计算最终 payload SUFFIX, CRC = find_suffix(BODY) PAYLOAD = BODY + SUFFIX SIZE = len(PAYLOAD) def le32(x): return struct.pack(\u0026#34;\u0026lt;I\u0026#34;, x) # 4字节小端无符号整数 def le16(x): return struct.pack(\u0026#34;\u0026lt;H\u0026#34;, x) # 2字节小端无符号整数 # ZIP 结构中各签名常量 SIG_LFH = 0x04034B50 # 本地文件头 Local File Header SIG_CDH = 0x02014B50 # 中央目录头 Central Directory Header SIG_EOCD = 0x06054B50 # 结束目录头 End of Central Directory # zip 文件偏移量设置 delta = len(JUNK_HEAD) # 构建 Local File Header \u0026#34;\u0026#34;\u0026#34; Local File Header 是 ZIP 格式中的一部分，告诉解压程序该文件的元信息 - version needed to extract，flags，compression method 等字段置 0 表示无压缩，简单存储 - CRC32、压缩大小、解压大小都是我们计算的 - 文件名长度和文件名 \u0026#34;\u0026#34;\u0026#34; lfh = ( le32(SIG_LFH) + le16(0) + le16(0) + le16(0) + le16(0) + le16(0) + le32(CRC) + le32(SIZE) + le32(SIZE) + le16(len(FILENAME)) + le16(0) + FILENAME ) # 构建 Central Directory Header \u0026#34;\u0026#34;\u0026#34; - Central Directory 是 ZIP 文件目录结构，记录每个文件信息和偏移， - 其中重要的是 relative offset of LFH，也就是 Local File Header 在整个 ZIP 文件里的偏移，必须加上 delta \u0026#34;\u0026#34;\u0026#34; cdh = ( le32(SIG_CDH) + le16(0) + le16(0) + le16(0) + le16(0) + le16(0) + le16(0) + le32(CRC) + le32(SIZE) + le32(SIZE) + le16(len(FILENAME)) + le16(0) + le16(0) + le16(0) + le16(0) + le32(0) + le32(delta) + FILENAME ) # 确保偏移量 ASCII-safe \u0026#34;\u0026#34;\u0026#34; - ZIP 目录偏移需要是 ASCII 字节，否则写入 .py 文件时会出错 - 这里通过填充若干 \\x00 字节，保证偏移合法 \u0026#34;\u0026#34;\u0026#34; cd_offset = delta + len(lfh) + len(PAYLOAD) pad = 0 while not ascii_safe(cd_offset + pad): pad += 1 padding = b\u0026#39;\\x00\u0026#39; * pad cd_offset += pad # 构建 End of Central Directory Header \u0026#34;\u0026#34;\u0026#34; EOCD 记录 ZIP 中央目录大小、偏移及注释长度等信息 \u0026#34;\u0026#34;\u0026#34; eocd = ( le32(SIG_EOCD) + le16(0) + le16(0) + le16(1) + le16(1) + le32(len(cdh)) + le32(cd_offset) + le16(len(JUNK_TAIL)) ) # 拼接完整 ZIP 内容 zip_bytes = lfh + PAYLOAD + padding + cdh + eocd zip_bytes = bytearray(zip_bytes) assert all(b \u0026lt; 0x80 for b in zip_bytes), \u0026#34;非 ASCII 字节存在\u0026#34; # 写入 polyglot.py 文件 with open(\u0026#34;polyglot.py\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(JUNK_HEAD + zip_bytes + JUNK_TAIL.encode()) # 运行提示 print(\u0026#34;✅ polyglot.py 生成完毕。运行它即可执行嵌入的 __main__.py 内容：\u0026#34;) print(\u0026#34; $ python3 polyglot.py\u0026#34;) Click to expand and view more ","title":"Executing arbitrary Python code from a comment"},{"link":"/posts/how-fastapi-works/","text":"FastAPI 的工作原理: 从 routing 到 lifecycle 以及在现实中的使用\nFastAPI FastAPI 是一个现代的 Python Web 框架, 注重高性能和开发效率. 旨在帮助开发者编写结构清晰、可靠的API, 同时尽量减少样板代码 (boilerplate)\n其由以下两个库驱动:\nStarlette: 负责 Web 服务器逻辑、路由、中间件和异步能力 Pydantic: 基于 Python 类型提示, 处理数据验证、解析和序列化 此外, Fastapi 还有输入验证、基于 Swagger UI 的自动文档生成和代码清晰化的基础\nAPI 请求周期 Fastapi 的请求生命周期如下\nPLAINTEXT Collapse Copy 客户端请求 (Client Request) ↓ FastAPI App ↓ 中间件（Middleware） ↓ 路由匹配 (Route Matching) ↓ 依赖注入（Dependency Injection） ↓ 输入验证 (Input Validation) ↓ 端点函数 (Endpoint) ↓ 响应序列化 (Response Serialization) ↓ 客户端响应 (Client Response) Click to expand and view more 请求首先进入 FastAPI 应用 (本质就是一个 Starlette 应用) 所有中间件优先执行 (如: 日志、错误处理、CORS等) 路由器检查路径和方法, 找到对应的处理函数 FastAPI 使用Depends解析依赖 使用 Pydantic 自动解析并验证输入数据 执行端点函数, 参数验证完毕 返回结果被序列化为合适的响应格式 (JSON) 响应返回给客户端 路由 Router 在应用对象上定义\n适合小项目或原型验证 PYTHON Collapse Copy from fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/items/{item_id}\u0026#34;) def read_item(): return {\u0026#34;item_id\u0026#34;: item_id} Click to expand and view more 使用 APIRouter 模块化\n适合大项目 PYTHON Collapse Copy from fastapi import FastAPI router = APIRouter(prefix=\u0026#34;/users\u0026#34;, tags=[\u0026#34;users\u0026#34;]) @router.get(\u0026#34;/{user_id}\u0026#34;) def get_user(user_id: int): return {\u0026#34;user_id\u0026#34;: user_id} Click to expand and view more 使用APIRouter可以将相关的端点分组, 添加前缀和标签, 保持代码结构清晰模块化 当某个请求与端点匹配时, FastAPI 内部执行一下步骤:\nStarlette 找到对应路由, 并创建一个APIRouter实例 FastAPI 使用get_router_header()包装端点函数并解析依赖 使用 Pydantic 或基本类型对请求数据解析与验证 装饰函数被调用, 传入验证后的参数 返回值被序列化为响应对象 依赖注入: 干净、可复用的逻辑 FastAPI 有一个轻量且强大的依赖注入系统, 可以进行数据库链接、身份验证信息或配置信息等\nPYTHON Collapse Copy from fastapi import Depends def get_db(): db = create_db_session() try: yield db finally: db.close() @app.get(\u0026#34;/items/\u0026#34;) def read_items(db=Depends(get_db)): return db.query(item).all() Click to expand and view more 使用Depends, FastAPI 会负责调用get_db, 处理生成器生命周期, 并将结果注入到函数中\n原生支持异步 (Async) 不同于一些后加入 async 的框架, FastAPI 一开始就设计为支持 async/await\nPYTHON Collapse Copy from fastapi import FastAPI import asyncio app = FastAPI() @app.get(\u0026#34;/hi\u0026#34;) async def greet(): await asyncio.sleep(1) return \u0026#34;Hello? World?\u0026#34; Click to expand and view more 当 fastapi 收到 /hi 这个 URL 的 GET 请求时，会自动调用 async greet(), 无需在任何地方添加 await\n但是, 对于其他的 async def 函数, 调用的时候必须在前面加上 await\nFastAPI 会运行一个异步事件循环，用于执行异步路径函数(async path functions)，同时也会使用一个线程池来处理同步函数(synchronous path functions), 这样就不需要手动调用 asyncio.gather() 和 asyncio.run() 之类的方法\n示例: CURD API PYTHON Collapse Copy from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str description: str = None price: float tax: float = None @app.post(\u0026#34;/items/\u0026#34;) async def create_item(item: Item): total = item.price + (item.tax or 0) return {\u0026#34;name\u0026#34;: item.name, \u0026#34;total_price\u0026#34;: total} @app.get(\u0026#34;/\u0026#34;) def read_root(): return {\u0026#34;message\u0026#34;: \u0026#34;FastAPI is working!\u0026#34;} Click to expand and view more 运行\nPLAINTEXT Collapse Copy uvicorn main:app --reload Click to expand and view more 还可以使用 Gunicorn 部署4个 Uvicorn 异步服务 PLAINTEXT Collapse Copy gunicorn main:app --workers 4 --worker-class \\ uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000 Click to expand and view more 实际上也可以直接诶使用 uvicorn 运行多个进程, 但是这样无法进行进程管理，因此使用 gunicorn 的方法一般更多被使用 性能提升 如果 API 返回大量数据, 使用 ORJSON 加快序列化速度\nPYTHON Collapse Copy from fastapi import FastAPI from fastapi.responses import ORJSONResponse app = FastAPI(default_response_class=ORJSONResponse) Click to expand and view more ","title":"How FastAPI Works"},{"link":"/posts/chaos-enginnering-in-partice/","text":"记录一个小故事 HHH\n“混沌工程”实践 项目延期，开发说时间不够干不完 老板：“不够就招人”\n今天偶然听到旁边同事给新来的员工做code review：\nQ：你这个代码不要这样写，因为\u0026hellip;\u0026hellip; A：哦，懂了 Q：唉？你这个 .idea/ 文件是什么？ A：啊？我也不知道 我：不是???(一脸震惊) 理想：Plan Do Check Act\n现实：Plan Delay Cancel Apologize\n","title":"\"Chaos Enginnering\" In Partice"},{"link":"/posts/blaugust/","text":"🎈 Oh hello, August! It\u0026rsquo;s time for Blaugust.\nBlaugust Begins: Writing as a Develpoer Habit This year, I\u0026rsquo;m joining Blaugust - a month-long blogging challenge that encourage consistent writing throught August. For develpoers, blogging isn\u0026rsquo;t just sharing, it\u0026rsquo;s about orgainzing thoughts, documenting ideas, and creating term references.\nWhat I Plan to Write Here is what I aim to cover this month:\nDaily dev partices: tools, logging, project structure patterns Python ecosystem: FastAPI, Pydantic, Langchain, Pytest and more AI project logs: buliding AI agents and orchestration workflows Architecture notes: async patterns, micorservice, data flow Learning notes \u0026amp; translation of blogs: deep dive into code and quality tech atricles I\u0026rsquo;m not necessarily writing one post per day - some days I might write multiple posts in advance - but the goal is to publish daily with a focus on consistency, reusability, and value.\nWriting Platform and Setup This blog is build with Hugo + Github Pages, using the narrow theme. Markdown keeps things simple, and version control is headled vai Git.\nRSS feed is available (blogroll exchange is welcome!)\nIf you\u0026rsquo;re blogging too or joining Blaugust, feel free to connect 👋 ","title":"Blaugust"},{"link":"/posts/dive-into-deeplearning-02-preliminaries/","text":" Course Note: d2l-video-05 - 线性代数 Jupyter Notebook: chapter_preliminaries/linear-algebra.ipynb 预备知识中 Liner Algebra 的部分\n线性代数 Scalars 标量: 指只有一个元素的张量 tensors\nPYTHON Collapse Copy import torch x = torch.tensor(3.0) # scalar y = torch.tensor(2.0) Click to expand and view more Vectors 向量: 可以视作标量构成的列表\nPYTHON Collapse Copy x = torch.arange(4) x[3] # 通过张量索引访问任一元素 len(x) # 访问张量长度 x.shape # torch.Size([4]) 只有一个轴的张量, 形状只有一个元素 Click to expand and view more Matrices 矩阵: 类似向量的推广, 可以构建更多轴的数据结构\nPYTHON Collapse Copy # 构建矩阵 A = torch.arange(20).reshape(5, 4) A.T # 转置 # 对称矩阵 B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) B = B.T Click to expand and view more 形状相同张量的计算\nPYTHON Collapse Copy A = torch.arange(20, dtype=torch.float32).reshape(5, 4) B = A.clone() A, A + B A * B # 对应元素相乘: Hadamard 积 Click to expand and view more 计算元素的和\nPYTHON Collapse Copy x = torch.arange(4, detype=torch.float64) x.sum() # 任意形状张量的和 Click to expand and view more 计算平均值\nPYTHON Collapse Copy A.mean() # 均值 A.sum() / A.numel() # 另一种计算均值的方法: 和 / 数量 Click to expand and view more 点乘是相同位置元素乘积的和\nPYTHON Collapse Copy x = torch.tensor([0., 1., 2., 3.]]) y = torch.tensor([1., 1., 1., 1.]]) torch.dot(x, y) # torch(6.) # 或者通过元素乘法, 求和表示点积 torch.sum(x * y) # torch(6.) Click to expand and view more 降维: axis 指定沿着哪一个轴来降低纬度\n假如现在有个张量A如下\nPLAINTEXT Collapse Copy tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.], [16., 17., 18., 19.]]) Click to expand and view more 现在沿着第0轴, 通过求和降低纬度\nPYTHON Collapse Copy A_sum_axis0 = A.sum(axis=0) A_sum_axis0, A_sum_axis0.shape Click to expand and view more 输出如下\n上面降维的原理就是, 由于axis=0, 就将最外层的纬度去掉, 原来 A.shape=torch.Size([5, 4]), 现在变成了A_sum_axis0=torch.Size([4])\nPLAINTEXT Collapse Copy (tensor([40., 45., 50., 55.]), torch.Size([4])) Click to expand and view more 类似的, 还可以降低多个纬度\nPYTHON Collapse Copy A.sum(axis=[0, 1]) Click to expand and view more 由于A就两个轴, 两个轴都被降低就成了标量\nPLAINTEXT Collapse Copy tensor(190.) Click to expand and view more 此外, 还可以保持纬度不变, 将要降的纬度变成1\nPYTHON Collapse Copy sum_A = A.sum(axis=1, keepdims=True) # keepdims=True 不丢掉原来的纬度 Click to expand and view more 输出如下:\n原来 A.shape=torch.Size([5, 4]) 现在变成了sum_A.shape=torch.Size([5,1])\nPLAINTEXT Collapse Copy tensor([[ 6.], [22.], [38.], [54.], [70.]]) Click to expand and view more 这种机制常用于广播, 广播要求纬度相同, 例如 A / sum_A 的计算结果如下\nPLAINTEXT Collapse Copy tensor([[0.0000, 0.1667, 0.3333, 0.5000], [0.1818, 0.2273, 0.2727, 0.3182], [0.2105, 0.2368, 0.2632, 0.2895], [0.2222, 0.2407, 0.2593, 0.2778], [0.2286, 0.2429, 0.2571, 0.2714]]) Click to expand and view more 还可以通过某个轴计算A元素的累积总和 A.cumsum(axis=0)\nPLAINTEXT Collapse Copy tensor([[ 0., 1., 2., 3.], [ 4., 6., 8., 10.], [12., 15., 18., 21.], [24., 28., 32., 36.], [40., 45., 50., 55.]]) Click to expand and view more Norms 范数\n范数可以理解为\u0026quot;向量的长度/大小\u0026quot;的一种度量方式,\n向量范数 L1范数, 它表示为向量元素的绝对值之和 (曼哈顿距离)\nPYTHON Collapse Copy torch.abs(u).sum() Click to expand and view more L2范数是向量元素平方和的平方根 (欧几里德距离)\nPYTHON Collapse Copy u = torch.tensor([3.0, -4.0]) torch.norm(u) Click to expand and view more 矩阵范数: 最小的满足下面公式的值 $$ c = A \\cdot b \\quad \\text{hence} \\quad |c| \\leq |A| \\cdot |b| $$\n矩阵的Frobenius范数(Frobenius norm)是矩阵元素平方和的平方根\n$$ |A|_{Frob} = \\left(\\sum_{i,j} A_{ij}^2 \\right)^{\\frac{1}{2}} $$\nPYTHON Collapse Copy torch.norm(torch.ones((4, 9))) Click to expand and view more ","title":"Dive into DeepLearning - 02 - Preliminaries"},{"link":"/posts/dive-into-deeplearning-01-preliminaries/","text":" Course Note: d2l-video-04 - 数据操作+数据预处理 Jupyter Notebook: chapter_preliminaries/pandas.ipynb 预备知识中 Data Manipulation 和 Data Preprocessing 的部分\n介绍 N 纬数组介绍\n0-d (标量)\nPLAINTEXT Collapse Copy 1.0 Click to expand and view more 一个类别\n1-d (向量)\nPLAINTEXT Collapse Copy [1.0, 2.7, 3.4] Click to expand and view more 一个特征向量\n2-d (矩阵)\nPLAINTEXT Collapse Copy [[1.0, 2.7, 3.4], [1.0, 2.7, 3.4], [1.0, 2.7, 3.4]] Click to expand and view more 一个样本 - 特征矩阵\n3-d RGB 图片(宽 x 高 x 通道)\nPLAINTEXT Collapse Copy [[[1.0, 2.7, 3.4], [1.0, 2.7, 3.4], [1.0, 2.7, 3.4]], [[1.0, 2.7, 3.4], [1.0, 2.7, 3.4], [1.0, 2.7, 3.4]]] Click to expand and view more 4-d 一个 RGB 图片批量 (批量大小 x 宽 x 高 x 通道)\nPLAINTEXT Collapse Copy [[[[... ... ...]]]] Click to expand and view more 5-d 一个视屏批量 (批量大小 x 时间 x 宽 x 高 x 通道)\nData Manipulation 数据操作 张量(tensor)表示一个数值表示的数组, 这个数组可能有多个纬度, 下面介绍一下 pytorch 里面基础的张量运算\n创建张量\nPYTHON Collapse Copy import torch x = torch.arange(12) shape = x.shape # 元素形状 num = x.numel() # 元素总数 X = x.reshape(3, 4) # 改变张量形状 Click to expand and view more 生成张量\nPYTHON Collapse Copy torch.zeros((2, 3, 4)) # 形状为 2x3x4 的全0张量 torch.ones((2, 3, 4)) # 形状为 2x3x4 的全1张量 torch.randn(3, 4) # 形状为 3 x 4 的随机张量 torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) # 通过py数组生成张量 Click to expand and view more 张量运算\nPYTHON Collapse Copy x = torch.tensor([1.0, 2, 4, 8]) # .0 表示为浮点数, 会转换为浮点数张量, 而不是整数 y = torch.tensor([2, 2, 2, 2]) x + y, x - y, x * y, x / y, x ** y # 对应位置的元素进行标准运算 Click to expand and view more 按照行 或 列 连结(concatenate) 在一起\nPYTHON Collapse Copy X = torch.arange(12, dtype=torch.float32).reshape((3,4)) # shape: 3x4 Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) # shape: 3x4 torch.cat((X, Y), dim=0) # 第0纬(外层)连结: 变成6x8 torch.cat((X, Y), dim=1) # 第1纬(内存)连结: 变成3x8 Click to expand and view more 通过逻辑运算符构建二元张量\nPYTHON Collapse Copy X == Y Click to expand and view more 张量所有元素求和\nPYTHON Collapse Copy X.sum() Click to expand and view more 即使形状不同, 仍然可以通过调用 广播机制(broadcasting mechanism) 来执行按元素操作\nPYTHON Collapse Copy # 使用 广播机制(broadcasting mechanism) 将形状不同的元素相加 a = torch.arange(3).reshape((3, 1)) b = torch.arange(2).reshape((1, 2)) # 将 a 3x2 复制为 3x2 的矩阵 # 将 b 1x2 复制为 3x2 的矩阵 a + b Click to expand and view more 选择元素\nPYTHON Collapse Copy X[-1], X[1:3] # 使用下标, 切片获取元素 X[1, 2] = 9 # 使用指定索引修改元素 X[0:2, :] = 12 # 为多个元素复制 (第一纬度中的 0,1 全部赋值为12) Click to expand and view more 内存相关\n内存重新分配\nPYTHON Collapse Copy before = id(Y) Y = Y + X # 这里加法导致Y内存重新分配 id(Y) == before # False Click to expand and view more 执行原地操作\nPYTHON Collapse Copy Z = torch.zeros_like(Y) print(\u0026#39;id(Z):\u0026#39;, id(Z)) # 使用X[:] = X + Y或X += Y来减少操作的内存开销 Z[:] = X + Y print(\u0026#39;id(Z):\u0026#39;, id(Z)) # 与上 print 输出相同 before = id(X) X += Y id(X) == before # True Click to expand and view more 类型转换\n转换为NumPy张量 (ndarray)\nPYTHON Collapse Copy A = X.numpy() B = torch.tensor(A) type(A), type(B) #\u0026gt; (numpy.ndarray, torch.Tensor) Click to expand and view more 将大小为1的张量转换为Python标量\nPYTHON Collapse Copy a = torch.tensor([3.5]) a, a.item(), float(a), int(a) #\u0026gt; (tensor([3.5000]), 3.5, 3.5, 3) Click to expand and view more Data Preprocessing 数据预处理 csv 全称 Comma-Seperated Values 即逗号分开的值, 是一种文本文件格式, 用来存储表格数据, 数据项之间通常用逗号分隔, 行与行之间用换行符分隔. 实际上, 可以使用其他符号, 例如;来做分隔符\n下面通过一个读取csv文件的例子, 说明如何将csv中的数据读入 pytorch\n首先构造一个csv文件\nPYTHON Collapse Copy import os os.makedirs(os.path.join(\u0026#39;..\u0026#39;, \u0026#39;data\u0026#39;), exist_ok=True) data_file = os.path.join(\u0026#39;..\u0026#39;, \u0026#39;data\u0026#39;, \u0026#39;house_tiny.csv\u0026#39;) with open(data_file, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;NumRooms,Alley,Price\\n\u0026#39;) f.write(\u0026#39;NA,Pave,127500\\n\u0026#39;) f.write(\u0026#39;2,NA,106000\\n\u0026#39;) f.write(\u0026#39;4,NA,178100\\n\u0026#39;) f.write(\u0026#39;NA,NA,140000\\n\u0026#39;) Click to expand and view more 从创建的文件中加载原始数据集\nPYTHON Collapse Copy import pandas as pd data = pd.read_csv(data_file) print(data) Click to expand and view more 会得到如下表格(第一列索引不是表格内容)\nNumRooms Alley Price 0 NaN Pave 127500 1 2.0 NaN 106000 2 4.0 NaN 178100 3 NaN NaN 140000 为了处理缺失的数据, 常使用插值和删除的方法, 这里使用插值\nPYTHON Collapse Copy # inputs: 所有行, 前两列数据, 房间数量和小巷 # outputs: 所有行, 最后一列数据, 价格 inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2] # 使用 pd.get_dummies() 将 Alley 分成两类, dummy_na 表示是否为缺失值(NaN)创建一个新的独热编码列 # 当 dummy_na=True 时, 如果原始数据中有缺失值(NaN), 函数会创建一个新的列, 列名为原列名_nan, 并用True来标记所有原始值为NaN的行 inputs = pd.get_dummies(inputs, dummy_na=True) print(inputs) Click to expand and view more NumRooms Alley_Pave Alley_nan 0 NaN True False 1 2.0 False True 2 4.0 False True 3 NaN False True PYTHON Collapse Copy # 使用平均值填充 inputs = inputs.fillna(inputs.mean()) print(inputs) Click to expand and view more NumRooms Alley_Pave Alley_nan 0 3.0 1 0 1 2.0 0 1 2 4.0 0 1 3 3.0 0 1 最后转换为 torch 张量\nPYTHON Collapse Copy import torch X = torch.tensor(inputs.to_numpy(dtype=float)) y = torch.tensor(outputs.to_numpy(dtype=float)) X, y Click to expand and view more 输出\nPLAINTEXT Collapse Copy (tensor([[3., 1., 0.], [2., 0., 1.], [4., 0., 1.], [3., 0., 1.]], dtype=torch.float64), tensor([127500., 106000., 178100., 140000.], dtype=torch.float64)) Click to expand and view more 深度学习更多使用 float32 类型运算, 64位太慢了\n","title":"Dive into DeepLearning - 01 - Preliminaries"}],"tags":[{"link":"/tags/agent/","name":"Agent","slug":"Agent"},{"link":"/tags/algorithm/","name":"Algorithm","slug":"Algorithm"},{"link":"/tags/c/","name":"C","slug":"C"},{"link":"/tags/concurrency/","name":"Concurrency","slug":"Concurrency"},{"link":"/tags/deeplearning/","name":"DeepLearning","slug":"DeepLearning"},{"link":"/tags/docker/","name":"Docker","slug":"Docker"},{"link":"/tags/english/","name":"English","slug":"English"},{"link":"/tags/essay/","name":"Essay","slug":"Essay"},{"link":"/tags/fastapi/","name":"FastAPI","slug":"FastAPI"},{"link":"/tags/git/","name":"Git","slug":"Git"},{"link":"/tags/go/","name":"Go","slug":"Go"},{"link":"/tags/hack/","name":"Hack","slug":"Hack"},{"link":"/tags/http/","name":"HTTP","slug":"HTTP"},{"link":"/tags/javascript/","name":"JavaScript","slug":"JavaScript"},{"link":"/tags/llms/","name":"LLMs","slug":"LLMs"},{"link":"/tags/microservice/","name":"Microservice","slug":"Microservice"},{"link":"/tags/openapi/","name":"OpenAPI","slug":"OpenAPI"},{"link":"/tags/prompt/","name":"Prompt","slug":"Prompt"},{"link":"/tags/python/","name":"Python","slug":"Python"},{"link":"/tags/redis/","name":"Redis","slug":"Redis"},{"link":"/tags/rest/","name":"REST","slug":"REST"},{"link":"/tags/rust/","name":"Rust","slug":"Rust"}]}